{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 14:51:58.526004: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-25 14:51:58.526106: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import more_itertools\n",
    "from typing import List\n",
    "from embedding_generator_default import EmbeddingGeneratorDefault\n",
    "from mongo_db_client import MongoDbClient\n",
    "from pre_processer_default import PreProcesserDefault\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models import PairDbDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = MongoDbClient()\n",
    "embedding_generator = EmbeddingGeneratorDefault()\n",
    "pre_processer = PreProcesserDefault()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_batched_pairs(pairs: List[PairDbDoc]):\n",
    "  code_sentences = [pre_processer.process_code(pair['code_tokens']) for pair in pairs]\n",
    "  comment_sentences = [pre_processer.process_text(pair['comment_tokens']) for pair in pairs]\n",
    "\n",
    "  return embedding_generator.from_code(code_sentences), embedding_generator.from_text(comment_sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tests using 64, 128 and 256 for batch_size and 1024 pairs from db, the fastest for generate embeddings was 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(db_client.get_pairs_collection().find().limit(64))\n",
    "code_emb, comment_emb = get_embeddings_from_batched_pairs(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 512, 384) dtype=float32 (created by layer 'code_input')>,\n",
       " <KerasTensor: shape=(None, 512, 384) dtype=float32 (created by layer 'comment_input')>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape\n",
    "from utils import encoder_hidden_size, encoder_seq_len\n",
    "\n",
    "transformer_embedding_shape = (encoder_seq_len, encoder_hidden_size)\n",
    "hidden_activation = 'relu'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "code_input, comment_input = Input(shape=transformer_embedding_shape, name=\"code_input\"), Input(shape=transformer_embedding_shape, name=\"comment_input\")\n",
    "code_input, comment_input\n",
    "# code_input = Reshape(target_shape=(-1, ))()\n",
    "# comment_input = Reshape(target_shape=(-1, ))() \n",
    "# merged = Concatenate(name=\"joint_embedding\")([code_input, comment_input])\n",
    "\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 196608) dtype=float32 (created by layer 'reshape')>,\n",
       " <KerasTensor: shape=(None, 196608) dtype=float32 (created by layer 'reshape_1')>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_code = Reshape(target_shape=(-1, ))(code_input)\n",
    "reshaped_comment = Reshape(target_shape=(-1, ))(comment_input)\n",
    "reshaped_code, reshaped_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 393216) dtype=float32 (created by layer 'joint_embedding')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = Concatenate(name=\"joint_embedding\")([reshaped_code, reshaped_comment])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(3,), dtype=tf.string, name=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.type_spec_from_value(['1', '2', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.ones(shape=(1, )), tf.zeros(shape=(1, ))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_tokens = [\"@\",\"VisibleForTesting\",\"protected\",\"static\",\"boolean\",\"notAllowedStrategy\",\"(\",\"DockerSlaveTemplate\",\"template\",\")\",\"{\",\"if\",\"(\",\"isNull\",\"(\",\"template\",\")\",\")\",\"{\",\"LOG\",\".\",\"debug\",\"(\",\"\\\"Skipping DockerProvisioningStrategy because: template is null\\\"\",\")\",\";\",\"return\",\"true\",\";\",\"}\",\"final\",\"RetentionStrategy\",\"retentionStrategy\",\"=\",\"template\",\".\",\"getRetentionStrategy\",\"(\",\")\",\";\",\"if\",\"(\",\"isNull\",\"(\",\"retentionStrategy\",\")\",\")\",\"{\",\"LOG\",\".\",\"debug\",\"(\",\"\\\"Skipping DockerProvisioningStrategy because: strategy is null for {}\\\"\",\",\",\"template\",\")\",\";\",\"}\",\"if\",\"(\",\"retentionStrategy\",\"instanceof\",\"DockerOnceRetentionStrategy\",\")\",\"{\",\"if\",\"(\",\"template\",\".\",\"getNumExecutors\",\"(\",\")\",\"==\",\"1\",\")\",\"{\",\"LOG\",\".\",\"debug\",\"(\",\"\\\"Applying faster provisioning for single executor template {}\\\"\",\",\",\"template\",\")\",\";\",\"return\",\"false\",\";\",\"}\",\"else\",\"{\",\"LOG\",\".\",\"debug\",\"(\",\"\\\"Skipping DockerProvisioningStrategy because: numExecutors is {} for {}\\\"\",\",\",\"template\",\".\",\"getNumExecutors\",\"(\",\")\",\",\",\"template\",\")\",\";\",\"return\",\"true\",\";\",\"}\",\"}\",\"if\",\"(\",\"retentionStrategy\",\"instanceof\",\"RetentionStrategy\",\".\",\"Demand\",\")\",\"{\",\"LOG\",\".\",\"debug\",\"(\",\"\\\"Applying faster provisioning for Demand strategy for template {}\\\"\",\",\",\"template\",\")\",\";\",\"return\",\"false\",\";\",\"}\",\"\\/\\/ forbid by default\",\"LOG\",\".\",\"trace\",\"(\",\"\\\"Skipping YAD provisioning for unknown mix of configuration for {}\\\"\",\",\",\"template\",\")\",\";\",\"return\",\"true\",\";\",\"}\"]\n",
    "comment_tokens = [\"Exclude\",\"unknown\",\"mix\",\"of\",\"configuration\",\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.code_input = Input(shape=transformer_embedding_shape, name=\"code_input\") \n",
    "    self.comment_input = Input(shape=transformer_embedding_shape, name=\"comment_input\")\n",
    "    self.reshaped_code = Reshape(target_shape=(-1, ))\n",
    "    self.reshaped_comment = Reshape(target_shape=(-1, ))\n",
    "    self.merged = Concatenate(name=\"joint_embedding\")\n",
    "    self.hidden1 = Dense(400, activation='relu')\n",
    "    self.hidden2 = Dense(200, activation='relu')\n",
    "    self.hidden3 = Dense(100, activation='relu')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransfomerEmbedding(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, units=32, input_dim=32):\n",
    "    super().__init__()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ObjectId' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m MyModel()\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      4\u001b[0m   optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/data_adapter.py:817\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m     \u001b[39m# The above call may fail if the model is a container-like class that\u001b[39;00m\n\u001b[1;32m    812\u001b[0m     \u001b[39m# does not implement its own forward pass (e.g. a GAN or VAE where the\u001b[39;00m\n\u001b[1;32m    813\u001b[0m     \u001b[39m# forward pass is handled by subcomponents).\u001b[39;00m\n\u001b[1;32m    814\u001b[0m     \u001b[39m# Such a model does not need to be built.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_batch_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mflatten(peek)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    819\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tensor_spec\u001b[39m(t):\n\u001b[1;32m    820\u001b[0m   \u001b[39m# TODO(b/226395276): Remove _with_tensor_ranks_only usage.\u001b[39;00m\n\u001b[1;32m    821\u001b[0m   \u001b[39mreturn\u001b[39;00m type_spec\u001b[39m.\u001b[39mtype_spec_from_value(t)\u001b[39m.\u001b[39m_with_tensor_ranks_only()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ObjectId' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dataset = db_client.get_pairs_collection().find().limit(10)\n",
    "model = MyModel()\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1():\n",
    "  for i in range(10):\n",
    "    yield i, i+1, i+2\n",
    "\n",
    "def test2():\n",
    "  for i in range(10):\n",
    "    yield ((i, i+1), i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i1: 0 i2: 1 target: 2\n",
      "i1: 1 i2: 2 target: 3\n",
      "i1: 2 i2: 3 target: 4\n",
      "i1: 3 i2: 4 target: 5\n",
      "i1: 4 i2: 5 target: 6\n",
      "i1: 5 i2: 6 target: 7\n",
      "i1: 6 i2: 7 target: 8\n",
      "i1: 7 i2: 8 target: 9\n",
      "i1: 8 i2: 9 target: 10\n",
      "i1: 9 i2: 10 target: 11\n"
     ]
    }
   ],
   "source": [
    "for input1, input2, target in test1():\n",
    "    print(f'i1: {input1} i2: {input2} target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (0, 1) target: 2\n",
      "inputs: (1, 2) target: 3\n",
      "inputs: (2, 3) target: 4\n",
      "inputs: (3, 4) target: 5\n",
      "inputs: (4, 5) target: 6\n",
      "inputs: (5, 6) target: 7\n",
      "inputs: (6, 7) target: 8\n",
      "inputs: (7, 8) target: 9\n",
      "inputs: (8, 9) target: 10\n",
      "inputs: (9, 10) target: 11\n"
     ]
    }
   ],
   "source": [
    "for item in test2():\n",
    "    print(f'inputs: {item[0]} target: {item[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = db_client.get_queries_collection()\n",
    "results = queries.update_many(\n",
    "  { \"language\": \"Java\" },\n",
    "  {\"$set\": {\"language\": \"java\" } }\n",
    ")\n",
    "\n",
    "results.modified_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x105a13be0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = queries.update_many(\n",
    "  { \"language\": \"Python\" },\n",
    "  {\"$set\": {\"language\": \"python\" } }\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target(target, batch_size):\n",
    "  target_embedding = tf.convert_to_tensor([target for _ in range(batch_size)])\n",
    "  return target_embedding\n",
    "\n",
    "get_target(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full((1, ), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
