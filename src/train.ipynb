{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 23:20:30.892781: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-28 23:20:30.892873: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import more_itertools\n",
    "from typing import List\n",
    "from embedding_generator_default import EmbeddingGeneratorDefault\n",
    "from mongo_db_client import MongoDbClient\n",
    "from pre_processer_default import PreProcesserDefault\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models import PairDbDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = MongoDbClient()\n",
    "embedding_generator = EmbeddingGeneratorDefault()\n",
    "pre_processer = PreProcesserDefault()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_batched_pairs(pairs: List[PairDbDoc]):\n",
    "  code_sentences = [pre_processer.process_code(pair['code_tokens']) for pair in pairs]\n",
    "  comment_sentences = [pre_processer.process_text(pair['comment_tokens']) for pair in pairs]\n",
    "\n",
    "  return embedding_generator.from_code(code_sentences), embedding_generator.from_text(comment_sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tests using 64, 128 and 256 for batch_size and 1024 pairs from db, the fastest for generate embeddings was 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(db_client.get_pairs_collection().find().limit(64))\n",
    "code_emb, comment_emb = get_embeddings_from_batched_pairs(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 512, 384) dtype=float32 (created by layer 'code_input')>,\n",
       " <KerasTensor: shape=(None, 512, 384) dtype=float32 (created by layer 'comment_input')>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape\n",
    "from utils import encoder_hidden_size, encoder_seq_len\n",
    "\n",
    "transformer_embedding_shape = (encoder_seq_len, encoder_hidden_size)\n",
    "hidden_activation = 'relu'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "code_input, comment_input = Input(shape=transformer_embedding_shape, name=\"code_input\"), Input(shape=transformer_embedding_shape, name=\"comment_input\")\n",
    "code_input, comment_input\n",
    "# code_input = Reshape(target_shape=(-1, ))()\n",
    "# comment_input = Reshape(target_shape=(-1, ))() \n",
    "# merged = Concatenate(name=\"joint_embedding\")([code_input, comment_input])\n",
    "\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 196608) dtype=float32 (created by layer 'reshape_2')>,\n",
       " <KerasTensor: shape=(None, 196608) dtype=float32 (created by layer 'reshape_3')>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_code = Reshape(target_shape=(-1, ))(code_input)\n",
    "reshaped_comment = Reshape(target_shape=(-1, ))(comment_input)\n",
    "reshaped_code, reshaped_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 393216) dtype=float32 (created by layer 'joint_embedding')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = Concatenate(name=\"joint_embedding\")([reshaped_code, reshaped_comment])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
