{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements\n",
    "Make sure you're using the local conda env for running this notebook. If is not created yet, create one with python 3.9 by running `conda create --name myenv python=3.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (23.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (4.34.1)\n",
      "Requirement already satisfied: datasets in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (2.14.5)\n",
      "Requirement already satisfied: numpy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (1.26.1)\n",
      "Requirement already satisfied: pandas in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: tensorflow in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-metal in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: plotly==5.18.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (5.18.0)\n",
      "Requirement already satisfied: nbformat in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (5.9.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from plotly==5.18.0->-r ../requirements.txt (line 9)) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from plotly==5.18.0->-r ../requirements.txt (line 9)) (23.2)\n",
      "Requirement already satisfied: filelock in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets->-r ../requirements.txt (line 2)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-metal->-r ../requirements.txt (line 7)) (0.41.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: scipy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (1.11.3)\n",
      "Requirement already satisfied: nltk in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (0.1.99)\n",
      "Requirement already satisfied: fastjsonschema in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (2.18.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (4.19.1)\n",
      "Requirement already satisfied: jupyter-core in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (5.11.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (0.10.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: sympy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jupyter-core->nbformat->-r ../requirements.txt (line 10)) (3.11.0)\n",
      "Requirement already satisfied: click in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nltk->sentence-transformers->-r ../requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nltk->sentence-transformers->-r ../requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from scikit-learn->sentence-transformers->-r ../requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torchvision->sentence-transformers->-r ../requirements.txt (line 8)) (10.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, load_from_disk, concatenate_datasets\n",
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "def load_from_cs_net(take: int) -> Dataset:\n",
    "  ds = load_dataset(dataset_name, 'python', split='train')\n",
    "  return Dataset.from_dict(ds[:take]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "comment_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "code_model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "embedding_shape = (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "random_generator = default_rng(seed=42)\n",
    "\n",
    "def generate_negative_samples(iterator: Iterator, negative_samples_per_sample: int):\n",
    "  for batched_sample in iterator:\n",
    "    codes_embeddings = batched_sample['code_embedding']\n",
    "    comments_embeddings = batched_sample['comment_embedding']\n",
    "    batch_indexes = range(len(codes_embeddings))\n",
    "\n",
    "    for index in batch_indexes:\n",
    "      indexes = [i for i in batch_indexes if i != index]\n",
    "      negative_indexes = random_generator.choice(indexes, negative_samples_per_sample, replace=False)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": codes_embeddings[index],\n",
    "        \"comment_embedding\": comments_embeddings[index],\n",
    "        \"target\": 1\n",
    "      }\n",
    "\n",
    "      for negative_index in negative_indexes:\n",
    "        yield {\n",
    "          \"code_embedding\": codes_embeddings[index],\n",
    "          \"comment_embedding\": comments_embeddings[negative_index],\n",
    "          \"target\": 0\n",
    "        }\n",
    "\n",
    "def with_neg_samples(dataset: Dataset, negative_samples_per_sample: int, batch_size = 100) -> Dataset:\n",
    "  assert negative_samples_per_sample <= batch_size, \"negative_samples_per_sample must not be greater than batch_size\"\n",
    "  if negative_samples_per_sample <= 0:\n",
    "    return dataset\n",
    "  \n",
    "  dataset_with_negative_samples: Dataset = Dataset.from_generator(lambda: generate_negative_samples(dataset.iter(batch_size=batch_size), negative_samples_per_sample)) # type: ignore\n",
    "  return dataset_with_negative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_count = 2000\n",
    "train_dataset_path = f'../datasets/embeddings_python_train_{train_count}'\n",
    "train_pairs = load_from_cs_net(train_count)\n",
    "is_embeddings_dataset_stored = os.path.isdir(train_dataset_path)\n",
    "\n",
    "def generate_embeddings_in_batch(batched_sample):\n",
    "  codes = batched_sample['func_code_string']\n",
    "  comments = batched_sample['func_documentation_string']\n",
    "\n",
    "  return {\n",
    "    \"code_embedding\": code_model.encode(codes),\n",
    "    \"comment_embedding\": comment_model.encode(comments),\n",
    "  }\n",
    "\n",
    "embeddings_dataset: Dataset = Dataset.from_dict(load_from_disk(train_dataset_path)[:train_count]) if is_embeddings_dataset_stored else train_pairs.map(\n",
    "  generate_embeddings_in_batch, \n",
    "  batched=True, \n",
    "  batch_size=100,\n",
    "  remove_columns=list(train_pairs[0].keys()),\n",
    "  desc=\"Generating embeddings\"\n",
    ") # type: ignore\n",
    "\n",
    "if is_embeddings_dataset_stored == False:\n",
    "  embeddings_dataset.save_to_disk(train_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add negative samples to train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_dataset(negative_samples_per_sample: int):\n",
    "  tf_train_dataset = with_neg_samples(embeddings_dataset.shuffle(), negative_samples_per_sample).to_tf_dataset().map(lambda sample: ({\n",
    "    \"code_embedding\": sample[\"code_embedding\"],\n",
    "    \"comment_embedding\": sample[\"comment_embedding\"],\n",
    "  }, sample[\"target\"]))\n",
    "  \n",
    "  return tf_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from models import build_dense_model\n",
    "\n",
    "neg_samples_count = [1, 5, 15]\n",
    "num_hidden_layers = 4\n",
    "for neg_count in neg_samples_count:\n",
    "  model = build_dense_model(num_hidden_layers=num_hidden_layers, input_shape=embedding_shape, model_name=f'dense_{num_hidden_layers}_neg_{neg_count}')\n",
    "  tf_train_dataset = to_tf_dataset(neg_count)\n",
    "  tensor_board_callback = callbacks.TensorBoard(log_dir=f'../logs/{model.name}')\n",
    "\n",
    "  model.fit(\n",
    "    tf_train_dataset.batch(batch_size),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch,\n",
    "    callbacks=[tensor_board_callback]\n",
    "  )\n",
    "  model.save(f'../models/{model.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CodeSearchNet queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splits = load_dataset(dataset_name, 'python', split=['train', 'test', 'validation']) # type: ignore\n",
    "python_full_dataset = concatenate_datasets(python_splits)\n",
    "splits_info = python_splits[0].info.splits\n",
    "python_full_dataset_count = sum([splits_info[key].num_examples for key in splits_info.keys()])\n",
    "\n",
    "full_dataset_url_index = { sample['func_code_url']: index  for index, sample in tqdm(enumerate(python_full_dataset), desc=\"Generating dict lookup\", total=python_full_dataset_count) }\n",
    "def search_by_url(url: str) -> Optional[int]:\n",
    "  try:\n",
    "    return full_dataset_url_index[url]\n",
    "  except:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples_path = '../datasets/query_samples'\n",
    "\n",
    "def remove_duplicates(dataset: Dataset) -> Dataset:\n",
    "  pandas_dataset = dataset.to_pandas().drop_duplicates(subset=['Language', 'Query', 'GitHubUrl', 'Relevance'], ignore_index=True) # type: ignore\n",
    "  dedup_dataset = Dataset.from_pandas(pandas_dataset)\n",
    "  return dedup_dataset\n",
    "\n",
    "def remove_queries_without_code(dataset: Dataset) -> Dataset:\n",
    "  return dataset.filter(lambda sample: search_by_url(sample['GitHubUrl']) is not None, desc=\"Filtering queries with no corresponding code\")\n",
    "\n",
    "def pre_process_query_samples() -> Dataset:\n",
    "  cs_net_queries_dataset: Dataset = Dataset.from_csv('../datasets/code_search_net_queries.csv') # type: ignore\n",
    "  \n",
    "  return remove_queries_without_code(remove_duplicates(cs_net_queries_dataset))\n",
    "\n",
    "def get_query_samples() -> Dataset:\n",
    "  try:\n",
    "    return Dataset.load_from_disk(query_samples_path)\n",
    "  except:\n",
    "    query_samples = pre_process_query_samples()\n",
    "    query_samples.save_to_disk(query_samples_path)\n",
    "    return query_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples: Dataset = get_query_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_code_embeddings(samples) -> Dataset:\n",
    "  query_texts = [sample['Query'] for sample in samples]\n",
    "  query_codes = [python_full_dataset[search_by_url(sample['GitHubUrl'])]['func_code_string'] for sample in samples]\n",
    "  assert len(query_texts) == len(query_codes), \"query_texts and query_codes arrays doesn't have the same length\"\n",
    "\n",
    "  query_embeddings = comment_model.encode(query_texts)\n",
    "  code_embeddings = code_model.encode(query_codes)\n",
    "\n",
    "  validation_dataset = []\n",
    "  for query_embedding, code_embedding in zip(query_embeddings, code_embeddings):\n",
    "    validation_dataset.append({\n",
    "      \"code_embedding\": code_embedding,\n",
    "      \"comment_embedding\": query_embedding,\n",
    "    })\n",
    "\n",
    "  return Dataset.from_list(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def validate(model, samples):\n",
    "  validation_dataset = get_query_code_embeddings(samples).to_tf_dataset(batch_size=10)\n",
    "\n",
    "  return {\n",
    "    \"predictions\": model.predict(validation_dataset, verbose=0).flatten(),\n",
    "    \"targets\": [sample['Relevance'] for sample in samples]\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prediction_correct(prediction, target) -> bool:\n",
    "  if target in [0, 1]:\n",
    "    return prediction <= 0.5\n",
    "  \n",
    "  if target in [2, 3]:\n",
    "    return prediction > 0.5\n",
    "  \n",
    "  raise ValueError(f\"target should be in range of [0, 3]. Instead, it has value of {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_query_samples = [sample for sample in query_samples if sample['Language'].lower() == 'python']\n",
    "validation_query_samples_count = len(validation_query_samples)\n",
    "\n",
    "for model_name in os.listdir('../models/'):\n",
    "  model = load_model(f'../models/{model_name}')\n",
    "  result = validate(model, validation_query_samples)\n",
    "  \n",
    "  hits = sum([is_prediction_correct(prediction, target) for prediction, target in zip(result['predictions'], result['targets'])])\n",
    "  success_percentage = hits / validation_query_samples_count\n",
    "\n",
    "  print(f\"model {model_name}: {success_percentage:.2%} - {hits} of {validation_query_samples_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generalization experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def search(query, model) -> List:\n",
    "  query_embedding = comment_model.encode([query]).flatten()\n",
    "  samples = Dataset.from_list([{ \"code_embedding\": embedding_pair[\"code_embedding\"], 'comment_embedding': query_embedding } for embedding_pair in embeddings_dataset]).to_tf_dataset(batch_size=10)\n",
    "\n",
    "  predictions = model.predict(samples).flatten()\n",
    "  results = [(prediction, index) for index, prediction in enumerate(predictions)]\n",
    "\n",
    "  return results\n",
    "\n",
    "def get_code(index: int) -> str:\n",
    "  return train_pairs[index]['func_code_string']\n",
    "\n",
    "def top_k(k: int, results: List):\n",
    "  return [get_code(index) for _, index in results[:k]]\n",
    "\n",
    "def bottom_k(k: int, results: List):\n",
    "  return [get_code(index) for _, index in results[-k:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results = search(\n",
    "  query=\"aes encryption\",\n",
    "  model=load_model('../models/dense_4_neg_1/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def addidsuffix(self, idsuffix, recursive = True):\\n        \"\"\"Appends a suffix to this element\\'s ID, and optionally to all child IDs as well. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        if self.id: self.id += idsuffix\\n        if recursive:\\n            for e in self:\\n                try:\\n                    e.addidsuffix(idsuffix, recursive)\\n                except Exception:\\n                    pass',\n",
       " 'def setparents(self):\\n        \"\"\"Correct all parent relations for elements within the scop. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        for c in self:\\n            if isinstance(c, AbstractElement):\\n                c.parent = self\\n                c.setparents()',\n",
       " 'def setdoc(self,newdoc):\\n        \"\"\"Set a different document. Usually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\\n        self.doc = newdoc\\n        if self.doc and self.id:\\n            self.doc.index[self.id] = self\\n        for c in self:\\n            if isinstance(c, AbstractElement):\\n                c.setdoc(newdoc)',\n",
       " 'def hastext(self,cls=\\'current\\',strict=True, correctionhandling=CorrectionHandling.CURRENT): #pylint: disable=too-many-return-statements\\n        \"\"\"Does this element have text (of the specified class)\\n\\n        By default, and unlike :meth:`text`, this checks strictly, i.e. the element itself must have the text and it is not inherited from its children.\\n\\n        Parameters:\\n            cls (str): The class of the text content to obtain, defaults to ``current``.\\n            strict (bool):  Set this if you are strictly interested in the text explicitly associated with the element, without recursing into children. Defaults to ``True``.\\n            correctionhandling: Specifies what text to check for when corrections are encountered. The default is ``CorrectionHandling.CURRENT``, which will retrieve the corrected/current text. You can set this to ``CorrectionHandling.ORIGINAL`` if you want the text prior to correction, and ``CorrectionHandling.EITHER`` if you don\\'t care.\\n\\n        Returns:\\n            bool\\n        \"\"\"\\n        if not self.PRINTABLE: #only printable elements can hold text\\n            return False\\n        elif self.TEXTCONTAINER:\\n            return True\\n        else:\\n            try:\\n                if strict:\\n                    self.textcontent(cls, correctionhandling) #will raise NoSuchTextException when not found\\n                    return True\\n                else:\\n                    #Check children\\n                    for e in self:\\n                        if e.PRINTABLE and not isinstance(e, TextContent):\\n                            if e.hastext(cls, strict, correctionhandling):\\n                                return True\\n\\n                    self.textcontent(cls, correctionhandling)  #will raise NoSuchTextException when not found\\n                    return True\\n            except NoSuchText:\\n                return False',\n",
       " 'def hasphon(self,cls=\\'current\\',strict=True,correctionhandling=CorrectionHandling.CURRENT): #pylint: disable=too-many-return-statements\\n        \"\"\"Does this element have phonetic content (of the specified class)\\n\\n        By default, and unlike :meth:`phon`, this checks strictly, i.e. the element itself must have the phonetic content and it is not inherited from its children.\\n\\n        Parameters:\\n            cls (str): The class of the phonetic content to obtain, defaults to ``current``.\\n            strict (bool):  Set this if you are strictly interested in the phonetic content explicitly associated with the element, without recursing into children. Defaults to ``True``.\\n            correctionhandling: Specifies what phonetic content to check for when corrections are encountered. The default is ``CorrectionHandling.CURRENT``, which will retrieve the corrected/current phonetic content. You can set this to ``CorrectionHandling.ORIGINAL`` if you want the phonetic content prior to correction, and ``CorrectionHandling.EITHER`` if you don\\'t care.\\n\\n        Returns:\\n            bool\\n        \"\"\"\\n        if not self.SPEAKABLE: #only printable elements can hold text\\n            return False\\n        elif self.PHONCONTAINER:\\n            return True\\n        else:\\n            try:\\n                if strict:\\n                    self.phoncontent(cls, correctionhandling)\\n                    return True\\n                else:\\n                    #Check children\\n                    for e in self:\\n                        if e.SPEAKABLE and not isinstance(e, PhonContent):\\n                            if e.hasphon(cls, strict, correctionhandling):\\n                                return True\\n\\n                    self.phoncontent(cls)  #will raise NoSuchTextException when not found\\n                    return True\\n            except NoSuchPhon:\\n                return False']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k(5, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def read_ipv4(self, length):\\n        \"\"\"Read Internet Protocol version 4 (IPv4).\\n\\n        Structure of IPv4 header [RFC 791]:\\n\\n             0                   1                   2                   3\\n             0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |Version|  IHL  |Type of Service|          Total Length         |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |         Identification        |Flags|      Fragment Offset    |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |  Time to Live |    Protocol   |         Header Checksum       |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |                       Source Address                          |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |                    Destination Address                        |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n            |                    Options                    |    Padding    |\\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n\\n            Octets      Bits        Name                    Description\\n              0           0     ip.version              Version (4)\\n              0           4     ip.hdr_len              Internal Header Length (IHL)\\n              1           8     ip.dsfield.dscp         Differentiated Services Code Point (DSCP)\\n              1          14     ip.dsfield.ecn          Explicit Congestion Notification (ECN)\\n              2          16     ip.len                  Total Length\\n              4          32     ip.id                   Identification\\n              6          48     -                       Reserved Bit (must be zero)\\n              6          49     ip.flags.df             Don\\'t Fragment (DF)\\n              6          50     ip.flags.mf             More Fragments (MF)\\n              6          51     ip.frag_offset          Fragment Offset\\n              8          64     ip.ttl                  Time To Live (TTL)\\n              9          72     ip.proto                Protocol (Transport Layer)\\n              10         80     ip.checksum             Header Checksum\\n              12         96     ip.src                  Source IP Address\\n              16        128     ip.dst                  Destination IP Address\\n              20        160     ip.options              IP Options (if IHL > 5)\\n\\n        \"\"\"\\n        if length is None:\\n            length = len(self)\\n\\n        _vihl = self._read_fileng(1).hex()\\n        _dscp = self._read_binary(1)\\n        _tlen = self._read_unpack(2)\\n        _iden = self._read_unpack(2)\\n        _frag = self._read_binary(2)\\n        _ttol = self._read_unpack(1)\\n        _prot = self._read_protos(1)\\n        _csum = self._read_fileng(2)\\n        _srca = self._read_ipv4_addr()\\n        _dsta = self._read_ipv4_addr()\\n\\n        ipv4 = dict(\\n            version=_vihl[0],\\n            hdr_len=int(_vihl[1], base=16) * 4,\\n            dsfield=dict(\\n                dscp=(\\n                    TOS_PRE.get(int(_dscp[:3], base=2)),\\n                    TOS_DEL.get(int(_dscp[3], base=2)),\\n                    TOS_THR.get(int(_dscp[4], base=2)),\\n                    TOS_REL.get(int(_dscp[5], base=2)),\\n                ),\\n                ecn=TOS_ECN.get(int(_dscp[-2:], base=2)),\\n            ),\\n            len=_tlen,\\n            id=_iden,\\n            flags=dict(\\n                df=True if int(_frag[1]) else False,\\n                mf=True if int(_frag[2]) else False,\\n            ),\\n            frag_offset=int(_frag[3:], base=2) * 8,\\n            ttl=_ttol,\\n            proto=_prot,\\n            checksum=_csum,\\n            src=_srca,\\n            dst=_dsta,\\n        )\\n\\n        _optl = ipv4[\\'hdr_len\\'] - 20\\n        if _optl:\\n            options = self._read_ipv4_options(_optl)\\n            ipv4[\\'opt\\'] = options[0]    # tuple of option acronyms\\n            ipv4.update(options[1])     # merge option info to buffer\\n            # ipv4[\\'opt\\'] = self._read_fileng(_optl) or None\\n\\n        hdr_len = ipv4[\\'hdr_len\\']\\n        raw_len = ipv4[\\'len\\'] - hdr_len\\n        ipv4[\\'packet\\'] = self._read_packet(header=hdr_len, payload=raw_len)\\n\\n        return self._decode_next_layer(ipv4, _prot, raw_len)',\n",
       " 'def _read_opt_type(self, kind):\\n        \"\"\"Read option type field.\\n\\n        Positional arguments:\\n            * kind -- int, option kind value\\n\\n        Returns:\\n            * dict -- extracted IPv4 option\\n\\n        Structure of option type field [RFC 791]:\\n\\n            Octets      Bits        Name                    Descriptions\\n              0           0     ip.opt.type.copy        Copied Flag (0/1)\\n              0           1     ip.opt.type.class       Option Class (0-3)\\n              0           3     ip.opt.type.number      Option Number\\n\\n        \"\"\"\\n        bin_ = bin(kind)[2:].zfill(8)\\n\\n        type_ = {\\n            \\'copy\\': bool(int(bin_[0], base=2)),\\n            \\'class\\': opt_class.get(int(bin_[1:3], base=2)),\\n            \\'number\\': int(bin_[3:], base=2),\\n        }\\n\\n        return type_',\n",
       " 'def _read_ipv4_options(self, size=None):\\n        \"\"\"Read IPv4 option list.\\n\\n        Positional arguments:\\n            * size -- int, buffer size\\n\\n        Returns:\\n            * tuple -- IPv4 option list\\n            * dict -- extracted IPv4 option\\n\\n        \"\"\"\\n        counter = 0         # length of read option list\\n        optkind = list()    # option kind list\\n        options = dict()    # dict of option data\\n\\n        while counter < size:\\n            # get option kind\\n            kind = self._read_unpack(1)\\n\\n            # fetch corresponding option tuple\\n            opts = IPv4_OPT.get(kind)\\n            if opts is None:\\n                len_ = size - counter\\n                counter = size\\n                options[\\'Unknown\\'] = self._read_fileng(len_)\\n                break\\n\\n            # extract option\\n            dscp = OPT_TYPE.get(kind)\\n            desc = dscp.name\\n            if opts[0]:\\n                byte = self._read_unpack(1)\\n                if byte:    # check option process mode\\n                    data = process_opt[opts[2]](self, byte, kind)\\n                else:       # permission options (length is 2)\\n                    data = dict(\\n                        kind=kind,                          # option kind\\n                        type=self._read_opt_type(kind),     # option type info\\n                        length=2,                           # option length\\n                        flag=True,                          # permission flag\\n                    )\\n            else:           # 1-bytes options\\n                byte = 1\\n\\n                data = dict(\\n                    kind=kind,                          # option kind\\n                    type=self._read_opt_type(kind),     # option type info\\n                    length=1,                           # option length\\n                )\\n\\n            # record option data\\n            counter += byte\\n            if dscp in optkind:\\n                if isinstance(options[desc], tuple):\\n                    options[desc] += (Info(data),)\\n                else:\\n                    options[desc] = (Info(options[desc]), Info(data))\\n            else:\\n                optkind.append(dscp)\\n                options[desc] = data\\n\\n            # break when eol triggered\\n            if not kind:\\n                break\\n\\n        # get padding\\n        if counter < size:\\n            len_ = size - counter\\n            self._read_binary(len_)\\n\\n        return tuple(optkind), options',\n",
       " 'def _read_mode_donone(self, size, kind):\\n        \"\"\"Read options request no process.\\n\\n        Positional arguments:\\n            * size - int, length of option\\n            * kind - int, option kind value\\n\\n        Returns:\\n            * dict -- extracted option\\n\\n        Structure of IPv4 options:\\n            Octets      Bits        Name                    Description\\n              0           0     ip.opt.kind             Kind\\n              0           0     ip.opt.type.copy        Copied Flag\\n              0           1     ip.opt.type.class       Option Class\\n              0           3     ip.opt.type.number      Option Number\\n              1           8     ip.opt.length           Length\\n              2          16     ip.opt.data             Kind-specific Data\\n\\n        \"\"\"\\n        if size < 3:\\n            raise ProtocolError(f\\'{self.alias}: [Optno {kind}] invalid format\\')\\n\\n        data = dict(\\n            kind=kind,\\n            type=self._read_opt_type(kind),\\n            length=size,\\n            data=self._read_fileng(size),\\n        )\\n\\n        return data',\n",
       " 'def _read_mode_unpack(self, size, kind):\\n        \"\"\"Read options request unpack process.\\n\\n        Positional arguments:\\n            * size - int, length of option\\n            * kind - int, option kind value\\n\\n        Returns:\\n            * dict -- extracted option\\n\\n        Structure of IPv4 options:\\n            Octets      Bits        Name                    Description\\n              0           0     ip.opt.kind             Kind\\n              0           0     ip.opt.type.copy        Copied Flag\\n              0           1     ip.opt.type.class       Option Class\\n              0           3     ip.opt.type.number      Option Number\\n              1           8     ip.opt.length           Length\\n              2          16     ip.opt.data             Kind-specific Data\\n\\n        \"\"\"\\n        if size < 3:\\n            raise ProtocolError(f\\'{self.alias}: [Optno {kind}] invalid format\\')\\n\\n        data = dict(\\n            kind=kind,\\n            type=self._read_opt_type(kind),\\n            length=size,\\n            data=self._read_unpack(size),\\n        )\\n\\n        return data']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_k(5, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>prediction=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999
         ],
         "xaxis": "x",
         "y": [
          0.9999891519546509,
          0.9999872446060181,
          0.9999871253967285,
          0.9999634027481079,
          0.9999569654464722,
          0.9999449253082275,
          0.999942421913147,
          0.9999356269836426,
          0.9999241828918457,
          0.9999206066131592,
          0.9999140501022339,
          0.9999122619628906,
          0.9999105930328369,
          0.999908447265625,
          0.9999053478240967,
          0.9999046325683594,
          0.9999033212661743,
          0.9999032020568848,
          0.999901294708252,
          0.999897837638855,
          0.9998925924301147,
          0.9998908042907715,
          0.9998899698257446,
          0.9998897314071655,
          0.9998854398727417,
          0.9998841285705566,
          0.9998830556869507,
          0.9998723268508911,
          0.9998698234558105,
          0.9998652935028076,
          0.9998618364334106,
          0.9998552799224854,
          0.9998537302017212,
          0.9998500347137451,
          0.9998482465744019,
          0.9998480081558228,
          0.9998453855514526,
          0.9998385906219482,
          0.9998363256454468,
          0.9998356103897095,
          0.9998337030410767,
          0.999832034111023,
          0.9998319149017334,
          0.9998319149017334,
          0.9998319149017334,
          0.9998288154602051,
          0.9998250603675842,
          0.9998247027397156,
          0.9998230338096619,
          0.9998173117637634,
          0.9998127818107605,
          0.9998103976249695,
          0.9998071789741516,
          0.9998038411140442,
          0.9997995495796204,
          0.9997966885566711,
          0.9997934699058533,
          0.9997904896736145,
          0.9997888207435608,
          0.9997887015342712,
          0.9997883439064026,
          0.9997753500938416,
          0.9997746348381042,
          0.9997732043266296,
          0.9997710585594177,
          0.9997677206993103,
          0.9997676014900208,
          0.9997662901878357,
          0.9997627139091492,
          0.9997549653053284,
          0.9997549653053284,
          0.9997517466545105,
          0.9997503161430359,
          0.9997386336326599,
          0.9997376799583435,
          0.9997345805168152,
          0.999729573726654,
          0.9997236132621765,
          0.9997208714485168,
          0.9997164607048035,
          0.999713122844696,
          0.9997102618217468,
          0.9997093081474304,
          0.9997089505195618,
          0.9996993541717529,
          0.999688982963562,
          0.9996869564056396,
          0.999685525894165,
          0.999680757522583,
          0.9996806383132935,
          0.9996788501739502,
          0.9996746778488159,
          0.9996680021286011,
          0.9996651411056519,
          0.9996587038040161,
          0.9996579885482788,
          0.9996503591537476,
          0.9996448755264282,
          0.9996381998062134,
          0.999637246131897,
          0.9996371269226074,
          0.9996277093887329,
          0.9996254444122314,
          0.9996219873428345,
          0.9996163845062256,
          0.9996135830879211,
          0.9996115565299988,
          0.999602735042572,
          0.9995995163917542,
          0.9995908141136169,
          0.9995822310447693,
          0.999579131603241,
          0.9995786547660828,
          0.9995679259300232,
          0.999567449092865,
          0.9995647072792053,
          0.9995611310005188,
          0.9995392560958862,
          0.9995348453521729,
          0.9995331764221191,
          0.999530553817749,
          0.9995236396789551,
          0.999512791633606,
          0.9995059967041016,
          0.9994995594024658,
          0.9994893074035645,
          0.9994810223579407,
          0.9994799494743347,
          0.9994733929634094,
          0.9994438290596008,
          0.9994198083877563,
          0.9994068145751953,
          0.9993951320648193,
          0.9993889331817627,
          0.9993828535079956,
          0.9993771910667419,
          0.9993687272071838,
          0.9993541836738586,
          0.9993402361869812,
          0.999330997467041,
          0.9993190765380859,
          0.9993126392364502,
          0.999303936958313,
          0.9993034601211548,
          0.9992971420288086,
          0.9992828965187073,
          0.9992620348930359,
          0.9992581009864807,
          0.9992541670799255,
          0.999234676361084,
          0.9992295503616333,
          0.9992215633392334,
          0.9992175102233887,
          0.9992063641548157,
          0.9991992115974426,
          0.9991668462753296,
          0.999146580696106,
          0.9991406202316284,
          0.9991287589073181,
          0.9991089701652527,
          0.9990984201431274,
          0.999071478843689,
          0.9990214109420776,
          0.999016523361206,
          0.9989885687828064,
          0.9989780187606812,
          0.9989546537399292,
          0.9989469647407532,
          0.9988542795181274,
          0.998853325843811,
          0.9988521337509155,
          0.9988433122634888,
          0.9988352656364441,
          0.9988276362419128,
          0.9988093376159668,
          0.9988051652908325,
          0.9987871050834656,
          0.9987502098083496,
          0.9987264275550842,
          0.9987217783927917,
          0.998688280582428,
          0.9986777901649475,
          0.9985413551330566,
          0.9985063672065735,
          0.9984257221221924,
          0.9983342289924622,
          0.9983285069465637,
          0.9982894062995911,
          0.9982792139053345,
          0.9982357025146484,
          0.9982250332832336,
          0.9982075691223145,
          0.998196542263031,
          0.9981921315193176,
          0.9981826543807983,
          0.9981793165206909,
          0.9981607794761658,
          0.9981379508972168,
          0.9981291890144348,
          0.9980408549308777,
          0.9979457259178162,
          0.9978750944137573,
          0.9978011250495911,
          0.997732400894165,
          0.9976633787155151,
          0.9974592328071594,
          0.9974326491355896,
          0.9974220991134644,
          0.9973932504653931,
          0.9973784685134888,
          0.9973733425140381,
          0.9972965121269226,
          0.9972867965698242,
          0.9972773194313049,
          0.9972346425056458,
          0.9971828460693359,
          0.9971729516983032,
          0.99698406457901,
          0.9969708919525146,
          0.9969171285629272,
          0.9969040751457214,
          0.9968863129615784,
          0.996878981590271,
          0.9968554973602295,
          0.9968193769454956,
          0.9967215657234192,
          0.9966745376586914,
          0.996609091758728,
          0.9964639544487,
          0.9964485168457031,
          0.996436357498169,
          0.9963592886924744,
          0.9963461756706238,
          0.9963313937187195,
          0.9962155222892761,
          0.9961289167404175,
          0.9960948824882507,
          0.9958896040916443,
          0.9958025813102722,
          0.9955528378486633,
          0.9954452514648438,
          0.9954326152801514,
          0.9954124093055725,
          0.9954062700271606,
          0.9953668117523193,
          0.9952037334442139,
          0.9952008724212646,
          0.9950567483901978,
          0.9948868155479431,
          0.994839608669281,
          0.9947243332862854,
          0.9945620894432068,
          0.994471549987793,
          0.9943885207176208,
          0.9943810105323792,
          0.9941892623901367,
          0.993928074836731,
          0.9939151406288147,
          0.9936880469322205,
          0.9932938814163208,
          0.9932115077972412,
          0.9927577972412109,
          0.9925582408905029,
          0.9925375580787659,
          0.9923672080039978,
          0.9918246865272522,
          0.9917153716087341,
          0.9916355609893799,
          0.9914331436157227,
          0.9914149641990662,
          0.9913244247436523,
          0.991226851940155,
          0.9906873106956482,
          0.9906376600265503,
          0.9905611872673035,
          0.9905334711074829,
          0.990449845790863,
          0.9902582168579102,
          0.9900951385498047,
          0.9900844097137451,
          0.9898427128791809,
          0.9897835850715637,
          0.9897740483283997,
          0.9897580146789551,
          0.9895422458648682,
          0.9892416596412659,
          0.989228367805481,
          0.9890342950820923,
          0.9882678389549255,
          0.9882224202156067,
          0.987793505191803,
          0.9875991344451904,
          0.9874562621116638,
          0.9874559044837952,
          0.9869092106819153,
          0.9863063097000122,
          0.9851105213165283,
          0.9846425652503967,
          0.9845439791679382,
          0.9839888215065002,
          0.9837591648101807,
          0.9834308624267578,
          0.9831578135490417,
          0.9828445911407471,
          0.982767641544342,
          0.9816997647285461,
          0.9816309809684753,
          0.9814714193344116,
          0.9813077449798584,
          0.9812398552894592,
          0.980820894241333,
          0.9808002710342407,
          0.9792070388793945,
          0.9786505699157715,
          0.9784801006317139,
          0.9780117273330688,
          0.976127028465271,
          0.9739737510681152,
          0.973640501499176,
          0.9732806086540222,
          0.9730440378189087,
          0.9725306630134583,
          0.9713912010192871,
          0.9708412289619446,
          0.9703091382980347,
          0.9689422845840454,
          0.9688480496406555,
          0.9682363271713257,
          0.9656850695610046,
          0.9656009674072266,
          0.9654781222343445,
          0.9648696780204773,
          0.9642261862754822,
          0.9640520215034485,
          0.9637997150421143,
          0.9636942744255066,
          0.9612652659416199,
          0.9610975980758667,
          0.9609953165054321,
          0.9604058265686035,
          0.9604016542434692,
          0.959887683391571,
          0.959317147731781,
          0.957449197769165,
          0.9550777077674866,
          0.9542221426963806,
          0.9530378580093384,
          0.9514305591583252,
          0.9504275918006897,
          0.9481307864189148,
          0.9465116262435913,
          0.9438895583152771,
          0.94354248046875,
          0.9430252909660339,
          0.9409622550010681,
          0.9363932013511658,
          0.9349582195281982,
          0.9343488216400146,
          0.9309802651405334,
          0.9295868277549744,
          0.9286901354789734,
          0.926142692565918,
          0.9259549975395203,
          0.9250098466873169,
          0.9228171110153198,
          0.920828640460968,
          0.9202096462249756,
          0.9200007319450378,
          0.919039249420166,
          0.9155425429344177,
          0.9144245386123657,
          0.912155032157898,
          0.9118546843528748,
          0.9093525409698486,
          0.9083677530288696,
          0.9066884517669678,
          0.9059000015258789,
          0.9008910059928894,
          0.9001613259315491,
          0.8976922035217285,
          0.897132158279419,
          0.8931971788406372,
          0.8881685137748718,
          0.8879969716072083,
          0.8878186941146851,
          0.8876444697380066,
          0.8840207457542419,
          0.8834477066993713,
          0.875599205493927,
          0.8738871812820435,
          0.8670052886009216,
          0.8663293123245239,
          0.8611137270927429,
          0.8518984913825989,
          0.8495848774909973,
          0.8491036891937256,
          0.8457769751548767,
          0.8438421487808228,
          0.8428676128387451,
          0.8311821818351746,
          0.8281989693641663,
          0.8193538784980774,
          0.818983256816864,
          0.8141713738441467,
          0.8091391921043396,
          0.7988211512565613,
          0.7983570098876953,
          0.7934920191764832,
          0.7909066081047058,
          0.7864382266998291,
          0.7849968075752258,
          0.7840238213539124,
          0.7824742794036865,
          0.7777673602104187,
          0.7571729421615601,
          0.7537415623664856,
          0.748048722743988,
          0.7374938726425171,
          0.7353240847587585,
          0.7352486848831177,
          0.7337355613708496,
          0.7337126135826111,
          0.7333285212516785,
          0.7265742421150208,
          0.7195656299591064,
          0.7183595895767212,
          0.7085641026496887,
          0.7048453688621521,
          0.70458984375,
          0.7022945880889893,
          0.7020467519760132,
          0.6942466497421265,
          0.6803126335144043,
          0.6751265525817871,
          0.6707139015197754,
          0.666725218296051,
          0.6638181805610657,
          0.6609214544296265,
          0.6518456339836121,
          0.6438744068145752,
          0.6433890461921692,
          0.6401860117912292,
          0.6363226175308228,
          0.6333832144737244,
          0.6292522549629211,
          0.6245168447494507,
          0.6238122582435608,
          0.6195918917655945,
          0.6173608899116516,
          0.6125653982162476,
          0.6124536991119385,
          0.6060276627540588,
          0.6059358716011047,
          0.5989881157875061,
          0.5839217305183411,
          0.5766093134880066,
          0.574424147605896,
          0.5721049904823303,
          0.5701535940170288,
          0.5659116506576538,
          0.5488430261611938,
          0.5484369397163391,
          0.5415533781051636,
          0.5323077440261841,
          0.5302502512931824,
          0.5292189121246338,
          0.5270384550094604,
          0.5226300358772278,
          0.513407826423645,
          0.5099465847015381,
          0.5092987418174744,
          0.5069387555122375,
          0.5056040287017822,
          0.5034262537956238,
          0.49628058075904846,
          0.4961361289024353,
          0.4871143698692322,
          0.48523202538490295,
          0.47708064317703247,
          0.4694170653820038,
          0.4643959701061249,
          0.4516330063343048,
          0.42572811245918274,
          0.40667492151260376,
          0.4013969600200653,
          0.3936571180820465,
          0.3857641816139221,
          0.3824201822280884,
          0.379609078168869,
          0.3763680160045624,
          0.3715333044528961,
          0.36014944314956665,
          0.3584304451942444,
          0.3580280840396881,
          0.3573944568634033,
          0.3567129373550415,
          0.31635841727256775,
          0.2959842383861542,
          0.29299184679985046,
          0.2859452962875366,
          0.28007972240448,
          0.2780827581882477,
          0.2735574245452881,
          0.2594625651836395,
          0.25102758407592773,
          0.2504742443561554,
          0.24943821132183075,
          0.2449730485677719,
          0.2430475950241089,
          0.2390836924314499,
          0.2379925698041916,
          0.23447737097740173,
          0.2213192582130432,
          0.20381425321102142,
          0.20013856887817383,
          0.19923783838748932,
          0.18749529123306274,
          0.18396566808223724,
          0.17948806285858154,
          0.1783984750509262,
          0.1756390482187271,
          0.17530424892902374,
          0.16990509629249573,
          0.16888168454170227,
          0.16737446188926697,
          0.16707128286361694,
          0.16464821994304657,
          0.16396848857402802,
          0.15966352820396423,
          0.1572287678718567,
          0.15351015329360962,
          0.1517283022403717,
          0.14645983278751373,
          0.14598660171031952,
          0.14551794528961182,
          0.14332188665866852,
          0.1421688348054886,
          0.1348278820514679,
          0.1342506855726242,
          0.1334887593984604,
          0.1313025951385498,
          0.1309894174337387,
          0.13031533360481262,
          0.12894125282764435,
          0.1273098737001419,
          0.12282109260559082,
          0.12194590270519257,
          0.11778677254915237,
          0.11759697645902634,
          0.11536408215761185,
          0.11465631425380707,
          0.11312974989414215,
          0.11003685742616653,
          0.10864660888910294,
          0.10678128898143768,
          0.10615343600511551,
          0.10601676255464554,
          0.10489862412214279,
          0.10394749790430069,
          0.1038413792848587,
          0.0967298075556755,
          0.09575791656970978,
          0.09565915167331696,
          0.09434152394533157,
          0.09426458925008774,
          0.08462311327457428,
          0.08126107603311539,
          0.07567427307367325,
          0.07531524449586868,
          0.07431930303573608,
          0.0729498565196991,
          0.07113274931907654,
          0.07073504477739334,
          0.0699622854590416,
          0.06982965767383575,
          0.06925425678491592,
          0.06871701031923294,
          0.06792037189006805,
          0.06389185786247253,
          0.06368840485811234,
          0.06313332170248032,
          0.06158530339598656,
          0.06048214063048363,
          0.06031850352883339,
          0.060123879462480545,
          0.05975663661956787,
          0.059015803039073944,
          0.057320158928632736,
          0.05639494210481644,
          0.05623670667409897,
          0.054982490837574005,
          0.054941464215517044,
          0.054788295179605484,
          0.054413314908742905,
          0.053287241607904434,
          0.052983447909355164,
          0.05228433385491371,
          0.05141155421733856,
          0.05138491466641426,
          0.05137389898300171,
          0.049340762197971344,
          0.04888800159096718,
          0.048789892345666885,
          0.048396334052085876,
          0.047764092683792114,
          0.047696202993392944,
          0.04694157838821411,
          0.04684501141309738,
          0.04675805941224098,
          0.04625746235251427,
          0.04548005014657974,
          0.04488801583647728,
          0.04415644705295563,
          0.042258113622665405,
          0.04182123392820358,
          0.039330508559942245,
          0.038592156022787094,
          0.037797555327415466,
          0.03714289888739586,
          0.036990392953157425,
          0.03663453087210655,
          0.03631512075662613,
          0.03104652836918831,
          0.02926904894411564,
          0.02849397249519825,
          0.028330648317933083,
          0.02798306755721569,
          0.026481185108423233,
          0.02583986707031727,
          0.025525806471705437,
          0.02525363862514496,
          0.024758026003837585,
          0.024574600160121918,
          0.023571955040097237,
          0.02342882938683033,
          0.023400386795401573,
          0.021789513528347015,
          0.021547716110944748,
          0.021239064633846283,
          0.02043476141989231,
          0.019955946132540703,
          0.019891029223799706,
          0.019349893555045128,
          0.019213352352380753,
          0.0191644374281168,
          0.01860804297029972,
          0.018320729956030846,
          0.017986560240387917,
          0.017271729186177254,
          0.016973458230495453,
          0.016924168914556503,
          0.016790464520454407,
          0.01589440181851387,
          0.01502710860222578,
          0.014930028468370438,
          0.014914531260728836,
          0.014490329660475254,
          0.014421138912439346,
          0.013969989493489265,
          0.013849854469299316,
          0.013789488933980465,
          0.013636860996484756,
          0.013310485519468784,
          0.012690058909356594,
          0.012440311722457409,
          0.012394753284752369,
          0.012371502816677094,
          0.01219581626355648,
          0.012028185650706291,
          0.011623452417552471,
          0.011443432420492172,
          0.011267104186117649,
          0.011244656518101692,
          0.011234523728489876,
          0.011016729287803173,
          0.010843946598470211,
          0.010709363035857677,
          0.010595058090984821,
          0.01030055433511734,
          0.009992944076657295,
          0.009746039286255836,
          0.009713511914014816,
          0.009703806601464748,
          0.009703806601464748,
          0.009566444903612137,
          0.009515751153230667,
          0.009510328061878681,
          0.009271305985748768,
          0.009157608263194561,
          0.009136422537267208,
          0.009106366895139217,
          0.009049040265381336,
          0.008855612948536873,
          0.008813158608973026,
          0.008808056823909283,
          0.008700566366314888,
          0.00867671612650156,
          0.00866074301302433,
          0.008589574135839939,
          0.008508216589689255,
          0.008484706282615662,
          0.008472030982375145,
          0.008252250961959362,
          0.008180462755262852,
          0.007812551222741604,
          0.007713856641203165,
          0.007594522554427385,
          0.0072542838752269745,
          0.007192551624029875,
          0.007098034955561161,
          0.006974632851779461,
          0.006685446482151747,
          0.006629260256886482,
          0.006332051008939743,
          0.006321683991700411,
          0.006117378361523151,
          0.006045536138117313,
          0.005993369035422802,
          0.005764423869550228,
          0.005693568382412195,
          0.005635890178382397,
          0.005592088680714369,
          0.005486245267093182,
          0.005473179742693901,
          0.005415291991084814,
          0.005302885547280312,
          0.005236885976046324,
          0.005230925511568785,
          0.005079297348856926,
          0.00506175821647048,
          0.0050603728741407394,
          0.0048646400682628155,
          0.004863667767494917,
          0.004762261640280485,
          0.004721740260720253,
          0.004690850153565407,
          0.004673282615840435,
          0.004600512329488993,
          0.004557816311717033,
          0.004394787363708019,
          0.0043377336114645,
          0.00421653687953949,
          0.004082945641130209,
          0.004060629289597273,
          0.004047022201120853,
          0.004011998418718576,
          0.003950704354792833,
          0.003937482833862305,
          0.003917743917554617,
          0.003912096843123436,
          0.0038821378257125616,
          0.0036582075990736485,
          0.0036400400567799807,
          0.003602632088586688,
          0.003594695357605815,
          0.0035722400061786175,
          0.0035166977904736996,
          0.003474913537502289,
          0.00331453257240355,
          0.003174867480993271,
          0.0031187778804451227,
          0.003112226026132703,
          0.0031073461286723614,
          0.002993011148646474,
          0.0029537260998040438,
          0.00285548297688365,
          0.0028357207775115967,
          0.00276480452157557,
          0.0027276885230094194,
          0.0026966084260493517,
          0.0026447351556271315,
          0.0024935994297266006,
          0.0024792419280856848,
          0.002429533749818802,
          0.0023895646445453167,
          0.0023549092002213,
          0.0023447535932064056,
          0.0023298563901335,
          0.002289661904796958,
          0.002220843220129609,
          0.002192119602113962,
          0.002170801628381014,
          0.0021559924352914095,
          0.0021366411820054054,
          0.0021356348879635334,
          0.002118305303156376,
          0.002111109672114253,
          0.0020946247968822718,
          0.0020782353822141886,
          0.00205420795828104,
          0.0020482020918279886,
          0.0019896612502634525,
          0.0019856065046042204,
          0.0019681875128299,
          0.0019673260394483805,
          0.001963499467819929,
          0.0019611071329563856,
          0.0019478887552395463,
          0.0019189926097169518,
          0.0018887267215177417,
          0.001819297089241445,
          0.001807098276913166,
          0.0017961416160687804,
          0.0017751473933458328,
          0.0017742450581863523,
          0.001765163615345955,
          0.0017549828626215458,
          0.00174798967782408,
          0.0017247069627046585,
          0.001705236965790391,
          0.0016637468943372369,
          0.0016533115413039923,
          0.0016256821108981967,
          0.0016079397173598409,
          0.001582328462973237,
          0.0015732222236692905,
          0.0015635475283488631,
          0.0015566799556836486,
          0.0015566799556836486,
          0.0015516135608777404,
          0.0015481248265132308,
          0.001511106383986771,
          0.0014730611583217978,
          0.0014501404948532581,
          0.0014462362742051482,
          0.001444056280888617,
          0.001420587650500238,
          0.0014078679960221052,
          0.0013852674746885896,
          0.001364760217256844,
          0.0013515892205759883,
          0.0013348642969503999,
          0.0013279395643621683,
          0.001278479816392064,
          0.0012683076784014702,
          0.0012613143771886826,
          0.0012397445971146226,
          0.001221745042130351,
          0.001195930177345872,
          0.0011853628093376756,
          0.0011806660331785679,
          0.0011653512483462691,
          0.0011568812187761068,
          0.0011054370552301407,
          0.0011032473994418979,
          0.0010945543181151152,
          0.0010859252652153373,
          0.0010599191300570965,
          0.0010521931108087301,
          0.0010311901569366455,
          0.0010292042279615998,
          0.0010291335638612509,
          0.0010165335843339562,
          0.00100375444162637,
          0.0009777434170246124,
          0.0009737506043165922,
          0.0009708729921840131,
          0.0009692356688901782,
          0.0009601859492249787,
          0.0009388278122060001,
          0.0009280611993744969,
          0.000927657529246062,
          0.0009259431972168386,
          0.0009133971179835498,
          0.0009120478644035757,
          0.0009101033792831004,
          0.0008964579319581389,
          0.000892596784979105,
          0.0008659392478875816,
          0.0008657462312839925,
          0.000861321110278368,
          0.0008548838668502867,
          0.000832998426631093,
          0.0008294133003801107,
          0.0008215678972192109,
          0.000807925418484956,
          0.0007905933889560401,
          0.0007887505344115198,
          0.0007425991352647543,
          0.0007423101924359798,
          0.000733855355065316,
          0.000729132501874119,
          0.0007006386877037585,
          0.00069652363890782,
          0.0006922780303284526,
          0.0006853920640423894,
          0.0006815447704866529,
          0.0006789361359551549,
          0.0006598517065867782,
          0.0006518569425679743,
          0.0006300029344856739,
          0.0006257676286622882,
          0.00061282969545573,
          0.0006084414781071246,
          0.0006039899890311062,
          0.0006037749699316919,
          0.000602980493567884,
          0.0005903085693717003,
          0.0005880463868379593,
          0.0005783287342637777,
          0.0005781857180409133,
          0.0005756323807872832,
          0.0005691866972483695,
          0.000559578649699688,
          0.0005539133562706411,
          0.0005533116054721177,
          0.000549259246326983,
          0.000543715781532228,
          0.0005405332776717842,
          0.0005397033528424799,
          0.0005389482248574495,
          0.0005337302573025227,
          0.000526632706169039,
          0.0005169592332094908,
          0.0005150052020326257,
          0.0005145498435012996,
          0.0005117152468301356,
          0.0005027553997933865,
          0.0005020102835260332,
          0.0005017734365537763,
          0.0005008961306884885,
          0.0004940227372571826,
          0.000489547208417207,
          0.0004825807991437614,
          0.000482132047181949,
          0.0004810846585314721,
          0.00048102662549354136,
          0.0004781345196533948,
          0.00047684917808510363,
          0.0004709947679657489,
          0.0004672088543884456,
          0.0004670924390666187,
          0.00046645483234897256,
          0.0004645450389944017,
          0.0004641832201741636,
          0.00045763797243125737,
          0.0004468869010452181,
          0.0004453170986380428,
          0.0004438566684257239,
          0.0004435392329469323,
          0.00043997442116960883,
          0.00043788584298454225,
          0.00043484181514941156,
          0.00042973144445568323,
          0.0004296460247132927,
          0.00042959998245351017,
          0.00042902870336547494,
          0.0004281829169485718,
          0.00042816848144866526,
          0.00042728890548460186,
          0.00042676361044868827,
          0.00042525454773567617,
          0.00041842437349259853,
          0.0004110845911782235,
          0.0004059425846207887,
          0.00040425173938274384,
          0.0004019463376607746,
          0.0004009830881841481,
          0.0004005148948635906,
          0.0003935924614779651,
          0.0003911749226972461,
          0.0003907623759005219,
          0.00038895002217032015,
          0.00038663280429318547,
          0.00038642596337012947,
          0.0003844549646601081,
          0.0003812754002865404,
          0.0003682742244563997,
          0.0003647407575044781,
          0.00036467189784161747,
          0.0003643479140009731,
          0.00035828768159262836,
          0.00035158524406142533,
          0.0003497091820463538,
          0.00034577480982989073,
          0.00034368346678093076,
          0.000340066704666242,
          0.00033960340078920126,
          0.00033190171234309673,
          0.0003291897301096469,
          0.0003271579626016319,
          0.00032588758040219545,
          0.00032465215190313756,
          0.0003231329028494656,
          0.00031635971390642226,
          0.0003122857597190887,
          0.0003120943729300052,
          0.00031089759431779385,
          0.00030543713364750147,
          0.00030306007829494774,
          0.0002992800436913967,
          0.0002981079451274127,
          0.0002948786714114249,
          0.0002940499398391694,
          0.0002938444958999753,
          0.0002936607925221324,
          0.000292701501166448,
          0.0002877253864426166,
          0.00028553479933179915,
          0.00028394805849529803,
          0.00028355850372463465,
          0.0002828286960721016,
          0.00028110682615078986,
          0.00027969107031822205,
          0.00027854941436089575,
          0.000276920385658741,
          0.00027687367401085794,
          0.00027684541419148445,
          0.00027254829183220863,
          0.000270182266831398,
          0.00026990805054083467,
          0.0002687889209482819,
          0.0002647959627211094,
          0.0002645920612849295,
          0.00026105789584107697,
          0.00026090533356182277,
          0.00025984359672293067,
          0.00025959350750781596,
          0.0002592118689790368,
          0.0002566151670180261,
          0.00025592249585315585,
          0.0002534677041694522,
          0.00025310326600447297,
          0.00025212590117007494,
          0.00025048511452041566,
          0.0002491021004971117,
          0.00024859554832801223,
          0.00024718549684621394,
          0.00024623682838864625,
          0.00024606785154901445,
          0.0002447281440254301,
          0.0002438637602608651,
          0.00024355541972909123,
          0.00024273127201013267,
          0.00024254390154965222,
          0.0002418469957774505,
          0.0002417992800474167,
          0.0002399960212642327,
          0.00023936100478749722,
          0.0002392745082033798,
          0.000238577660638839,
          0.00023548872559331357,
          0.00023321743356063962,
          0.00022928405087441206,
          0.00022657995577901602,
          0.00022514010197483003,
          0.0002230889949714765,
          0.0002226168435299769,
          0.0002217121364083141,
          0.0002204194461228326,
          0.00021857337560504675,
          0.00021789981110487133,
          0.00021734619804192334,
          0.0002166758058592677,
          0.00021584630303550512,
          0.0002153685491066426,
          0.0002151936641894281,
          0.00021509212092496455,
          0.0002147234627045691,
          0.00021245544485282153,
          0.00021242423099465668,
          0.00020918702648486942,
          0.0002065591252176091,
          0.00020170473726466298,
          0.00020047035650350153,
          0.00019905783119611442,
          0.00019737104594241828,
          0.00019585613335948437,
          0.00019573404279071838,
          0.00019333498494233936,
          0.00019236722437199205,
          0.00019152952881995589,
          0.00018908931815531105,
          0.000188254241948016,
          0.00018808343156706542,
          0.00018761843966785818,
          0.000187445359188132,
          0.00018652607104741037,
          0.00018342900148127228,
          0.00018321085372008383,
          0.00018219678895547986,
          0.0001819584285840392,
          0.0001812439877539873,
          0.0001797172153601423,
          0.00017808731354307383,
          0.00017537160601932555,
          0.00017421577649656683,
          0.00017390077118761837,
          0.0001737335551297292,
          0.00017304909124504775,
          0.00017303405911661685,
          0.00017269073578063399,
          0.00017043895786628127,
          0.00016962589870672673,
          0.0001695146638667211,
          0.0001692638179520145,
          0.00016890234837774187,
          0.0001681745343375951,
          0.00016784388571977615,
          0.00016722804866731167,
          0.00016720542043913156,
          0.00016685915761627257,
          0.0001655124215176329,
          0.0001648398902034387,
          0.00016471011622343212,
          0.00016399456944782287,
          0.00016273671644739807,
          0.00016216188669204712,
          0.00016148790018633008,
          0.00015978967712726444,
          0.0001597840600879863,
          0.00015853717923164368,
          0.00015778116357978433,
          0.00015672226436436176,
          0.000156591268023476,
          0.00015578288002870977,
          0.00015535314742010087,
          0.00015476411499548703,
          0.0001537071366328746,
          0.00015168839308898896,
          0.00015146826626732945,
          0.00015110603999346495,
          0.00014990600175224245,
          0.00014975099475122988,
          0.00014793068112339824,
          0.00014768629625905305,
          0.00014580445713363588,
          0.00014542510325554758,
          0.00014465421554632485,
          0.00014397705672308803,
          0.00014140448183752596,
          0.00014128048496786505,
          0.00013885799853596836,
          0.00013878228492103517,
          0.00013869178656022996,
          0.00013737808330915868,
          0.00013726181350648403,
          0.0001370589598082006,
          0.00013673574721906334,
          0.000134984016767703,
          0.0001342805044259876,
          0.00013425144425127655,
          0.00013405444042291492,
          0.00013404511264525354,
          0.00013331980153452605,
          0.00013310398207977414,
          0.00013280517305247486,
          0.000132773129735142,
          0.00013251650671008974,
          0.0001318748836638406,
          0.00013170095917303115,
          0.0001299560972256586,
          0.0001295638649025932,
          0.00012905178300570697,
          0.00012810429325327277,
          0.00012774200877174735,
          0.00012758959201164544,
          0.00012756332580465823,
          0.0001266389444936067,
          0.0001261321740457788,
          0.00012556480942294002,
          0.00012552397674880922,
          0.00012486285413615406,
          0.00012411405623424798,
          0.0001239806297235191,
          0.00012389401672407985,
          0.00012345801224000752,
          0.00012320117093622684,
          0.00012046477786498144,
          0.00012014497042400762,
          0.0001199385806103237,
          0.0001198199242935516,
          0.00011906525469385087,
          0.00011757315951399505,
          0.00011737713793991134,
          0.00011630664812400937,
          0.00011629644723143429,
          0.00011569571506697685,
          0.0001151061151176691,
          0.0001148234005086124,
          0.0001137474610004574,
          0.00011357045877957717,
          0.0001134493577410467,
          0.00011229427036596462,
          0.00011181215813849121,
          0.00011107180034741759,
          0.0001109758741222322,
          0.00011011612514266744,
          0.00010943457164103165,
          0.000109028973383829,
          0.00010652399942046031,
          0.00010628597374306992,
          0.00010625465074554086,
          0.0001048389749485068,
          0.00010465179366292432,
          0.00010447949898662046,
          0.00010345173359382898,
          0.00010269520862493664,
          0.00010234687943011522,
          0.00010231936175841838,
          0.00010177075455430895,
          0.00010118965292349458,
          0.00010115540499100462,
          0.00010083845700137317,
          0.00010068501433124766,
          0.00009809894254431129,
          0.00009726684947963804,
          0.00009716505883261561,
          0.00009705884440336376,
          0.0000963510901783593,
          0.000096270909125451,
          0.00009560782200424,
          0.0000950356261455454,
          0.00009487526403972879,
          0.00009458575368626043,
          0.00009340663382317871,
          0.00009251160372514278,
          0.00009245321416528895,
          0.00009234448953066021,
          0.00009221671643899754,
          0.00009217327897204086,
          0.00009099985618377104,
          0.00009041807061294094,
          0.00008979588892543688,
          0.00008937677921494469,
          0.00008892280311556533,
          0.00008883882401278242,
          0.00008877733489498496,
          0.00008871209138305858,
          0.00008867732685757801,
          0.00008867707219906151,
          0.00008858976070769131,
          0.00008848262950778008,
          0.00008832701132632792,
          0.00008808761776890606,
          0.00008799861825536937,
          0.00008771092689130455,
          0.00008762365177972242,
          0.00008716313459444791,
          0.00008699291356606409,
          0.00008686639921506867,
          0.00008603641617810354,
          0.00008567226177547127,
          0.00008552957297069952,
          0.0000855153048178181,
          0.00008546996832592413,
          0.00008431865717284381,
          0.00008405308471992612,
          0.00008404691470786929,
          0.00008338447514688596,
          0.0000833697704365477,
          0.00008302038622787222,
          0.00008300424087792635,
          0.00008283241913886741,
          0.00008190596417989582,
          0.00008184881880879402,
          0.00008150486974045634,
          0.00008082307613221928,
          0.00008074549987213686,
          0.00008020547102205455,
          0.00008019140659598634,
          0.00008010465535335243,
          0.00008009548764675856,
          0.00008003493712749332,
          0.00007951680163387209,
          0.00007942040974739939,
          0.00007709286728641018,
          0.0000766465236665681,
          0.00007655309309484437,
          0.00007654856744920835,
          0.00007620938413310796,
          0.00007601732795592397,
          0.00007557102071586996,
          0.00007543781248386949,
          0.00007540746446466073,
          0.00007466843817383051,
          0.00007462166831828654,
          0.00007452288991771638,
          0.00007409969839500263,
          0.00007400704635074362,
          0.00007357302820309997,
          0.00007302523590624332,
          0.00007277351687662303,
          0.00007264316809596494,
          0.0000722515833331272,
          0.00007134828774724156,
          0.00007126981654437259,
          0.00007076865585986525,
          0.00007051032298477367,
          0.00007019299664534628,
          0.00007000168989179656,
          0.00006999447214184329,
          0.00006989776011323556,
          0.00006979864701861516,
          0.00006971097900532186,
          0.00006970446702325717,
          0.00006955924618523568,
          0.00006953132105991244,
          0.00006951852992642671,
          0.00006939784361748025,
          0.00006927545473445207,
          0.00006905654299771413,
          0.00006901355664012954,
          0.00006881935405544937,
          0.0000688154177623801,
          0.00006864069291623309,
          0.00006843865412520245,
          0.00006739375385222957,
          0.00006719346856698394,
          0.00006647716509178281,
          0.00006640196079388261,
          0.00006631621363339946,
          0.00006599353218916804,
          0.00006597383617190644,
          0.00006596496677957475,
          0.00006557416782015935,
          0.00006555247091455385,
          0.00006548505916725844,
          0.00006531902909046039,
          0.00006529866368509829,
          0.0000652619419270195,
          0.00006507202488137409,
          0.00006507202488137409,
          0.00006505985948024318,
          0.00006479622243205085,
          0.000064466854382772,
          0.00006441056757466868,
          0.00006427086191251874,
          0.00006398723053280264,
          0.00006393922376446426,
          0.00006382390711223707,
          0.00006378788384608924,
          0.00006376623059622943,
          0.00006368000322254375,
          0.00006366604065988213,
          0.000063439438235946,
          0.0000630658250884153,
          0.00006280649540713057,
          0.00006276817293837667,
          0.00006234955799300224,
          0.00006220168870640919,
          0.00006218864291440696,
          0.00006174520967761055,
          0.00006170653796289116,
          0.00006169565313030034,
          0.00006114152347436175,
          0.000060987389588262886,
          0.00006070232484489679,
          0.00006069977462175302,
          0.000060685884818667546,
          0.00006066360947443172,
          0.000060657188441837206,
          0.00006059053339413367,
          0.00006049371586414054,
          0.0000604703527642414,
          0.00006035196565790102,
          0.00006034649413777515,
          0.00006018753265379928,
          0.00005998412234475836,
          0.000059964902902720496,
          0.00005915842120884918,
          0.000058858106058323756,
          0.000058792247727978975,
          0.00005875777787878178,
          0.000058752182667376474,
          0.00005861831232323311,
          0.00005831633825437166,
          0.00005827036875416525,
          0.000058178531617159024,
          0.000057957371609518304,
          0.000057945762819144875,
          0.00005790184877696447,
          0.000057203629694413394,
          0.00005711511039407924,
          0.00005704754948965274,
          0.00005698247332475148,
          0.000056412984122289345,
          0.000056198041420429945,
          0.00005615159898297861,
          0.00005609004801954143,
          0.000055879172577988356,
          0.00005587863415712491,
          0.000055866916227387264,
          0.00005578136187978089,
          0.000055666845582891256,
          0.00005544042869587429,
          0.00005541183054447174,
          0.00005528515248443,
          0.00005519607293535955,
          0.00005489351678988896,
          0.000054832406021887437,
          0.00005475773650687188,
          0.00005473314377013594,
          0.00005457699080579914,
          0.00005440385211841203,
          0.000054354113672161475,
          0.00005433639307739213,
          0.00005420096204034053,
          0.000054157560953171924,
          0.00005414759289124049,
          0.0000538899730599951,
          0.00005375293767428957,
          0.000053734591347165406,
          0.000053525927796727046,
          0.0000533389720658306,
          0.000053040468628751114,
          0.00005294420043355785,
          0.000052867719205096364,
          0.00005271950431051664,
          0.000052669951401185244,
          0.00005265157233225182,
          0.000052597573812818155,
          0.00005225346103543416,
          0.00005215444616624154,
          0.00005213952681515366,
          0.00005209141818340868,
          0.00005203566252021119,
          0.00005176054037292488,
          0.00005172313831280917,
          0.000051685026846826077,
          0.00005168044299352914,
          0.00005151973164174706,
          0.0000514449602633249,
          0.00005118413901072927,
          0.00005107209653942846,
          0.000050986789574380964,
          0.0000509716228407342,
          0.000050804104830604047,
          0.0000507160002598539,
          0.00005069520921097137,
          0.00005068820246378891,
          0.00005067674646852538,
          0.00005061738920630887,
          0.00005039395909989253,
          0.00005021937977289781,
          0.000050170889153378084,
          0.00005011274333810434,
          0.00005009716915083118,
          0.00004996925054001622,
          0.00004996143979951739,
          0.0000498113440698944,
          0.00004979918958269991,
          0.00004973179238731973,
          0.00004972914030076936,
          0.000049721413233783096,
          0.00004959534635418095,
          0.00004949641152052209,
          0.0000494763080496341,
          0.00004931012881570496,
          0.00004925251050735824,
          0.000049233400204684585,
          0.00004922274092677981,
          0.0000491663085995242,
          0.00004916129182674922,
          0.0000491434293508064,
          0.000049140147893922403,
          0.00004910646748612635,
          0.000049064015911426395,
          0.0000489906597067602,
          0.00004892870128969662,
          0.00004892487413599156,
          0.0000489169433421921,
          0.00004889464980806224,
          0.00004878543404629454,
          0.000048783149395603687,
          0.00004877184983342886,
          0.000048736328608356416,
          0.00004872331555816345,
          0.000048690708354115486,
          0.00004860910485149361,
          0.00004859172258875333,
          0.000048509402404306456,
          0.00004844708746531978,
          0.00004841581903747283,
          0.00004840838664676994,
          0.00004837123560719192,
          0.00004835181971429847,
          0.00004835149593418464,
          0.00004830435136682354,
          0.000048301455535693094,
          0.000048259324103128165,
          0.00004824165444006212,
          0.00004820642789127305,
          0.000048196267016464844,
          0.000048193738621193916,
          0.00004814982457901351,
          0.00004814977728528902,
          0.000048146106564672664,
          0.00004814372005057521,
          0.00004814151179743931,
          0.000048111865908140317,
          0.000048107915063155815,
          0.000048096131649799645,
          0.000048051526391645893,
          0.00004800087117473595,
          0.000047950590669643134,
          0.000047911373258102685,
          0.000047855708544375375,
          0.00004783873737324029,
          0.00004783667827723548,
          0.00004780758172273636,
          0.000047801520850043744,
          0.000047751131205586717,
          0.000047670873755123466,
          0.00004766009806189686,
          0.0000476234381494578,
          0.000047618214011890814,
          0.00004755422560265288,
          0.00004751764936372638,
          0.00004750980588141829,
          0.000047490331780863926,
          0.000047435019951080903,
          0.000047379729949170724,
          0.00004736937989946455,
          0.000047349192755063996,
          0.000047331857786048204,
          0.00004725126927951351,
          0.000047197270760079846,
          0.00004717301999335177,
          0.00004707055995822884,
          0.000047061763325473294,
          0.000047055393224582076,
          0.000047052431909833103,
          0.000047037268814165145,
          0.000046982353524072096,
          0.00004697778422269039,
          0.000046953908167779446,
          0.00004693537266575731,
          0.00004690620335168205,
          0.00004689797424362041,
          0.000046896766434656456,
          0.0000468854523205664,
          0.000046814722736598924,
          0.00004681325299316086,
          0.0000467310928797815,
          0.00004671376518672332,
          0.00004670997441280633,
          0.00004670890484703705,
          0.000046691271563759074,
          0.000046681387175340205,
          0.000046678134822286665,
          0.00004667337270802818,
          0.00004666821041610092,
          0.000046594836021540686,
          0.00004659035039367154,
          0.00004658563921111636,
          0.000046556859160773456,
          0.000046518071030732244,
          0.00004649305992643349,
          0.00004647231617127545,
          0.00004645322042051703,
          0.00004640588667825796,
          0.00004638177415472455,
          0.000046371915232157335,
          0.00004635329605662264,
          0.00004633305434253998,
          0.00004630549665307626,
          0.000046219865907914937,
          0.00004620924300979823,
          0.00004620743857230991,
          0.00004620289837475866,
          0.00004619836181518622,
          0.000046151464630384,
          0.000046143188228597865,
          0.000046099907194729894,
          0.0000460971386928577,
          0.00004606383299687877,
          0.000046054123231442645,
          0.000046005574404262006,
          0.00004593753328663297,
          0.000045929260522825643,
          0.00004592461118591018,
          0.00004590000753523782,
          0.00004586657814797945,
          0.00004583776535582729,
          0.00004581862231134437,
          0.000045777698687743396,
          0.00004577350409817882,
          0.000045759148633806035,
          0.000045758359192404896,
          0.000045742788643110543,
          0.00004573223122861236,
          0.00004570458986563608,
          0.00004568258373183198,
          0.00004565240669762716,
          0.00004563507900456898,
          0.000045621723984368145,
          0.00004561863170238212,
          0.000045601060264743865,
          0.00004559571243589744,
          0.00004559349690680392,
          0.000045588149077957496,
          0.000045587799831992015,
          0.00004558680302579887,
          0.00004558571527013555,
          0.000045567285269498825,
          0.000045540178689407185,
          0.00004547412390820682,
          0.00004546255149762146,
          0.000045439668610924855,
          0.00004538769644568674,
          0.00004535810148809105,
          0.00004528449790086597,
          0.000045175202103564516,
          0.00004451720087672584,
          0.000044121905375504866,
          0.0000436768532381393,
          0.00004345558045315556,
          0.00004344758053775877,
          0.00004326970156398602,
          0.000042950676288455725,
          0.00004256766987964511,
          0.00004245755553711206,
          0.00004221213748678565,
          0.00004210318729747087,
          0.00004192613414488733,
          0.00004186177466181107,
          0.000041751973185455427,
          0.00004170227475697175,
          0.000041492901800666004,
          0.00004127064312342554,
          0.00004093125244253315,
          0.00003995145016233437,
          0.00003970953184762038,
          0.00003949219535570592,
          0.0000381297868443653,
          0.00003788990215980448,
          0.000037776899262098595,
          0.00003771790215978399,
          0.00003771419869735837,
          0.000036874323996016756,
          0.00003664191535790451,
          0.00003658905188785866,
          0.00003650512371677905,
          0.00003622367512434721,
          0.00003612187720136717,
          0.00003590345659176819,
          0.000035777611628873274,
          0.00003567206658772193,
          0.000035402539651840925,
          0.00003515590287861414,
          0.00003492113319225609,
          0.00003491797178867273,
          0.00003489719529170543,
          0.00003483807813609019,
          0.00003468823342700489,
          0.000034656553907552734,
          0.00003417385232751258,
          0.0000340696242346894,
          0.000033983666071435437,
          0.000033875850931508467,
          0.000033872398489620537,
          0.0000331707633449696,
          0.000033099793654400855,
          0.000033099382562795654,
          0.00003202988227712922,
          0.000031927993404679,
          0.000031887069781078026,
          0.000031745705200592056,
          0.00003164423833368346,
          0.00003086173819610849,
          0.000030673545552417636,
          0.00002975906500068959,
          0.00002947090979432687,
          0.000029348289899644442,
          0.000029213169909780845,
          0.00002920765291491989,
          0.00002913268872362096,
          0.000029057437131996267,
          0.000028957851100130938,
          0.00002827050229825545,
          0.000028039728931616992,
          0.000027827894882648252,
          0.000027813382985186763,
          0.000027749347282224335,
          0.000027249150662100874,
          0.000027060421416535974,
          0.000026632238586898893,
          0.000026555520889814943,
          0.00002625739034556318,
          0.000026161083951592445,
          0.000026098417947650887,
          0.000026079109375132248,
          0.000025335404643556103,
          0.00002513788604119327,
          0.000025047002054634504,
          0.000024449707780149765,
          0.000024361823307117447,
          0.000024331895474460907,
          0.00002401324854872655,
          0.000023943961423356086,
          0.000023839358618715778,
          0.000023669435904594138,
          0.000023593624064233154,
          0.00002316071550012566,
          0.000023156475435825996,
          0.000023099855752661824,
          0.000023093447452993132,
          0.0000230208424909506,
          0.00002293297256983351,
          0.000022744163288734853,
          0.00002253710408695042,
          0.00002241291804239154,
          0.000022071213606977835,
          0.000021854290025657974,
          0.000021634854419971816,
          0.000021380094040068798,
          0.0000209568788704928,
          0.00002061876148218289,
          0.000020607163605745882,
          0.000020596711692633107,
          0.000020503270206972957,
          0.000020468340153456666,
          0.000020033596229040995,
          0.000019800181689788587,
          0.000019671764675877057,
          0.000019495817468850873,
          0.000019353052266524173,
          0.000019279403204564005,
          0.000019251752746640705,
          0.000019244593204348348,
          0.000019173499822500162,
          0.00001915836583066266,
          0.00001911562321765814,
          0.000018982085748575628,
          0.00001894951128633693,
          0.000018911923689302057,
          0.000018714606994763017,
          0.000018481010556570254,
          0.000018470314898877405,
          0.00001841126140789129,
          0.000018295253539690748,
          0.000018188611647929065,
          0.00001811203583201859,
          0.00001802460610633716,
          0.000017975460650632158,
          0.000017969032342080027,
          0.000017890037270262837,
          0.000017678463336778805,
          0.000017134987501776777,
          0.000017050144379027188,
          0.000017018028302118182,
          0.00001699070526228752,
          0.000016917349057621323,
          0.000016660746041452512,
          0.000016525465980521403,
          0.00001651990351092536,
          0.000016352048987755552,
          0.000016308784324792214,
          0.000016277475879178382,
          0.00001623614298296161,
          0.000016192212569876574,
          0.000016079206034191884,
          0.000016029445760068484,
          0.000015959296433720738,
          0.000015814714060979895,
          0.000015785617506480776,
          0.000015679454008932225,
          0.000015630141206202097,
          0.00001561701537866611,
          0.000015347373846452683,
          0.000015299909136956558,
          0.000015173131032497622,
          0.00001511103801021818,
          0.000015110533240658697,
          0.000014990370800660457,
          0.000014710069990542252,
          0.000014670100426883437,
          0.000014533606190525461,
          0.000014498416931019165,
          0.00001444084682589164,
          0.0000144287196235382,
          0.000014391532204172108,
          0.000014339309018396307,
          0.00001420865737600252,
          0.000013951845176052302,
          0.000013852119991497602,
          0.00001373060695186723,
          0.000013459952242556028,
          0.000013346230844035745,
          0.000013300261343829334,
          0.000013296913493832108,
          0.00001320656701864209,
          0.000013073038644506596,
          0.000013054524970357306,
          0.000013007438610657118,
          0.000013001696970604826,
          0.00001291977423534263,
          0.000012912852071167435,
          0.000012836739188060164,
          0.000012807781786250416,
          0.000012705761037068442,
          0.000012658146260946523,
          0.000012637605323106982,
          0.000012528215847851243,
          0.00001228736527991714,
          0.000012246257028891705,
          0.00001223365052283043,
          0.00001214331314258743,
          0.00001213863470184151,
          0.000012118496670154855,
          0.00001208253888762556,
          0.000012049997167196125,
          0.000011987026482529473,
          0.000011951493434025906,
          0.000011901799553015735,
          0.000011868974979734048,
          0.00001186023928312352,
          0.000011759138033085037,
          0.000011722836461558472,
          0.000011714813808794133,
          0.00001163058914244175,
          0.000011621375051618088,
          0.000011583148989302572,
          0.000011498379535623826,
          0.000011466667274362408,
          0.000011308075045235455,
          0.000011303071914881002,
          0.00001129760767071275,
          0.000011259413440711796,
          0.00001121326204156503,
          0.00001111151505028829,
          0.000011098637514805887,
          0.000010935453246929683,
          0.000010903192560363095,
          0.000010880797162826639,
          0.000010812557775352616,
          0.000010785750419017859,
          0.000010758690223156009,
          0.000010722318620537408,
          0.000010720212230808102,
          0.00001060961585608311,
          0.000010583129551378079,
          0.000010521673175389878,
          0.000010518281669646967,
          0.000010464294064149726,
          0.000010446556188981049,
          0.00001039833023241954,
          0.0000103542952274438,
          0.000010311626283510122,
          0.000010302209375367966,
          0.00001025364144879859,
          0.00001023463028104743,
          0.000010173023838433437,
          0.000010074834790430032,
          0.000010070079952129163,
          0.00001003966372081777,
          0.000009982009942177683,
          0.000009922254321281798,
          0.000009881064215733204,
          0.000009863515515462495,
          0.000009749848686624318,
          0.000009561171282257419,
          0.000009530755960440729,
          0.000009526594112685416,
          0.000009490585398452822,
          0.000009454442079004366,
          0.000009443106137041468,
          0.00000941907364904182,
          0.000009298895747633651,
          0.000009286028216592968,
          0.000009250937182514463,
          0.000009244552529708017,
          0.0000091549754870357,
          0.000009152086022368167,
          0.000009110303835768718,
          0.000009089720151678193,
          0.00000906776222109329,
          0.000009040278200700413,
          0.000009004656021716073,
          0.000009001290891319513,
          0.000008978853657026775,
          0.000008966284440248273,
          0.00000896329220267944,
          0.000008962718311522622,
          0.000008892488040146418,
          0.000008854559382598381,
          0.00000885382542037405,
          0.000008805693141766824,
          0.000008742709724174347,
          0.000008741700185055379,
          0.000008734167749935295,
          0.000008728505235922057,
          0.000008713077477295883,
          0.000008663785592943896,
          0.000008544218871975318,
          0.000008542125215171836,
          0.000008528084435965866,
          0.000008476005859847646,
          0.000008472086847177707,
          0.000008453193913737778,
          0.000008275493200926576,
          0.000008232710570155177,
          0.000008212957254727371,
          0.000008199386684282217,
          0.000008128971785481554,
          0.000008123508450808004,
          0.000008122570761770476,
          0.000008071059710346162,
          0.000008042938134167343,
          0.000008024603630474303,
          0.000008022438123589382,
          0.000007964692485984415,
          0.000007963538337207865,
          0.000007950970939418767,
          0.000007921771612018347,
          0.000007900601303845178,
          0.000007865628504077904,
          0.000007754525540804025,
          0.000007749564247205853,
          0.00000770215228840243,
          0.000007651599844393786,
          0.000007649709914403502,
          0.00000764465585234575,
          0.000007629157153132837,
          0.0000075996972555003595,
          0.000007551070211775368,
          0.00000751930156184244,
          0.0000074694921750051435,
          0.000007456858384102816,
          0.000007446107247233158,
          0.000007443338745360961,
          0.000007426237061736174,
          0.00000742023303246242,
          0.000007367581474682083,
          0.000007275957614183426,
          0.000007269396519404836,
          0.000007224756700452417,
          0.000007222311523946701,
          0.000007217608526843833,
          0.000007196885235316586,
          0.000007174052370828576,
          0.000007102187737473287,
          0.000007100311449903529,
          0.000007099031790858135,
          0.000007076198926370125,
          0.000007075787380017573,
          0.00000704321610101033,
          0.000007038603143882938,
          0.00000689509033691138,
          0.000006878356089146109,
          0.00000682367681292817,
          0.0000067927253439847846,
          0.000006790251518395962,
          0.000006720731562381843,
          0.000006711232799716527,
          0.000006666166882496327,
          0.0000066535849327920005,
          0.000006602354460483184,
          0.0000066016677919833455,
          0.000006590728389710421,
          0.000006554386800416978,
          0.000006487052360171219,
          0.000006461108569055796,
          0.000006419135388568975,
          0.000006417538315872662,
          0.000006417134500225075,
          0.000006355378900479991,
          0.000006236854915186996,
          0.000006231379302334972,
          0.000006211207164596999,
          0.000006184296580613591,
          0.000006176574970595539,
          0.000006156479685159866,
          0.000006013281108607771,
          0.000005963635885564145,
          0.000005904959834879264,
          0.000005903225883230334,
          0.0000058710779740067665,
          0.000005757522103522206,
          0.000005752675406256458,
          0.000005740941560361534,
          0.000005726407380279852,
          0.000005662473540724022,
          0.000005644035809382331,
          0.000005641667485178914,
          0.000005640882136503933,
          0.000005592374236584874,
          0.000005579589469562052,
          0.00000548036587133538,
          0.000005453083758766297,
          0.0000054187089517654385,
          0.000005378540208766935,
          0.000005356243946152972,
          0.000005217447778704809,
          0.000005073493412055541,
          0.000005025055997975869,
          0.000005001314548280789,
          0.0000049169866542797536,
          0.000004913864358968567,
          0.000004835256277146982,
          0.000004766816800838569,
          0.000004718147465609945,
          0.000004699264536611736,
          0.000004653947598853847,
          0.000004633828211808577,
          0.00000461800391349243,
          0.000004461616754269926,
          0.000004222442839818541,
          0.000004213336069369689
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Results (descending)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "prediction"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict(\n",
    "    index = list(range(len(results))),\n",
    "    prediction = [prediction for prediction, index in sorted(results, reverse=True)]\n",
    "))\n",
    "px.line(df, x='index', y='prediction', title=\"Results (descending)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
