{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements\n",
    "Make sure you're using the local conda env for running this notebook. If is not created yet, create one with python 3.9 by running `conda create --name myenv python=3.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (23.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (4.34.1)\n",
      "Requirement already satisfied: datasets in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (2.14.5)\n",
      "Requirement already satisfied: numpy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (1.26.1)\n",
      "Requirement already satisfied: pandas in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: tensorflow in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-metal in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.1.0)\n",
      "Collecting sentence-transformers (from -r ../requirements.txt (line 8))\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets->-r ../requirements.txt (line 2)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-metal->-r ../requirements.txt (line 7)) (0.41.2)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading torch-2.1.0-cp39-none-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Collecting torchvision (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading torchvision-0.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading scikit_learn-1.3.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading scipy-1.11.3-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting sentencepiece (from sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.0.0)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click (from nltk->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading Pillow-10.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.2.2)\n",
      "Downloading torch-2.1.0-cp39-none-macosx_11_0_arm64.whl (59.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.1-cp39-cp39-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp39-cp39-macosx_12_0_arm64.whl (29.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.16.0-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.1.0-cp39-cp39-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=fbd493c418a2b703f22aa5e05db61474baf2079b1271a3726047a2c01ffda852\n",
      "  Stored in directory: /Users/beto/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, mpmath, threadpoolctl, sympy, scipy, pillow, networkx, joblib, jinja2, click, torch, scikit-learn, nltk, torchvision, sentence-transformers\n",
      "Successfully installed click-8.1.7 jinja2-3.1.2 joblib-1.3.2 mpmath-1.3.0 networkx-3.2 nltk-3.8.1 pillow-10.1.0 scikit-learn-1.3.1 scipy-1.11.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.2.0 torch-2.1.0 torchvision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, load_from_disk, concatenate_datasets\n",
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "def load_from_cs_net(take: int) -> Dataset:\n",
    "  ds = load_dataset(dataset_name, 'python', split='train')\n",
    "  return Dataset.from_dict(ds[:take]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "comment_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "code_model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "embedding_shape = (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "random_generator = default_rng(seed=42)\n",
    "\n",
    "def generate_negative_samples(iterator: Iterator, negative_samples_per_sample: int):\n",
    "  for batched_sample in iterator:\n",
    "    codes_embeddings = batched_sample['code_embedding']\n",
    "    comments_embeddings = batched_sample['comment_embedding']\n",
    "    batch_indexes = range(len(codes_embeddings))\n",
    "\n",
    "    for index in batch_indexes:\n",
    "      indexes = [i for i in batch_indexes if i != index]\n",
    "      negative_indexes = random_generator.choice(indexes, negative_samples_per_sample, replace=False)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": codes_embeddings[index],\n",
    "        \"comment_embedding\": comments_embeddings[index],\n",
    "        \"target\": 1\n",
    "      }\n",
    "\n",
    "      for negative_index in negative_indexes:\n",
    "        yield {\n",
    "          \"code_embedding\": codes_embeddings[index],\n",
    "          \"comment_embedding\": comments_embeddings[negative_index],\n",
    "          \"target\": 0\n",
    "        }\n",
    "\n",
    "def with_neg_samples(dataset: Dataset, negative_samples_per_sample: int, batch_size = 100) -> Dataset:\n",
    "  assert negative_samples_per_sample <= batch_size, \"negative_samples_per_sample must not be greater than batch_size\"\n",
    "  if negative_samples_per_sample <= 0:\n",
    "    return dataset\n",
    "  \n",
    "  dataset_with_negative_samples: Dataset = Dataset.from_generator(lambda: generate_negative_samples(dataset.iter(batch_size=batch_size), negative_samples_per_sample)) # type: ignore\n",
    "  return dataset_with_negative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 8.44k/8.44k [00:00<00:00, 15.2MB/s]\n",
      "Downloading metadata: 100%|██████████| 18.5k/18.5k [00:00<00:00, 10.5MB/s]\n",
      "Downloading readme: 100%|██████████| 12.9k/12.9k [00:00<00:00, 11.0MB/s]\n",
      "Downloading data: 100%|██████████| 941M/941M [00:46<00:00, 20.0MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:48<00:00, 48.79s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Generating train split: 100%|██████████| 412178/412178 [01:00<00:00, 6766.82 examples/s]\n",
      "Generating test split: 100%|██████████| 22176/22176 [00:03<00:00, 6758.14 examples/s]\n",
      "Generating validation split: 100%|██████████| 23107/23107 [00:03<00:00, 6553.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_count = 2000\n",
    "train_dataset_path = f'../datasets/embeddings_python_train_{train_count}'\n",
    "train_pairs = load_from_cs_net(train_count)\n",
    "is_embeddings_dataset_stored = os.path.isdir(train_dataset_path)\n",
    "\n",
    "def generate_embeddings_in_batch(batched_sample):\n",
    "  codes = batched_sample['func_code_string']\n",
    "  comments = batched_sample['func_documentation_string']\n",
    "\n",
    "  return {\n",
    "    \"code_embedding\": code_model.encode(codes),\n",
    "    \"comment_embedding\": comment_model.encode(comments),\n",
    "  }\n",
    "\n",
    "embeddings_dataset: Dataset = Dataset.from_dict(load_from_disk(train_dataset_path)[:train_count]) if is_embeddings_dataset_stored else train_pairs.map(\n",
    "  generate_embeddings_in_batch, \n",
    "  batched=True, \n",
    "  batch_size=100,\n",
    "  remove_columns=list(train_pairs[0].keys()),\n",
    "  desc=\"Generating embeddings\"\n",
    ") # type: ignore\n",
    "\n",
    "if is_embeddings_dataset_stored == False:\n",
    "  embeddings_dataset.save_to_disk(train_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add negative samples to train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_dataset(negative_samples_per_sample: int):\n",
    "  tf_train_dataset = with_neg_samples(embeddings_dataset.shuffle(), negative_samples_per_sample).to_tf_dataset().map(lambda sample: ({\n",
    "    \"code_embedding\": sample[\"code_embedding\"],\n",
    "    \"comment_embedding\": sample[\"comment_embedding\"],\n",
    "  }, sample[\"target\"]))\n",
    "  \n",
    "  return tf_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 15:40:25.682503: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-10-20 15:40:25.682521: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-10-20 15:40:25.682526: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-10-20 15:40:25.682575: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-20 15:40:25.682788: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "Generating train split: 4000 examples [00:00, 6523.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 15:40:28.218464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-10-20 15:40:28.261700: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 11s 280ms/step - loss: 0.6958 - binary_accuracy: 0.5002 - precision: 0.5003 - recall: 0.4930\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.6922 - binary_accuracy: 0.5232 - precision: 0.5222 - recall: 0.5480\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.6776 - binary_accuracy: 0.5688 - precision: 0.5711 - recall: 0.5520\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.5770 - binary_accuracy: 0.7038 - precision: 0.6815 - recall: 0.7650\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.4503 - binary_accuracy: 0.7885 - precision: 0.7553 - recall: 0.8535\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.3886 - binary_accuracy: 0.8280 - precision: 0.8026 - recall: 0.8700\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.3495 - binary_accuracy: 0.8497 - precision: 0.8207 - recall: 0.8950\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 6s 274ms/step - loss: 0.3298 - binary_accuracy: 0.8562 - precision: 0.8306 - recall: 0.8950\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 6s 275ms/step - loss: 0.3082 - binary_accuracy: 0.8717 - precision: 0.8512 - recall: 0.9010\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 6s 274ms/step - loss: 0.2655 - binary_accuracy: 0.8967 - precision: 0.8766 - recall: 0.9235\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.2328 - binary_accuracy: 0.9145 - precision: 0.8870 - recall: 0.9500\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.2138 - binary_accuracy: 0.9222 - precision: 0.8982 - recall: 0.9525\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.2120 - binary_accuracy: 0.9190 - precision: 0.9068 - recall: 0.9340\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.2180 - binary_accuracy: 0.9150 - precision: 0.8908 - recall: 0.9460\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.2323 - binary_accuracy: 0.9060 - precision: 0.8874 - recall: 0.9300\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 6s 286ms/step - loss: 0.2657 - binary_accuracy: 0.8900 - precision: 0.8732 - recall: 0.9125\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 6s 286ms/step - loss: 0.2213 - binary_accuracy: 0.9160 - precision: 0.9031 - recall: 0.9320\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 6s 280ms/step - loss: 0.1824 - binary_accuracy: 0.9370 - precision: 0.9194 - recall: 0.9580\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.1638 - binary_accuracy: 0.9433 - precision: 0.9331 - recall: 0.9550\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.1649 - binary_accuracy: 0.9392 - precision: 0.9325 - recall: 0.9470\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.2116 - binary_accuracy: 0.9178 - precision: 0.8965 - recall: 0.9445\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.2026 - binary_accuracy: 0.9208 - precision: 0.9013 - recall: 0.9450\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.1542 - binary_accuracy: 0.9470 - precision: 0.9506 - recall: 0.9430\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 6s 291ms/step - loss: 0.1457 - binary_accuracy: 0.9510 - precision: 0.9391 - recall: 0.9645\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.1318 - binary_accuracy: 0.9548 - precision: 0.9469 - recall: 0.9635\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.1592 - binary_accuracy: 0.9442 - precision: 0.9423 - recall: 0.9465\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.1549 - binary_accuracy: 0.9467 - precision: 0.9344 - recall: 0.9610\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.1132 - binary_accuracy: 0.9617 - precision: 0.9511 - recall: 0.9735\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 6s 275ms/step - loss: 0.0916 - binary_accuracy: 0.9747 - precision: 0.9694 - recall: 0.9805\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 6s 277ms/step - loss: 0.0891 - binary_accuracy: 0.9732 - precision: 0.9665 - recall: 0.9805\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0959 - binary_accuracy: 0.9680 - precision: 0.9647 - recall: 0.9715\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0859 - binary_accuracy: 0.9728 - precision: 0.9601 - recall: 0.9865\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0928 - binary_accuracy: 0.9680 - precision: 0.9606 - recall: 0.9760\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0640 - binary_accuracy: 0.9803 - precision: 0.9767 - recall: 0.9840\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0497 - binary_accuracy: 0.9852 - precision: 0.9764 - recall: 0.9945\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0460 - binary_accuracy: 0.9865 - precision: 0.9822 - recall: 0.9910\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0426 - binary_accuracy: 0.9875 - precision: 0.9827 - recall: 0.9925\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0412 - binary_accuracy: 0.9872 - precision: 0.9856 - recall: 0.9890\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.0423 - binary_accuracy: 0.9868 - precision: 0.9855 - recall: 0.9880\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.0400 - binary_accuracy: 0.9895 - precision: 0.9851 - recall: 0.9940\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.0423 - binary_accuracy: 0.9868 - precision: 0.9836 - recall: 0.9900\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0435 - binary_accuracy: 0.9877 - precision: 0.9880 - recall: 0.9875\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.0419 - binary_accuracy: 0.9855 - precision: 0.9870 - recall: 0.9840\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 6s 278ms/step - loss: 0.0426 - binary_accuracy: 0.9870 - precision: 0.9851 - recall: 0.9890\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.0445 - binary_accuracy: 0.9850 - precision: 0.9807 - recall: 0.9895\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 6s 279ms/step - loss: 0.0444 - binary_accuracy: 0.9870 - precision: 0.9860 - recall: 0.9880\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.0448 - binary_accuracy: 0.9865 - precision: 0.9841 - recall: 0.9890\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0240 - binary_accuracy: 0.9925 - precision: 0.9920 - recall: 0.9930\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0217 - binary_accuracy: 0.9945 - precision: 0.9940 - recall: 0.9950\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0141 - binary_accuracy: 0.9975 - precision: 0.9960 - recall: 0.9990\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0076 - binary_accuracy: 0.9992 - precision: 0.9990 - recall: 0.9995\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0051 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0043 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0038 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0035 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.0032 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0030 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 6s 290ms/step - loss: 0.0028 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.0025 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 6s 275ms/step - loss: 0.0024 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 5s 275ms/step - loss: 0.0026 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0032 - binary_accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0023 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0031 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 6s 293ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.0023 - binary_accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 0.0019 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.0017 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.0027 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 5s 258ms/step - loss: 0.0017 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0022 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 5s 256ms/step - loss: 0.0021 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 5s 256ms/step - loss: 0.0014 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0015 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0016 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.0012 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0014 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.0011 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 5s 266ms/step - loss: 0.0011 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.0014 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.0011 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0010 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0012 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.0010 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 931s 49s/step - loss: 0.0012 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 0.0010 - binary_accuracy: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_1/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "Generating train split: 12000 examples [00:00, 15392.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-10-20 16:07:03.326269: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 18s 258ms/step - loss: 0.4545 - binary_accuracy: 0.8278 - precision: 0.2000 - recall: 0.0110\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 15s 256ms/step - loss: 0.4053 - binary_accuracy: 0.8337 - precision: 0.5909 - recall: 0.0065\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 15s 255ms/step - loss: 0.3264 - binary_accuracy: 0.8460 - precision: 0.6176 - recall: 0.1995\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.2759 - binary_accuracy: 0.8652 - precision: 0.6364 - recall: 0.4455\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 15s 254ms/step - loss: 0.2457 - binary_accuracy: 0.8852 - precision: 0.6903 - recall: 0.5640\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 15s 255ms/step - loss: 0.2229 - binary_accuracy: 0.8961 - precision: 0.7109 - recall: 0.6345\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 89s 316ms/step - loss: 0.1961 - binary_accuracy: 0.9130 - precision: 0.7567 - recall: 0.7045\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 17s 288ms/step - loss: 0.1679 - binary_accuracy: 0.9311 - precision: 0.8053 - recall: 0.7735\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 17s 279ms/step - loss: 0.1570 - binary_accuracy: 0.9348 - precision: 0.8050 - recall: 0.8030\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 17s 279ms/step - loss: 0.1414 - binary_accuracy: 0.9423 - precision: 0.8257 - recall: 0.8290\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 17s 275ms/step - loss: 0.1240 - binary_accuracy: 0.9511 - precision: 0.8545 - recall: 0.8515\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 16s 275ms/step - loss: 0.1073 - binary_accuracy: 0.9569 - precision: 0.8673 - recall: 0.8755\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 17s 281ms/step - loss: 0.0931 - binary_accuracy: 0.9639 - precision: 0.8858 - recall: 0.8995\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0817 - binary_accuracy: 0.9693 - precision: 0.9067 - recall: 0.9090\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 17s 283ms/step - loss: 0.0796 - binary_accuracy: 0.9688 - precision: 0.9053 - recall: 0.9080\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0709 - binary_accuracy: 0.9728 - precision: 0.9135 - recall: 0.9240\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0570 - binary_accuracy: 0.9794 - precision: 0.9363 - recall: 0.9405\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 17s 283ms/step - loss: 0.0484 - binary_accuracy: 0.9829 - precision: 0.9454 - recall: 0.9525\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0520 - binary_accuracy: 0.9812 - precision: 0.9378 - recall: 0.9500\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0474 - binary_accuracy: 0.9827 - precision: 0.9418 - recall: 0.9555\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 16s 272ms/step - loss: 0.0484 - binary_accuracy: 0.9818 - precision: 0.9411 - recall: 0.9500\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 17s 287ms/step - loss: 0.0415 - binary_accuracy: 0.9852 - precision: 0.9519 - recall: 0.9600\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 19s 319ms/step - loss: 0.0348 - binary_accuracy: 0.9872 - precision: 0.9597 - recall: 0.9640\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 19s 312ms/step - loss: 0.0260 - binary_accuracy: 0.9918 - precision: 0.9694 - recall: 0.9820\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 17s 282ms/step - loss: 0.0182 - binary_accuracy: 0.9944 - precision: 0.9811 - recall: 0.9855\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 17s 284ms/step - loss: 0.0156 - binary_accuracy: 0.9962 - precision: 0.9866 - recall: 0.9905\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 17s 280ms/step - loss: 0.0131 - binary_accuracy: 0.9966 - precision: 0.9866 - recall: 0.9930\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 17s 284ms/step - loss: 0.0101 - binary_accuracy: 0.9981 - precision: 0.9925 - recall: 0.9960\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 17s 278ms/step - loss: 0.0120 - binary_accuracy: 0.9971 - precision: 0.9886 - recall: 0.9940\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 17s 290ms/step - loss: 0.0089 - binary_accuracy: 0.9979 - precision: 0.9920 - recall: 0.9955\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 17s 282ms/step - loss: 0.0083 - binary_accuracy: 0.9983 - precision: 0.9940 - recall: 0.9960\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 18s 292ms/step - loss: 0.0055 - binary_accuracy: 0.9992 - precision: 0.9960 - recall: 0.9995\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 17s 275ms/step - loss: 0.0047 - binary_accuracy: 0.9992 - precision: 0.9965 - recall: 0.9990\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 16s 270ms/step - loss: 0.0039 - binary_accuracy: 0.9990 - precision: 0.9955 - recall: 0.9985\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 16s 270ms/step - loss: 0.0042 - binary_accuracy: 0.9991 - precision: 0.9960 - recall: 0.9985\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 16s 272ms/step - loss: 0.0066 - binary_accuracy: 0.9984 - precision: 0.9955 - recall: 0.9950\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0113 - binary_accuracy: 0.9962 - precision: 0.9870 - recall: 0.9905\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 17s 278ms/step - loss: 0.0213 - binary_accuracy: 0.9917 - precision: 0.9750 - recall: 0.9750\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0283 - binary_accuracy: 0.9910 - precision: 0.9702 - recall: 0.9760\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 17s 279ms/step - loss: 0.0290 - binary_accuracy: 0.9895 - precision: 0.9676 - recall: 0.9695\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 16s 271ms/step - loss: 0.0219 - binary_accuracy: 0.9922 - precision: 0.9760 - recall: 0.9770\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 16s 270ms/step - loss: 0.0173 - binary_accuracy: 0.9942 - precision: 0.9777 - recall: 0.9880\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0140 - binary_accuracy: 0.9945 - precision: 0.9835 - recall: 0.9835\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 18s 299ms/step - loss: 0.0090 - binary_accuracy: 0.9971 - precision: 0.9905 - recall: 0.9920\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0051 - binary_accuracy: 0.9988 - precision: 0.9950 - recall: 0.9980\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 17s 275ms/step - loss: 0.0036 - binary_accuracy: 0.9992 - precision: 0.9965 - recall: 0.9985\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.0023 - binary_accuracy: 0.9994 - precision: 0.9980 - recall: 0.9985\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - precision: 0.9980 - recall: 0.9990\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 17s 275ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - precision: 0.9975 - recall: 0.9995\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0017 - binary_accuracy: 0.9995 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 17s 279ms/step - loss: 0.0015 - binary_accuracy: 0.9996 - precision: 0.9975 - recall: 1.0000\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 17s 284ms/step - loss: 0.0013 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 17s 289ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - precision: 0.9980 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 16s 273ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - precision: 0.9980 - recall: 1.0000\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 16s 274ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.9985 - recall: 0.9990\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 17s 275ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9980 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 16s 272ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 17s 277ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9980 - recall: 1.0000\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 17s 280ms/step - loss: 0.0015 - binary_accuracy: 0.9995 - precision: 0.9980 - recall: 0.9990\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 16s 275ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.9980 - recall: 0.9995\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 16s 271ms/step - loss: 9.9659e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 16s 270ms/step - loss: 9.9850e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 16s 272ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 17s 278ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 17s 278ms/step - loss: 9.7102e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 17s 276ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - precision: 0.9980 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 16s 273ms/step - loss: 0.0023 - binary_accuracy: 0.9993 - precision: 0.9975 - recall: 0.9985\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 16s 268ms/step - loss: 0.0310 - binary_accuracy: 0.9903 - precision: 0.9682 - recall: 0.9740\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 39s 663ms/step - loss: 0.0667 - binary_accuracy: 0.9747 - precision: 0.9232 - recall: 0.9255\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 55s 932ms/step - loss: 0.0395 - binary_accuracy: 0.9868 - precision: 0.9559 - recall: 0.9650\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 31s 483ms/step - loss: 0.0193 - binary_accuracy: 0.9942 - precision: 0.9820 - recall: 0.9835\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 30s 487ms/step - loss: 0.0098 - binary_accuracy: 0.9969 - precision: 0.9890 - recall: 0.9925\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.0072 - binary_accuracy: 0.9983 - precision: 0.9950 - recall: 0.9945\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 23s 389ms/step - loss: 0.0028 - binary_accuracy: 0.9995 - precision: 0.9975 - recall: 0.9995\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 21s 350ms/step - loss: 0.0016 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 19s 322ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 20s 336ms/step - loss: 0.0011 - binary_accuracy: 0.9996 - precision: 0.9985 - recall: 0.9990\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 19s 313ms/step - loss: 9.6046e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 19s 322ms/step - loss: 8.6163e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 19s 317ms/step - loss: 8.0134e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 20s 329ms/step - loss: 7.8320e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 19s 312ms/step - loss: 7.6276e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 19s 317ms/step - loss: 7.7436e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 19s 316ms/step - loss: 7.7590e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 20s 327ms/step - loss: 8.5287e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 19s 308ms/step - loss: 9.0628e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 19s 315ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.9985 - recall: 0.9990\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 19s 315ms/step - loss: 9.7253e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 19s 312ms/step - loss: 8.6625e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 19s 321ms/step - loss: 7.4417e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 19s 309ms/step - loss: 6.5294e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 19s 314ms/step - loss: 6.1385e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 19s 321ms/step - loss: 5.8166e-04 - binary_accuracy: 0.9997 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 19s 316ms/step - loss: 5.6761e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 19s 309ms/step - loss: 5.6547e-04 - binary_accuracy: 0.9997 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 19s 312ms/step - loss: 8.9832e-04 - binary_accuracy: 0.9996 - precision: 0.9990 - recall: 0.9985\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 19s 310ms/step - loss: 9.7888e-04 - binary_accuracy: 0.9996 - precision: 0.9980 - recall: 0.9995\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 19s 318ms/step - loss: 0.0010 - binary_accuracy: 0.9996 - precision: 0.9990 - recall: 0.9985\n",
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_5/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "Generating train split: 32000 examples [00:01, 24497.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 16:54:14.636278: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 52s 304ms/step - loss: 0.2373 - binary_accuracy: 0.9353 - precision: 0.1354 - recall: 0.0065\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.1899 - binary_accuracy: 0.9374 - precision: 0.4681 - recall: 0.0110\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.1618 - binary_accuracy: 0.9385 - precision: 0.5943 - recall: 0.0520\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.1330 - binary_accuracy: 0.9430 - precision: 0.6212 - recall: 0.2255\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 52s 323ms/step - loss: 0.1166 - binary_accuracy: 0.9489 - precision: 0.6533 - recall: 0.3900\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.1036 - binary_accuracy: 0.9535 - precision: 0.6737 - recall: 0.4965\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0908 - binary_accuracy: 0.9612 - precision: 0.7296 - recall: 0.6030\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0805 - binary_accuracy: 0.9658 - precision: 0.7515 - recall: 0.6760\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0721 - binary_accuracy: 0.9709 - precision: 0.7899 - recall: 0.7275\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 51s 321ms/step - loss: 0.0641 - binary_accuracy: 0.9741 - precision: 0.8099 - recall: 0.7645\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0537 - binary_accuracy: 0.9786 - precision: 0.8433 - recall: 0.8075\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0469 - binary_accuracy: 0.9817 - precision: 0.8601 - recall: 0.8450\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0421 - binary_accuracy: 0.9838 - precision: 0.8757 - recall: 0.8630\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0389 - binary_accuracy: 0.9851 - precision: 0.8820 - recall: 0.8785\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 52s 323ms/step - loss: 0.0364 - binary_accuracy: 0.9857 - precision: 0.8867 - recall: 0.8845\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 51s 321ms/step - loss: 0.0276 - binary_accuracy: 0.9900 - precision: 0.9242 - recall: 0.9150\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 0.0239 - binary_accuracy: 0.9912 - precision: 0.9334 - recall: 0.9245\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0184 - binary_accuracy: 0.9942 - precision: 0.9549 - recall: 0.9520\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 49s 309ms/step - loss: 0.0154 - binary_accuracy: 0.9951 - precision: 0.9624 - recall: 0.9590\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0142 - binary_accuracy: 0.9952 - precision: 0.9574 - recall: 0.9655\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0133 - binary_accuracy: 0.9952 - precision: 0.9588 - recall: 0.9655\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0116 - binary_accuracy: 0.9963 - precision: 0.9710 - recall: 0.9705\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0118 - binary_accuracy: 0.9959 - precision: 0.9661 - recall: 0.9690\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0107 - binary_accuracy: 0.9961 - precision: 0.9685 - recall: 0.9695\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 0.0081 - binary_accuracy: 0.9971 - precision: 0.9760 - recall: 0.9780\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0099 - binary_accuracy: 0.9964 - precision: 0.9710 - recall: 0.9720\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0112 - binary_accuracy: 0.9958 - precision: 0.9674 - recall: 0.9655\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 51s 321ms/step - loss: 0.0101 - binary_accuracy: 0.9963 - precision: 0.9691 - recall: 0.9715\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 52s 322ms/step - loss: 0.0094 - binary_accuracy: 0.9966 - precision: 0.9730 - recall: 0.9730\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0075 - binary_accuracy: 0.9974 - precision: 0.9752 - recall: 0.9840\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 51s 319ms/step - loss: 0.0086 - binary_accuracy: 0.9969 - precision: 0.9727 - recall: 0.9785\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 52s 323ms/step - loss: 0.0055 - binary_accuracy: 0.9978 - precision: 0.9820 - recall: 0.9835\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 51s 320ms/step - loss: 0.0090 - binary_accuracy: 0.9968 - precision: 0.9745 - recall: 0.9740\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 52s 322ms/step - loss: 0.0086 - binary_accuracy: 0.9970 - precision: 0.9750 - recall: 0.9765\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0046 - binary_accuracy: 0.9986 - precision: 0.9895 - recall: 0.9885\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 52s 323ms/step - loss: 0.0032 - binary_accuracy: 0.9990 - precision: 0.9925 - recall: 0.9915\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0030 - binary_accuracy: 0.9992 - precision: 0.9910 - recall: 0.9960\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 48s 302ms/step - loss: 0.0056 - binary_accuracy: 0.9981 - precision: 0.9835 - recall: 0.9855\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0070 - binary_accuracy: 0.9973 - precision: 0.9790 - recall: 0.9775\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0065 - binary_accuracy: 0.9976 - precision: 0.9800 - recall: 0.9815\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0074 - binary_accuracy: 0.9975 - precision: 0.9795 - recall: 0.9805\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0070 - binary_accuracy: 0.9976 - precision: 0.9815 - recall: 0.9795\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 49s 306ms/step - loss: 0.0065 - binary_accuracy: 0.9978 - precision: 0.9820 - recall: 0.9830\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0045 - binary_accuracy: 0.9985 - precision: 0.9880 - recall: 0.9885\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 49s 306ms/step - loss: 0.0035 - binary_accuracy: 0.9987 - precision: 0.9880 - recall: 0.9910\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 50s 316ms/step - loss: 0.0040 - binary_accuracy: 0.9987 - precision: 0.9885 - recall: 0.9910\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0029 - binary_accuracy: 0.9992 - precision: 0.9925 - recall: 0.9945\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0036 - binary_accuracy: 0.9988 - precision: 0.9885 - recall: 0.9920\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0053 - binary_accuracy: 0.9983 - precision: 0.9885 - recall: 0.9850\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0073 - binary_accuracy: 0.9973 - precision: 0.9780 - recall: 0.9790\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0063 - binary_accuracy: 0.9978 - precision: 0.9815 - recall: 0.9835\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0056 - binary_accuracy: 0.9981 - precision: 0.9840 - recall: 0.9860\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0053 - binary_accuracy: 0.9983 - precision: 0.9836 - recall: 0.9890\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0037 - binary_accuracy: 0.9988 - precision: 0.9900 - recall: 0.9905\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0023 - binary_accuracy: 0.9993 - precision: 0.9940 - recall: 0.9945\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0035 - binary_accuracy: 0.9987 - precision: 0.9890 - recall: 0.9895\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0074 - binary_accuracy: 0.9977 - precision: 0.9791 - recall: 0.9835\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0063 - binary_accuracy: 0.9981 - precision: 0.9826 - recall: 0.9865\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0047 - binary_accuracy: 0.9984 - precision: 0.9880 - recall: 0.9865\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0023 - binary_accuracy: 0.9991 - precision: 0.9925 - recall: 0.9935\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - precision: 0.9965 - recall: 0.9985\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 6.3982e-04 - binary_accuracy: 0.9998 - precision: 0.9990 - recall: 0.9985\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 49s 308ms/step - loss: 6.8013e-04 - binary_accuracy: 0.9998 - precision: 0.9980 - recall: 0.9995\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 3.2798e-04 - binary_accuracy: 0.9999 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 49s 308ms/step - loss: 7.2925e-04 - binary_accuracy: 0.9997 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0127 - binary_accuracy: 0.9956 - precision: 0.9636 - recall: 0.9665\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 50s 311ms/step - loss: 0.0120 - binary_accuracy: 0.9954 - precision: 0.9621 - recall: 0.9650\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 51s 321ms/step - loss: 0.0059 - binary_accuracy: 0.9980 - precision: 0.9850 - recall: 0.9835\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0039 - binary_accuracy: 0.9987 - precision: 0.9890 - recall: 0.9910\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 50s 316ms/step - loss: 0.0016 - binary_accuracy: 0.9995 - precision: 0.9960 - recall: 0.9960\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 0.0022 - binary_accuracy: 0.9993 - precision: 0.9935 - recall: 0.9955\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0018 - binary_accuracy: 0.9994 - precision: 0.9955 - recall: 0.9950\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0024 - binary_accuracy: 0.9992 - precision: 0.9935 - recall: 0.9945\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0034 - binary_accuracy: 0.9990 - precision: 0.9915 - recall: 0.9920\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0046 - binary_accuracy: 0.9987 - precision: 0.9900 - recall: 0.9890\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 0.0064 - binary_accuracy: 0.9975 - precision: 0.9790 - recall: 0.9810\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 0.0076 - binary_accuracy: 0.9974 - precision: 0.9781 - recall: 0.9810\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 49s 307ms/step - loss: 0.0039 - binary_accuracy: 0.9985 - precision: 0.9890 - recall: 0.9865\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 49s 304ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - precision: 0.9940 - recall: 0.9935\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 49s 308ms/step - loss: 6.9022e-04 - binary_accuracy: 0.9998 - precision: 0.9975 - recall: 0.9990\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - precision: 0.9970 - recall: 0.9985\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 3.6404e-04 - binary_accuracy: 0.9999 - precision: 0.9990 - recall: 0.9995\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 5.0957e-04 - binary_accuracy: 0.9999 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 52s 324ms/step - loss: 4.7045e-04 - binary_accuracy: 0.9999 - precision: 0.9985 - recall: 0.9995\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 50s 315ms/step - loss: 2.6166e-04 - binary_accuracy: 0.9999 - precision: 0.9985 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 2.2819e-04 - binary_accuracy: 0.9999 - precision: 0.9990 - recall: 0.9995\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 6.3980e-04 - binary_accuracy: 0.9998 - precision: 0.9995 - recall: 0.9975\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 50s 310ms/step - loss: 5.6390e-04 - binary_accuracy: 0.9998 - precision: 0.9980 - recall: 0.9990\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 50s 312ms/step - loss: 0.0027 - binary_accuracy: 0.9990 - precision: 0.9905 - recall: 0.9930\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 53s 328ms/step - loss: 0.0163 - binary_accuracy: 0.9948 - precision: 0.9594 - recall: 0.9570\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 55s 344ms/step - loss: 0.0141 - binary_accuracy: 0.9951 - precision: 0.9647 - recall: 0.9570\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 50s 314ms/step - loss: 0.0038 - binary_accuracy: 0.9987 - precision: 0.9890 - recall: 0.9910\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 51s 320ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - precision: 0.9955 - recall: 0.9965\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 53s 331ms/step - loss: 0.0023 - binary_accuracy: 0.9992 - precision: 0.9935 - recall: 0.9945\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0016 - binary_accuracy: 0.9995 - precision: 0.9960 - recall: 0.9955\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 51s 316ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - precision: 0.9970 - recall: 0.9980\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 50s 313ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - precision: 0.9945 - recall: 0.9935\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 51s 319ms/step - loss: 0.0041 - binary_accuracy: 0.9988 - precision: 0.9905 - recall: 0.9900\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 51s 318ms/step - loss: 0.0067 - binary_accuracy: 0.9978 - precision: 0.9820 - recall: 0.9835\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 51s 317ms/step - loss: 0.0038 - binary_accuracy: 0.9987 - precision: 0.9885 - recall: 0.9915\n",
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_15/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dense_4_neg_15/assets\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "from models import build_dense_model\n",
    "\n",
    "neg_samples_count = [1, 5, 15]\n",
    "num_hidden_layers = 4\n",
    "for neg_count in neg_samples_count:\n",
    "  model = build_dense_model(num_hidden_layers=num_hidden_layers, input_shape=embedding_shape, model_name=f'dense_{num_hidden_layers}_neg_{neg_count}')\n",
    "  tf_train_dataset = to_tf_dataset(neg_count)\n",
    "  tensor_board_callback = callbacks.TensorBoard(log_dir=f'../logs/{model.name}')\n",
    "\n",
    "  model.fit(\n",
    "    tf_train_dataset.batch(batch_size),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch,\n",
    "    callbacks=[tensor_board_callback]\n",
    "  )\n",
    "  model.save(f'../models/{model.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pairs lookup dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "python_splits = load_dataset(dataset_name, 'python', split=['train', 'test', 'validation']) # type: ignore\n",
    "python_full_dataset = concatenate_datasets(python_splits)\n",
    "splits_info = python_splits[0].info.splits\n",
    "python_full_dataset_count = sum([splits_info[key].num_examples for key in splits_info.keys()])\n",
    "\n",
    "full_dataset_url_index = { sample['func_code_url']: index  for index, sample in tqdm(enumerate(python_full_dataset), desc=\"Generating dict lookup\", total=python_full_dataset_count) }\n",
    "def search_by_url(url: str) -> int | None:\n",
    "  try:\n",
    "    return full_dataset_url_index[url]\n",
    "  except:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CodeSearchNet queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples_path = '../datasets/query_samples'\n",
    "\n",
    "def remove_duplicates(dataset: Dataset) -> Dataset:\n",
    "  pandas_dataset = dataset.to_pandas().drop_duplicates(subset=['Language', 'Query', 'GitHubUrl', 'Relevance'], ignore_index=True) # type: ignore\n",
    "  dedup_dataset = Dataset.from_pandas(pandas_dataset)\n",
    "  return dedup_dataset\n",
    "\n",
    "def remove_queries_without_code(dataset: Dataset) -> Dataset:\n",
    "  return dataset.filter(lambda sample: search_by_url(sample['GitHubUrl']) is not None, desc=\"Filtering queries with no corresponding code\")\n",
    "\n",
    "def pre_process_query_samples() -> Dataset:\n",
    "  cs_net_queries_dataset: Dataset = Dataset.from_csv('../datasets/code_search_net_queries.csv') # type: ignore\n",
    "  \n",
    "  return remove_queries_without_code(remove_duplicates(cs_net_queries_dataset))\n",
    "\n",
    "def get_query_samples() -> Dataset:\n",
    "  try:\n",
    "    return Dataset.load_from_disk(query_samples_path)\n",
    "  except:\n",
    "    query_samples = pre_process_query_samples()\n",
    "    query_samples.save_to_disk(query_samples_path)\n",
    "    return query_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples: Dataset = get_query_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_code_embeddings(samples) -> Dataset:\n",
    "  query_texts = [sample['Query'] for sample in samples]\n",
    "  query_codes = [python_full_dataset[search_by_url(sample['GitHubUrl'])]['func_code_string'] for sample in samples]\n",
    "  assert len(query_texts) == len(query_codes), \"query_texts and query_codes arrays doesn't have the same length\"\n",
    "\n",
    "  query_embeddings = comment_model.encode(query_texts)\n",
    "  code_embeddings = code_model.encode(query_codes)\n",
    "\n",
    "  validation_dataset = []\n",
    "  for query_embedding, code_embedding in zip(query_embeddings, code_embeddings):\n",
    "    validation_dataset.append({\n",
    "      \"code_embedding\": code_embedding,\n",
    "      \"comment_embedding\": query_embedding,\n",
    "    })\n",
    "\n",
    "  return Dataset.from_list(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def validate(model, samples):\n",
    "  validation_dataset = get_query_code_embeddings(samples).to_tf_dataset(batch_size=10)\n",
    "\n",
    "  return {\n",
    "    \"predictions\": model.predict(validation_dataset, verbose=0).flatten(),\n",
    "    \"targets\": [sample['Relevance'] for sample in samples]\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prediction_correct(prediction, target) -> bool:\n",
    "  if target in [0, 1]:\n",
    "    return prediction <= 0.5\n",
    "  \n",
    "  if target in [2, 3]:\n",
    "    return prediction > 0.5\n",
    "  \n",
    "  raise ValueError(f\"target should be in range of [0, 3]. Instead, it has value of {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_query_samples = [sample for sample in query_samples if sample['Language'].lower() == 'python']\n",
    "validation_query_samples_count = len(validation_query_samples)\n",
    "\n",
    "for model_name in os.listdir('../models/'):\n",
    "  model = load_model(f'../models/{model_name}')\n",
    "  result = validate(model, validation_query_samples)\n",
    "  \n",
    "  hits = sum([is_prediction_correct(prediction, target) for prediction, target in zip(result['predictions'], result['targets'])])\n",
    "  success_percentage = hits / validation_query_samples_count\n",
    "\n",
    "  print(f\"model {model_name}: {success_percentage:.2%} - {hits} of {validation_query_samples_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
