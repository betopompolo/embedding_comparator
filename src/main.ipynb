{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements\n",
    "Make sure you're using the local conda env for running this notebook. If is not created yet, create one with python 3.9 by running `conda create --name myenv python=3.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (23.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (4.34.1)\n",
      "Requirement already satisfied: datasets in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (2.14.5)\n",
      "Requirement already satisfied: numpy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (1.26.1)\n",
      "Requirement already satisfied: pandas in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: tensorflow in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-metal in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: plotly==5.18.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (5.18.0)\n",
      "Requirement already satisfied: nbformat in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (5.9.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from plotly==5.18.0->-r ../requirements.txt (line 9)) (8.2.3)\n",
      "Requirement already satisfied: packaging in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from plotly==5.18.0->-r ../requirements.txt (line 9)) (23.2)\n",
      "Requirement already satisfied: filelock in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from transformers->-r ../requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets->-r ../requirements.txt (line 2)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from datasets->-r ../requirements.txt (line 2)) (3.8.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-macos->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorflow-metal->-r ../requirements.txt (line 7)) (0.41.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: scipy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (1.11.3)\n",
      "Requirement already satisfied: nltk in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sentence-transformers->-r ../requirements.txt (line 8)) (0.1.99)\n",
      "Requirement already satisfied: fastjsonschema in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (2.18.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (4.19.1)\n",
      "Requirement already satisfied: jupyter-core in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nbformat->-r ../requirements.txt (line 10)) (5.11.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from aiohttp->datasets->-r ../requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->-r ../requirements.txt (line 10)) (0.10.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests->transformers->-r ../requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: sympy in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from jupyter-core->nbformat->-r ../requirements.txt (line 10)) (3.11.0)\n",
      "Requirement already satisfied: click in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nltk->sentence-transformers->-r ../requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from nltk->sentence-transformers->-r ../requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from scikit-learn->sentence-transformers->-r ../requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from torchvision->sentence-transformers->-r ../requirements.txt (line 8)) (10.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers->-r ../requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos->-r ../requirements.txt (line 6)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/Projects/embedding_comparator/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, load_from_disk, concatenate_datasets\n",
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "def load_from_cs_net(take: int) -> Dataset:\n",
    "  ds = load_dataset(dataset_name, 'python', split='train')\n",
    "  return Dataset.from_dict(ds[:take]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "comment_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "code_model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "embedding_shape = (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "random_generator = default_rng(seed=42)\n",
    "\n",
    "def generate_negative_samples(iterator: Iterator, negative_samples_per_sample: int):\n",
    "  for batched_sample in iterator:\n",
    "    codes_embeddings = batched_sample['code_embedding']\n",
    "    comments_embeddings = batched_sample['comment_embedding']\n",
    "    batch_indexes = range(len(codes_embeddings))\n",
    "\n",
    "    for index in batch_indexes:\n",
    "      indexes = [i for i in batch_indexes if i != index]\n",
    "      negative_indexes = random_generator.choice(indexes, negative_samples_per_sample, replace=False)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": codes_embeddings[index],\n",
    "        \"comment_embedding\": comments_embeddings[index],\n",
    "        \"target\": 1\n",
    "      }\n",
    "\n",
    "      for negative_index in negative_indexes:\n",
    "        yield {\n",
    "          \"code_embedding\": codes_embeddings[index],\n",
    "          \"comment_embedding\": comments_embeddings[negative_index],\n",
    "          \"target\": 0\n",
    "        }\n",
    "\n",
    "def with_neg_samples(dataset: Dataset, negative_samples_per_sample: int, batch_size = 100) -> Dataset:\n",
    "  assert negative_samples_per_sample <= batch_size, \"negative_samples_per_sample must not be greater than batch_size\"\n",
    "  if negative_samples_per_sample <= 0:\n",
    "    return dataset\n",
    "  \n",
    "  dataset_with_negative_samples: Dataset = Dataset.from_generator(lambda: generate_negative_samples(dataset.iter(batch_size=batch_size), negative_samples_per_sample)) # type: ignore\n",
    "  return dataset_with_negative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_count = 2000\n",
    "train_dataset_path = f'../datasets/embeddings_python_train_{train_count}'\n",
    "train_pairs = load_from_cs_net(train_count)\n",
    "is_embeddings_dataset_stored = os.path.isdir(train_dataset_path)\n",
    "\n",
    "def generate_embeddings_in_batch(batched_sample):\n",
    "  codes = batched_sample['func_code_string']\n",
    "  comments = batched_sample['func_documentation_string']\n",
    "\n",
    "  return {\n",
    "    \"code_embedding\": code_model.encode(codes),\n",
    "    \"comment_embedding\": comment_model.encode(comments),\n",
    "  }\n",
    "\n",
    "embeddings_dataset: Dataset = Dataset.from_dict(load_from_disk(train_dataset_path)[:train_count]) if is_embeddings_dataset_stored else train_pairs.map(\n",
    "  generate_embeddings_in_batch, \n",
    "  batched=True, \n",
    "  batch_size=100,\n",
    "  remove_columns=list(train_pairs[0].keys()),\n",
    "  desc=\"Generating embeddings\"\n",
    ") # type: ignore\n",
    "\n",
    "if is_embeddings_dataset_stored == False:\n",
    "  embeddings_dataset.save_to_disk(train_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add negative samples to train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_dataset(negative_samples_per_sample: int):\n",
    "  tf_train_dataset = with_neg_samples(embeddings_dataset.shuffle(), negative_samples_per_sample).to_tf_dataset().map(lambda sample: ({\n",
    "    \"code_embedding\": sample[\"code_embedding\"],\n",
    "    \"comment_embedding\": sample[\"comment_embedding\"],\n",
    "  }, sample[\"target\"]))\n",
    "  \n",
    "  return tf_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from models import build_dense_model\n",
    "\n",
    "neg_samples_count = [1, 5, 15]\n",
    "num_hidden_layers = 4\n",
    "for neg_count in neg_samples_count:\n",
    "  model = build_dense_model(num_hidden_layers=num_hidden_layers, input_shape=embedding_shape, model_name=f'dense_{num_hidden_layers}_neg_{neg_count}')\n",
    "  tf_train_dataset = to_tf_dataset(neg_count)\n",
    "  tensor_board_callback = callbacks.TensorBoard(log_dir=f'../logs/{model.name}')\n",
    "\n",
    "  model.fit(\n",
    "    tf_train_dataset.batch(batch_size),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch,\n",
    "    callbacks=[tensor_board_callback]\n",
    "  )\n",
    "  model.save(f'../models/{model.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CodeSearchNet queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splits = load_dataset(dataset_name, 'python', split=['train', 'test', 'validation']) # type: ignore\n",
    "python_full_dataset = concatenate_datasets(python_splits)\n",
    "splits_info = python_splits[0].info.splits\n",
    "python_full_dataset_count = sum([splits_info[key].num_examples for key in splits_info.keys()])\n",
    "\n",
    "full_dataset_url_index = { sample['func_code_url']: index  for index, sample in tqdm(enumerate(python_full_dataset), desc=\"Generating dict lookup\", total=python_full_dataset_count) }\n",
    "def search_by_url(url: str) -> Optional[int]:\n",
    "  try:\n",
    "    return full_dataset_url_index[url]\n",
    "  except:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples_path = '../datasets/query_samples'\n",
    "\n",
    "def remove_duplicates(dataset: Dataset) -> Dataset:\n",
    "  pandas_dataset = dataset.to_pandas().drop_duplicates(subset=['Language', 'Query', 'GitHubUrl', 'Relevance'], ignore_index=True) # type: ignore\n",
    "  dedup_dataset = Dataset.from_pandas(pandas_dataset)\n",
    "  return dedup_dataset\n",
    "\n",
    "def remove_queries_without_code(dataset: Dataset) -> Dataset:\n",
    "  return dataset.filter(lambda sample: search_by_url(sample['GitHubUrl']) is not None, desc=\"Filtering queries with no corresponding code\")\n",
    "\n",
    "def pre_process_query_samples() -> Dataset:\n",
    "  cs_net_queries_dataset: Dataset = Dataset.from_csv('../datasets/code_search_net_queries.csv') # type: ignore\n",
    "  \n",
    "  return remove_queries_without_code(remove_duplicates(cs_net_queries_dataset))\n",
    "\n",
    "def get_query_samples() -> Dataset:\n",
    "  try:\n",
    "    return Dataset.load_from_disk(query_samples_path)\n",
    "  except:\n",
    "    query_samples = pre_process_query_samples()\n",
    "    query_samples.save_to_disk(query_samples_path)\n",
    "    return query_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_samples: Dataset = get_query_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_code_embeddings(samples) -> Dataset:\n",
    "  query_texts = [sample['Query'] for sample in samples]\n",
    "  query_codes = [python_full_dataset[search_by_url(sample['GitHubUrl'])]['func_code_string'] for sample in samples]\n",
    "  assert len(query_texts) == len(query_codes), \"query_texts and query_codes arrays doesn't have the same length\"\n",
    "\n",
    "  query_embeddings = comment_model.encode(query_texts)\n",
    "  code_embeddings = code_model.encode(query_codes)\n",
    "\n",
    "  validation_dataset = []\n",
    "  for query_embedding, code_embedding in zip(query_embeddings, code_embeddings):\n",
    "    validation_dataset.append({\n",
    "      \"code_embedding\": code_embedding,\n",
    "      \"comment_embedding\": query_embedding,\n",
    "    })\n",
    "\n",
    "  return Dataset.from_list(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def validate(model, samples):\n",
    "  validation_dataset = get_query_code_embeddings(samples).to_tf_dataset(batch_size=10)\n",
    "\n",
    "  return {\n",
    "    \"predictions\": model.predict(validation_dataset, verbose=0).flatten(),\n",
    "    \"targets\": [sample['Relevance'] for sample in samples]\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prediction_correct(prediction, target) -> bool:\n",
    "  if target in [0, 1]:\n",
    "    return prediction <= 0.5\n",
    "  \n",
    "  if target in [2, 3]:\n",
    "    return prediction > 0.5\n",
    "  \n",
    "  raise ValueError(f\"target should be in range of [0, 3]. Instead, it has value of {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_query_samples = [sample for sample in query_samples if sample['Language'].lower() == 'python']\n",
    "validation_query_samples_count = len(validation_query_samples)\n",
    "\n",
    "for model_name in os.listdir('../models/'):\n",
    "  model = load_model(f'../models/{model_name}')\n",
    "  result = validate(model, validation_query_samples)\n",
    "  \n",
    "  hits = sum([is_prediction_correct(prediction, target) for prediction, target in zip(result['predictions'], result['targets'])])\n",
    "  success_percentage = hits / validation_query_samples_count\n",
    "\n",
    "  print(f\"model {model_name}: {success_percentage:.2%} - {hits} of {validation_query_samples_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generalization experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def search(query, model) -> List:\n",
    "  query_embedding = comment_model.encode([query]).flatten()\n",
    "  samples = Dataset.from_list([{ \"code_embedding\": embedding_pair[\"code_embedding\"], 'comment_embedding': query_embedding } for embedding_pair in embeddings_dataset]).to_tf_dataset(batch_size=10)\n",
    "\n",
    "  predictions = model.predict(samples, verbose=0).flatten()\n",
    "  results = [{ \"prediction\": prediction, \"index\": index } for index, prediction in enumerate(predictions)]\n",
    "\n",
    "  return results\n",
    "\n",
    "def top_k(k: int, results: List):\n",
    "  return [train_pairs[result['index']] for result in results[:k]]\n",
    "\n",
    "def bottom_k(k: int, results: List):\n",
    "  return [train_pairs[result['index']] for result in results[-k:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "Running generalization experiment: 100%|██████████| 10/10 [02:52<00:00, 17.28s/it]\n"
     ]
    }
   ],
   "source": [
    "search_model = load_model('../models/dense_4_neg_5/')\n",
    "max_words_to_remove = 30\n",
    "experiment_results = []\n",
    "samples_count = 10\n",
    "\n",
    "for sample in tqdm(train_pairs.to_iterable_dataset().take(samples_count), total=samples_count, desc=\"Running generalization experiment\"):\n",
    "  comment_tokens: list = sample['func_documentation_tokens']\n",
    "  words_to_remove_count = min(len(comment_tokens), max_words_to_remove)\n",
    "  word_indexes_to_remove = list(range(words_to_remove_count))\n",
    "  random_generator.shuffle(word_indexes_to_remove)\n",
    "  \n",
    "  for word_index in word_indexes_to_remove:\n",
    "    comment_tokens_copy = comment_tokens.copy()\n",
    "    word_removed = comment_tokens_copy.pop(word_index)\n",
    "    query = ' '.join(comment_tokens_copy)\n",
    "    search_results = search(\n",
    "      query=query,\n",
    "      model=search_model\n",
    "    )\n",
    "\n",
    "    experiment_results.append({\n",
    "      \"query\": query,\n",
    "      \"word_removed\": word_removed,\n",
    "      \"top_1_code\": top_k(1, search_results)[0]['func_code_string'],\n",
    "      \"top_1_prediction_score\": search_results[0]['prediction']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 364.28ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86283"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(experiment_results).to_csv('../results/generalization_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
