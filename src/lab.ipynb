{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(pairs_ids: List[str]) -> tf.data.Dataset:\n",
    "  def dataset_generator():\n",
    "    for pair_id in pairs_ids:\n",
    "      [code_embedding, comment_embedding] = embedding_dataset.get(pair_id)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": code_embedding,\n",
    "        \"comment_embedding\": comment_embedding,\n",
    "      }\n",
    "  \n",
    "  return tf.data.Dataset.from_generator(dataset_generator, output_types={\n",
    "    \"code_embedding\": tf.float32, \n",
    "    \"comment_embedding\": tf.float32,\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumDenseLayers = Literal[2, 4, 8]\n",
    "input_shape = (1024) # TODO: Use variables\n",
    "hidden_layer_activation = 'tanh'\n",
    "output_activation = 'sigmoid'\n",
    "dense_layers: Dict[NumDenseLayers, List] = {\n",
    "  2: [\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ],\n",
    "  4: [\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "  8: [\n",
    "    Dense(800, activation=hidden_layer_activation),\n",
    "    Dense(600, activation=hidden_layer_activation),\n",
    "    Dense(500, activation=hidden_layer_activation),\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(300, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "}\n",
    "dropout_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveLoss(Loss):\n",
    "   def __init__(self, reduction=losses_utils.ReductionV2.AUTO, name=\"constrastive_loss\", margin=1):\n",
    "      self.margin = margin\n",
    "      super().__init__(reduction, name)\n",
    "\n",
    "   def call(self, y_true, y_pred):\n",
    "      square_pred = tf.math.square(y_pred)\n",
    "      margin_square = tf.math.square(tf.math.maximum(self.margin - (y_pred), 0))\n",
    "      return tf.math.reduce_mean(\n",
    "        (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "      )\n",
    "\n",
    "def build_model(num_hidden_layers: NumDenseLayers):\n",
    "  code_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "\n",
    "  concatenated_inputs = Concatenate()([code_input, comment_input])\n",
    "  hidden_layers = Sequential(dense_layers[num_hidden_layers], name=\"hidden_layers\")(concatenated_inputs)\n",
    "  output = Dense(1, activation=output_activation, name=\"output\")(hidden_layers)\n",
    "  model = Model(\n",
    "    inputs=[code_input, comment_input],\n",
    "    outputs=output,\n",
    "    name=\"embedding_comparator\"\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_comparator = build_model(num_hidden_layers=2)\n",
    "tensor_board_callback = callbacks.TensorBoard(log_dir=f\"../logs/scalars/{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "train_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(train_samples_count))]\n",
    "valid_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(valid_samples_count))]\n",
    "\n",
    "# def map_to_train(sample, target):\n",
    "#     return (sample, target)\n",
    "\n",
    "# positive_pairs = create_tf_dataset(train_pairs).map(lambda sample: map_to_train(sample, 1))\n",
    "# negative_pairs = positive_pairs.shuffle(buffer_size=int(train_samples_count * 0.4))\n",
    "# pairs_dataset = tf.data.Dataset.choose_from_datasets([positive_pairs, negative_pairs], [0, 1])\n",
    "# valid_pairs = create_tf_dataset(valid_pairs).map(lambda sample: map_to_train(sample, 1)).batch(100)\n",
    "\n",
    "# results = embedding_comparator.fit(\n",
    "#     pairs_dataset,\n",
    "#     validation_data=valid_pairs,\n",
    "#     epochs=10,\n",
    "#     callbacks=[tensor_board_callback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sample_target(sample, target: int):\n",
    "  sample['target'] = target\n",
    "  return sample\n",
    "\n",
    "train_dataset = create_tf_dataset(train_pairs).map(lambda sample: set_sample_target(sample, 0))\n",
    "negative_pairs_ds = train_dataset.map(lambda sample: set_sample_target(sample, 1)).shuffle(buffer_size=int(train_samples_count * 0.2))\n",
    "\n",
    "is_equal_count = 0\n",
    "for positive, negative in zip(train_dataset, negative_pairs_ds):\n",
    "  is_equal = np.array_equal(positive['code_embedding'], negative['code_embedding']) and np.array_equal(positive['comment_embedding'], negative['comment_embedding'])\n",
    "  is_equal_count += 1 if is_equal else 0\n",
    "\n",
    "print(f'equal pairs: {is_equal_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_with_target = x.map(lambda sample: set_sample_target(sample, 0))\n",
    "neg_x = x.map(lambda sample: set_sample_target(sample, 1))\n",
    "for positive, negative in zip(x_with_target.take(10), neg_x.take(10)):\n",
    "\n",
    "    print(f\"positive label: {positive['target']} negative target: {negative['target']}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "choice_dataset = tf.data.Dataset.range(2).repeat(10).shuffle(5)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "negative_ds = dataset.shuffle(5).map(lambda i: -i)\n",
    "\n",
    "all_data = tf.data.Dataset.choose_from_datasets([dataset, negative_ds], choice_dataset)\n",
    "\n",
    "for i in all_data:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "  [x, y] = vects\n",
    "  sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=0)\n",
    "  distance = tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "  return distance\n",
    "\n",
    "def build_siamese_model():\n",
    "  code_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "  similarity_score = Dot(normalize=True, axes=1)([code_embedding_input, comment_embedding_input])\n",
    "\n",
    "  # normal_layer = BatchNormalization()(concatenated_inputs)\n",
    "  output_layer = Dense(1, activation=\"sigmoid\")(similarity_score)\n",
    "  model = Model(inputs=[code_embedding_input, comment_embedding_input], outputs=output_layer, name=\"siamese_model\")\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model = build_siamese_model()\n",
    "# siamese_model.fit(\n",
    "#     pairs_dataset,\n",
    "#     validation_data=valid_pairs,\n",
    "#     epochs=10,\n",
    "#     callbacks=[tensor_board_callback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(test_samples_count))]\n",
    "# test_dataset = create_tf_dataset(test_pairs, for_training=False).batch(100)\n",
    "\n",
    "# predicts = siamese_model.predict(test_dataset)\n",
    "# predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embedding_sample(sample):\n",
    "  fig, axs = plt.subplots(ncols=2, nrows=1)\n",
    "  code_axs = axs[0]\n",
    "  comment_axs = axs[1]\n",
    "\n",
    "  code_axs.plot(sample['code_embedding'], label=\"code\", color=\"blue\")\n",
    "  comment_axs.plot(sample['comment_embedding'], label=\"comment\", color=\"orange\")\n",
    "  fig.legend()\n",
    "  \n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = MongoDbClient().get_pairs_collection().find_one({\"language\": \"python\", \"partition\": \"train\" })\n",
    "if pair is None:\n",
    "    raise ValueError(\"Not found\")\n",
    "\n",
    "[code, comment] = EmbeddingGenerator().from_pairs([pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embedding_sample({\n",
    "    \"code_embedding\": code.numpy()[0],\n",
    "    \"comment_embedding\": comment.numpy()[0],\n",
    "})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import orjson\n",
    "def create_tf_dataset_from_csnet(partition: str) -> Iterator:\n",
    "  dataset_dir = os.path.join('../datasets/temp_python/python', 'final', 'jsonl', partition)\n",
    "  # file_names = [os.path.join(dataset_dir, file_name) for file_name in os.listdir(dataset_dir) if file_name.endswith('.jsonl.gz')]\n",
    "  file_names = [os.path.join(dataset_dir, 'python_train_0.jsonl.gz')]\n",
    "  return tf.data.TextLineDataset(\n",
    "    filenames=file_names,\n",
    "    compression_type='GZIP',\n",
    "    num_parallel_reads=tf.data.AUTOTUNE,\n",
    "  )\n",
    "\n",
    "expected = {\"repo\": \"ageitgey/face_recognition\", \"path\": \"examples/face_recognition_knn.py\", \"func_name\": \"train\", \"original_string\": \"def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \\\"\\\"\\\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \\\"\\\"\\\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\\\"Image {} not suitable for training: {}\\\".format(img_path, \\\"Didn't find a face\\\" if len(face_bounding_boxes) < 1 else \\\"Found more than one face\\\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\\\"Chose n_neighbors automatically:\\\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, 'wb') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf\", \"language\": \"python\", \"code\": \"def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \\\"\\\"\\\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \\\"\\\"\\\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\\\"Image {} not suitable for training: {}\\\".format(img_path, \\\"Didn't find a face\\\" if len(face_bounding_boxes) < 1 else \\\"Found more than one face\\\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\\\"Chose n_neighbors automatically:\\\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, 'wb') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf\", \"code_tokens\": [\"def\", \"train\", \"(\", \"train_dir\", \",\", \"model_save_path\", \"=\", \"None\", \",\", \"n_neighbors\", \"=\", \"None\", \",\", \"knn_algo\", \"=\", \"'ball_tree'\", \",\", \"verbose\", \"=\", \"False\", \")\", \":\", \"X\", \"=\", \"[\", \"]\", \"y\", \"=\", \"[\", \"]\", \"# Loop through each person in the training set\", \"for\", \"class_dir\", \"in\", \"os\", \".\", \"listdir\", \"(\", \"train_dir\", \")\", \":\", \"if\", \"not\", \"os\", \".\", \"path\", \".\", \"isdir\", \"(\", \"os\", \".\", \"path\", \".\", \"join\", \"(\", \"train_dir\", \",\", \"class_dir\", \")\", \")\", \":\", \"continue\", \"# Loop through each training image for the current person\", \"for\", \"img_path\", \"in\", \"image_files_in_folder\", \"(\", \"os\", \".\", \"path\", \".\", \"join\", \"(\", \"train_dir\", \",\", \"class_dir\", \")\", \")\", \":\", \"image\", \"=\", \"face_recognition\", \".\", \"load_image_file\", \"(\", \"img_path\", \")\", \"face_bounding_boxes\", \"=\", \"face_recognition\", \".\", \"face_locations\", \"(\", \"image\", \")\", \"if\", \"len\", \"(\", \"face_bounding_boxes\", \")\", \"!=\", \"1\", \":\", \"# If there are no people (or too many people) in a training image, skip the image.\", \"if\", \"verbose\", \":\", \"print\", \"(\", \"\\\"Image {} not suitable for training: {}\\\"\", \".\", \"format\", \"(\", \"img_path\", \",\", \"\\\"Didn't find a face\\\"\", \"if\", \"len\", \"(\", \"face_bounding_boxes\", \")\", \"<\", \"1\", \"else\", \"\\\"Found more than one face\\\"\", \")\", \")\", \"else\", \":\", \"# Add face encoding for current image to the training set\", \"X\", \".\", \"append\", \"(\", \"face_recognition\", \".\", \"face_encodings\", \"(\", \"image\", \",\", \"known_face_locations\", \"=\", \"face_bounding_boxes\", \")\", \"[\", \"0\", \"]\", \")\", \"y\", \".\", \"append\", \"(\", \"class_dir\", \")\", \"# Determine how many neighbors to use for weighting in the KNN classifier\", \"if\", \"n_neighbors\", \"is\", \"None\", \":\", \"n_neighbors\", \"=\", \"int\", \"(\", \"round\", \"(\", \"math\", \".\", \"sqrt\", \"(\", \"len\", \"(\", \"X\", \")\", \")\", \")\", \")\", \"if\", \"verbose\", \":\", \"print\", \"(\", \"\\\"Chose n_neighbors automatically:\\\"\", \",\", \"n_neighbors\", \")\", \"# Create and train the KNN classifier\", \"knn_clf\", \"=\", \"neighbors\", \".\", \"KNeighborsClassifier\", \"(\", \"n_neighbors\", \"=\", \"n_neighbors\", \",\", \"algorithm\", \"=\", \"knn_algo\", \",\", \"weights\", \"=\", \"'distance'\", \")\", \"knn_clf\", \".\", \"fit\", \"(\", \"X\", \",\", \"y\", \")\", \"# Save the trained KNN classifier\", \"if\", \"model_save_path\", \"is\", \"not\", \"None\", \":\", \"with\", \"open\", \"(\", \"model_save_path\", \",\", \"'wb'\", \")\", \"as\", \"f\", \":\", \"pickle\", \".\", \"dump\", \"(\", \"knn_clf\", \",\", \"f\", \")\", \"return\", \"knn_clf\"], \"docstring\": \"Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\", \"docstring_tokens\": [\"Trains\", \"a\", \"k\", \"-\", \"nearest\", \"neighbors\", \"classifier\", \"for\", \"face\", \"recognition\", \".\"], \"sha\": \"c96b010c02f15e8eeb0f71308c641179ac1f19bb\", \"url\": \"https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108\", \"partition\": \"train\"}\n",
    "for i in create_tf_dataset_from_csnet('train'):\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs_net_parser import CSNetParser\n",
    "\n",
    "\n",
    "cs_net_parser = CSNetParser()\n",
    "for tensor in cs_net_parser.to_tf_dataset(partition='train', language='python'):\n",
    "  sample = cs_net_parser.tensor_to_sample(tensor)\n",
    "  if sample['url'] == 'https://github.com/mjirik/imcut/blob/1b38e7cd18a7a38fe683c1cabe1222fe5fa03aa3/imcut/graph.py#L586-L636':\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = 'heey'\n",
    "len(my_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as transformers_logging\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from embedding_dataset import EmbeddingDataset\n",
    "from mongo_db_client import MongoDbClient\n",
    "from embedding_generator import EmbeddingGenerator\n",
    "\n",
    "embedding_generator = EmbeddingGenerator()\n",
    "embedding_dataset = EmbeddingDataset(dataset_dir='../datasets/embeddings/', dataset_name='embeddings_db')\n",
    "mongo_db = MongoDbClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(mongo_db.get_pairs_collection().find({ \"partition\": 'train', \"language\": 'python' }).limit(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pairs: 500 found embeddings: 500\n"
     ]
    }
   ],
   "source": [
    "embeddings = [embedding_dataset.get(pair['id']) for pair in pairs]\n",
    "\n",
    "print(f'total pairs: {len(pairs)} found embeddings: {len(embeddings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 embeddings found\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in embedding_dataset.list_all():\n",
    "    count += 1\n",
    "\n",
    "print(f'{count} embeddings found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "embs = []\n",
    "with open('../datasets/embeddings/embeddings_db.pkl', 'rb') as file:\n",
    "  while True:\n",
    "    try:\n",
    "      embs.append(pickle.load(file))\n",
    "    except EOFError:\n",
    "      break\n",
    "\n",
    "print(len(embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
