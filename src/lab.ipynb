{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, TFAutoModel, logging as transformers_logging\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Literal, List\n",
    "from keras import Model, Sequential, callbacks\n",
    "from keras.layers import Dense, Input, Concatenate, Dot\n",
    "from keras.losses import Loss\n",
    "from keras.utils import losses_utils\n",
    "from keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "from keras.optimizers import Adam\n",
    "from mongo_db_client import MongoDbClient\n",
    "from models import MongoDbPairDoc\n",
    "import more_itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "def shuffle(list: List) -> List:\n",
    "  shuffled_list = list.copy()\n",
    "  random.shuffle(shuffled_list)\n",
    "  return shuffled_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_max_length = 256\n",
    "\n",
    "def pre_process_tokens(tokens) -> str:\n",
    "    parsed = ' '.join(tokens).replace('\\n', ' ')\n",
    "    parsed = ' '.join(parsed.strip().split())\n",
    "    return parsed\n",
    "\n",
    "# TODO: rename to 'generate_embeddings'\n",
    "def get_embeddings(pairs: List[MongoDbPairDoc]):\n",
    "  codes = [pre_process_tokens(pair['code_tokens']) for pair in pairs]\n",
    "  comments = [pre_process_tokens(pair['comment_tokens']) for pair in pairs]\n",
    "\n",
    "  return [generate_embeddings(codes), generate_embeddings(comments)]\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = tf.cast(tf.tile(tf.expand_dims(attention_mask, -1), [1, 1, token_embeddings.shape[-1]]), tf.float32)\n",
    "    return tf.math.reduce_sum(token_embeddings * input_mask_expanded, 1) / tf.math.maximum(tf.math.reduce_sum(input_mask_expanded, 1), 1e-9)\n",
    "\n",
    "# TODO: rename to generate_sentences_embeddings\n",
    "def generate_embeddings(sentences: List[str]):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "    model = TFAutoModel.from_pretrained(\"bert-large-uncased\")\n",
    "    \n",
    "    encoded_input = tokenizer(\n",
    "        sentences, \n",
    "        padding='max_length', \n",
    "        max_length=embedding_max_length, \n",
    "        truncation=True, \n",
    "        return_tensors='tf',\n",
    "    )\n",
    "    model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_count = 5000\n",
    "test_samples_count = 1000\n",
    "valid_samples_count = 1000\n",
    "embedding_dataset_dir = '../datasets/embeddings/'\n",
    "db_client = MongoDbClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove unused functions\n",
    "def save_embeddings_dataset(pairs: List[MongoDbPairDoc], batch_size = 100):\n",
    "  stored_pairs_ids = { pair_id.replace('.npy', ''): \"\" for pair_id in os.listdir(embedding_dataset_dir) if pair_id.endswith('.npy') }\n",
    "  new_pairs = [pair for pair in pairs if str(pair['_id']) not in stored_pairs_ids]\n",
    "\n",
    "  with tqdm(total=len(new_pairs), desc=f\"Saving {len(new_pairs)} pairs into embedding dataset\") as progress_bar:\n",
    "    for batch_pairs in more_itertools.chunked(new_pairs, batch_size):\n",
    "      [code_embeddings, comment_embeddings] = get_embeddings(batch_pairs)\n",
    "      for pair, code_embedding, comment_embedding in zip(batch_pairs, code_embeddings, comment_embeddings):\n",
    "        np.save(os.path.join(embedding_dataset_dir, f'{pair[\"_id\"]}.npy'), [code_embedding, comment_embedding])\n",
    "      progress_bar.update(len(batch_pairs))\n",
    "\n",
    "def get_stored_embeddings(pair_id: str):\n",
    "  return np.load(os.path.join(embedding_dataset_dir, f'{pair_id}.npy'))\n",
    "\n",
    "def validate_embeddings_dataset(pairs: List[MongoDbPairDoc]):\n",
    "  pairs_len = len(pairs)\n",
    "  if pairs_len > 100:\n",
    "    raise ValueError(\"The pairs length should be <= 100\")\n",
    "\n",
    "  random_index = random.randint(0, pairs_len - 1)\n",
    "  [code_embeddings, comment_embeddings] = get_embeddings(pairs)\n",
    "  [store_code_emb, store_comment_emb] = get_stored_embeddings(str(pairs[random_index][\"_id\"]))\n",
    "\n",
    "  correct_indexes = []\n",
    "  for index, (code_emb, comment_emb) in enumerate(zip(code_embeddings, comment_embeddings)):\n",
    "    is_correct = np.array_equal(code_emb, store_code_emb) and np.array_equal(comment_emb, store_comment_emb)\n",
    "    if is_correct:\n",
    "      correct_indexes.append(index)\n",
    "  \n",
    "  return len(correct_indexes) == 1 and correct_indexes[0] == random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(pairs_ids: List[str], for_training = True) -> tf.data.Dataset:\n",
    "  def dataset_generator():\n",
    "    if for_training:\n",
    "      negative_pairs_ids = shuffle(pairs_ids)\n",
    "      for pair_id, negative_pair_id in zip(pairs_ids, negative_pairs_ids):\n",
    "        [code_embedding, comment_embedding] = get_stored_embeddings(pair_id)\n",
    "        [_, negative_comment_embedding] = get_stored_embeddings(negative_pair_id)\n",
    "\n",
    "        yield {\n",
    "          \"code_embedding\": code_embedding,\n",
    "          \"comment_embedding\": comment_embedding,\n",
    "        }, 1.0\n",
    "\n",
    "        yield {\n",
    "          \"code_embedding\": code_embedding,\n",
    "          \"comment_embedding\": negative_comment_embedding,\n",
    "        }, 0.0\n",
    "    else:\n",
    "      for pair_id in pairs_ids:\n",
    "        [code_embedding, comment_embedding] = get_stored_embeddings(pair_id)\n",
    "        yield {\n",
    "          \"code_embedding\": code_embedding,\n",
    "          \"comment_embedding\": comment_embedding,\n",
    "        }\n",
    "  \n",
    "  training_output_types = ({\n",
    "    \"code_embedding\": tf.float32, \n",
    "    \"comment_embedding\": tf.float32,\n",
    "  }, tf.float16)\n",
    "  test_output_types = {\n",
    "    \"code_embedding\": tf.float32, \n",
    "    \"comment_embedding\": tf.float32,\n",
    "  }\n",
    "\n",
    "  return tf.data.Dataset.from_generator(dataset_generator, output_types=training_output_types if for_training else test_output_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(train_samples_count)))\n",
    "# save_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"test\", \"language\": \"python\" }).limit(test_samples_count)))\n",
    "# save_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(valid_samples_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_train_correct = validate_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(100)))\n",
    "# is_test_correct = validate_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"test\", \"language\": \"python\" }).limit(100)))\n",
    "# is_valid_correct = validate_embeddings_dataset(list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(100)))\n",
    "\n",
    "# print(f'is train dataset correct? {is_train_correct}') \n",
    "# print(f'is test dataset correct? {is_test_correct}') \n",
    "# print(f'is valid dataset correct? {is_valid_correct}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumDenseLayers = Literal[2, 4, 8]\n",
    "input_shape = (1024) # TODO: Use variables\n",
    "hidden_layer_activation = 'tanh'\n",
    "output_activation = 'sigmoid'\n",
    "dense_layers: Dict[NumDenseLayers, List] = {\n",
    "  2: [\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ],\n",
    "  4: [\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "  8: [\n",
    "    Dense(800, activation=hidden_layer_activation),\n",
    "    Dense(600, activation=hidden_layer_activation),\n",
    "    Dense(500, activation=hidden_layer_activation),\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(300, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "}\n",
    "dropout_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveLoss(Loss):\n",
    "   def __init__(self, reduction=losses_utils.ReductionV2.AUTO, name=\"constrastive_loss\", margin=1):\n",
    "      self.margin = margin\n",
    "      super().__init__(reduction, name)\n",
    "\n",
    "   def call(self, y_true, y_pred):\n",
    "      square_pred = tf.math.square(y_pred)\n",
    "      margin_square = tf.math.square(tf.math.maximum(self.margin - (y_pred), 0))\n",
    "      return tf.math.reduce_mean(\n",
    "        (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "      )\n",
    "\n",
    "def build_model(num_hidden_layers: NumDenseLayers):\n",
    "  code_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "\n",
    "  concatenated_inputs = Concatenate()([code_input, comment_input])\n",
    "  hidden_layers = Sequential(dense_layers[num_hidden_layers], name=\"hidden_layers\")(concatenated_inputs)\n",
    "  output = Dense(1, activation=output_activation, name=\"output\")(hidden_layers)\n",
    "  model = Model(\n",
    "    inputs=[code_input, comment_input],\n",
    "    outputs=output,\n",
    "    name=\"embedding_comparator\"\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_comparator = build_model(num_hidden_layers=2)\n",
    "tensor_board_callback = callbacks.TensorBoard(log_dir=f\"../logs/scalars/{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "train_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(train_samples_count))]\n",
    "valid_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(valid_samples_count))]\n",
    "\n",
    "pairs_dataset = create_tf_dataset(train_pairs).shuffle(buffer_size=int(train_samples_count * 0.4)).batch(100)\n",
    "valid_pairs = create_tf_dataset(valid_pairs).batch(100)\n",
    "\n",
    "# results = embedding_comparator.fit(\n",
    "#     pairs_dataset,\n",
    "#     validation_data=valid_pairs,\n",
    "#     epochs=10,\n",
    "#     callbacks=[tensor_board_callback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "  [x, y] = vects\n",
    "  sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=0)\n",
    "  distance = tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "  return distance\n",
    "\n",
    "def build_siamese_model():\n",
    "  code_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "  similarity_score = Dot(normalize=True, axes=1)([code_embedding_input, comment_embedding_input])\n",
    "\n",
    "  # normal_layer = BatchNormalization()(concatenated_inputs)\n",
    "  output_layer = Dense(1, activation=\"sigmoid\")(similarity_score)\n",
    "  model = Model(inputs=[code_embedding_input, comment_embedding_input], outputs=output_layer, name=\"siamese_model\")\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 6s 47ms/step - loss: 0.2611 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2576 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 5s 44ms/step - loss: 0.2552 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2533 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 5s 41ms/step - loss: 0.2521 - binary_accuracy: 0.4996 - precision: 0.3571 - recall: 0.0010 - val_loss: 0.2512 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2508 - binary_accuracy: 0.4975 - precision: 0.3967 - recall: 0.0096 - val_loss: 0.2504 - val_binary_accuracy: 0.4985 - val_precision: 0.4545 - val_recall: 0.0150\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.2503 - binary_accuracy: 0.4842 - precision: 0.3609 - recall: 0.0410 - val_loss: 0.2502 - val_binary_accuracy: 0.4785 - val_precision: 0.3453 - val_recall: 0.0480\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 0.2501 - binary_accuracy: 0.4515 - precision: 0.3537 - recall: 0.1172 - val_loss: 0.2501 - val_binary_accuracy: 0.4375 - val_precision: 0.3434 - val_recall: 0.1370\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 44ms/step - loss: 0.2501 - binary_accuracy: 0.4216 - precision: 0.3704 - recall: 0.2240 - val_loss: 0.2500 - val_binary_accuracy: 0.4280 - val_precision: 0.3916 - val_recall: 0.2600\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 5s 42ms/step - loss: 0.2501 - binary_accuracy: 0.4165 - precision: 0.3854 - recall: 0.2808 - val_loss: 0.2500 - val_binary_accuracy: 0.4115 - val_precision: 0.4058 - val_recall: 0.3810\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.2501 - binary_accuracy: 0.4076 - precision: 0.3947 - recall: 0.3464 - val_loss: 0.2500 - val_binary_accuracy: 0.4195 - val_precision: 0.4110 - val_recall: 0.3720\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 5s 42ms/step - loss: 0.2501 - binary_accuracy: 0.4098 - precision: 0.4071 - recall: 0.3952 - val_loss: 0.2500 - val_binary_accuracy: 0.4050 - val_precision: 0.4006 - val_recall: 0.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x298f58a60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model = build_siamese_model()\n",
    "siamese_model.fit(\n",
    "    pairs_dataset,\n",
    "    validation_data=valid_pairs,\n",
    "    epochs=10,\n",
    "    callbacks=[tensor_board_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(test_samples_count))]\n",
    "test_dataset = create_tf_dataset(test_pairs, for_training=False).batch(100)\n",
    "\n",
    "predicts = siamese_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49001256],\n",
       "       [0.48823547],\n",
       "       [0.49016502],\n",
       "       [0.49716097],\n",
       "       [0.5032835 ],\n",
       "       [0.4932924 ],\n",
       "       [0.5113383 ],\n",
       "       [0.49203396],\n",
       "       [0.49851727],\n",
       "       [0.5054143 ],\n",
       "       [0.49279276],\n",
       "       [0.49300584],\n",
       "       [0.49157286],\n",
       "       [0.49411175],\n",
       "       [0.49608177],\n",
       "       [0.49472323],\n",
       "       [0.5002973 ],\n",
       "       [0.49251303],\n",
       "       [0.49543485],\n",
       "       [0.49366418],\n",
       "       [0.4883237 ],\n",
       "       [0.49596703],\n",
       "       [0.49617872],\n",
       "       [0.49846917],\n",
       "       [0.49569196],\n",
       "       [0.49192384],\n",
       "       [0.49165168],\n",
       "       [0.49066103],\n",
       "       [0.49273133],\n",
       "       [0.49222624],\n",
       "       [0.4952268 ],\n",
       "       [0.49444643],\n",
       "       [0.5023585 ],\n",
       "       [0.49322832],\n",
       "       [0.50029457],\n",
       "       [0.4948389 ],\n",
       "       [0.49472323],\n",
       "       [0.49787334],\n",
       "       [0.49762088],\n",
       "       [0.49765688],\n",
       "       [0.49834386],\n",
       "       [0.5005353 ],\n",
       "       [0.4942247 ],\n",
       "       [0.49851975],\n",
       "       [0.49824095],\n",
       "       [0.500186  ],\n",
       "       [0.49653998],\n",
       "       [0.49246445],\n",
       "       [0.50068134],\n",
       "       [0.48994425],\n",
       "       [0.49183962],\n",
       "       [0.49740168],\n",
       "       [0.49909714],\n",
       "       [0.48790288],\n",
       "       [0.48791856],\n",
       "       [0.49222368],\n",
       "       [0.4923674 ],\n",
       "       [0.4992072 ],\n",
       "       [0.50348794],\n",
       "       [0.4945964 ],\n",
       "       [0.49646512],\n",
       "       [0.4943307 ],\n",
       "       [0.4956799 ],\n",
       "       [0.48938653],\n",
       "       [0.5117356 ],\n",
       "       [0.4974157 ],\n",
       "       [0.49312636],\n",
       "       [0.48882407],\n",
       "       [0.49644843],\n",
       "       [0.49680877],\n",
       "       [0.4936547 ],\n",
       "       [0.4934813 ],\n",
       "       [0.4922987 ],\n",
       "       [0.50416094],\n",
       "       [0.5054128 ],\n",
       "       [0.50069124],\n",
       "       [0.509385  ],\n",
       "       [0.49913466],\n",
       "       [0.50310224],\n",
       "       [0.5042888 ],\n",
       "       [0.5024469 ],\n",
       "       [0.5038432 ],\n",
       "       [0.492935  ],\n",
       "       [0.49830785],\n",
       "       [0.49745184],\n",
       "       [0.49786457],\n",
       "       [0.510792  ],\n",
       "       [0.501914  ],\n",
       "       [0.48892012],\n",
       "       [0.48940447],\n",
       "       [0.50212765],\n",
       "       [0.48949048],\n",
       "       [0.5077319 ],\n",
       "       [0.51028013],\n",
       "       [0.5061664 ],\n",
       "       [0.4940068 ],\n",
       "       [0.49906975],\n",
       "       [0.4933577 ],\n",
       "       [0.49121183],\n",
       "       [0.4913515 ],\n",
       "       [0.48759818],\n",
       "       [0.49418986],\n",
       "       [0.51096606],\n",
       "       [0.493165  ],\n",
       "       [0.4941158 ],\n",
       "       [0.4958111 ],\n",
       "       [0.501116  ],\n",
       "       [0.4996227 ],\n",
       "       [0.4959504 ],\n",
       "       [0.49597478],\n",
       "       [0.5214507 ],\n",
       "       [0.49199557],\n",
       "       [0.49371496],\n",
       "       [0.49516237],\n",
       "       [0.49547425],\n",
       "       [0.49905252],\n",
       "       [0.50044143],\n",
       "       [0.4918117 ],\n",
       "       [0.49121574],\n",
       "       [0.49562648],\n",
       "       [0.5076364 ],\n",
       "       [0.5185608 ],\n",
       "       [0.509256  ],\n",
       "       [0.5013169 ],\n",
       "       [0.50183856],\n",
       "       [0.49965942],\n",
       "       [0.49761602],\n",
       "       [0.49227297],\n",
       "       [0.50301087],\n",
       "       [0.49399278],\n",
       "       [0.49803644],\n",
       "       [0.49196672],\n",
       "       [0.49153507],\n",
       "       [0.4951229 ],\n",
       "       [0.49107477],\n",
       "       [0.49325523],\n",
       "       [0.48878658],\n",
       "       [0.49893054],\n",
       "       [0.48767734],\n",
       "       [0.49791807],\n",
       "       [0.4928692 ],\n",
       "       [0.495551  ],\n",
       "       [0.49123558],\n",
       "       [0.49488947],\n",
       "       [0.4973512 ],\n",
       "       [0.49406424],\n",
       "       [0.49778238],\n",
       "       [0.49069536],\n",
       "       [0.49503842],\n",
       "       [0.49324304],\n",
       "       [0.49450502],\n",
       "       [0.49771205],\n",
       "       [0.4897288 ],\n",
       "       [0.49610984],\n",
       "       [0.5012634 ],\n",
       "       [0.49211314],\n",
       "       [0.4982045 ],\n",
       "       [0.49675563],\n",
       "       [0.5080133 ],\n",
       "       [0.4895242 ],\n",
       "       [0.49989787],\n",
       "       [0.51135087],\n",
       "       [0.51189274],\n",
       "       [0.48931095],\n",
       "       [0.49234325],\n",
       "       [0.4921076 ],\n",
       "       [0.5065395 ],\n",
       "       [0.50018525],\n",
       "       [0.48990607],\n",
       "       [0.49427897],\n",
       "       [0.4936695 ],\n",
       "       [0.4973886 ],\n",
       "       [0.49492624],\n",
       "       [0.49529105],\n",
       "       [0.49116102],\n",
       "       [0.49139395],\n",
       "       [0.49297035],\n",
       "       [0.48892212],\n",
       "       [0.49550644],\n",
       "       [0.49931437],\n",
       "       [0.49148184],\n",
       "       [0.49118772],\n",
       "       [0.48560438],\n",
       "       [0.49272156],\n",
       "       [0.4914116 ],\n",
       "       [0.49620783],\n",
       "       [0.49324697],\n",
       "       [0.4931518 ],\n",
       "       [0.5054812 ],\n",
       "       [0.4988404 ],\n",
       "       [0.49506855],\n",
       "       [0.49192637],\n",
       "       [0.5097686 ],\n",
       "       [0.50589097],\n",
       "       [0.5006654 ],\n",
       "       [0.50046146],\n",
       "       [0.5046454 ],\n",
       "       [0.4907971 ],\n",
       "       [0.49304926],\n",
       "       [0.49502206],\n",
       "       [0.5066604 ],\n",
       "       [0.4920343 ],\n",
       "       [0.50451934],\n",
       "       [0.4962503 ],\n",
       "       [0.4994228 ],\n",
       "       [0.49914387],\n",
       "       [0.49329808],\n",
       "       [0.4891733 ],\n",
       "       [0.50468355],\n",
       "       [0.49584755],\n",
       "       [0.5018315 ],\n",
       "       [0.48994243],\n",
       "       [0.50163305],\n",
       "       [0.51773345],\n",
       "       [0.50740474],\n",
       "       [0.5094678 ],\n",
       "       [0.49870506],\n",
       "       [0.49251327],\n",
       "       [0.49256116],\n",
       "       [0.4937105 ],\n",
       "       [0.49389005],\n",
       "       [0.5130292 ],\n",
       "       [0.49476978],\n",
       "       [0.4943332 ],\n",
       "       [0.49054432],\n",
       "       [0.4930175 ],\n",
       "       [0.5044169 ],\n",
       "       [0.5032443 ],\n",
       "       [0.5051393 ],\n",
       "       [0.5000876 ],\n",
       "       [0.49695003],\n",
       "       [0.4909971 ],\n",
       "       [0.4900764 ],\n",
       "       [0.49453288],\n",
       "       [0.49388355],\n",
       "       [0.501766  ],\n",
       "       [0.4943441 ],\n",
       "       [0.4942199 ],\n",
       "       [0.4994341 ],\n",
       "       [0.49739343],\n",
       "       [0.4917477 ],\n",
       "       [0.49222946],\n",
       "       [0.5067325 ],\n",
       "       [0.50859   ],\n",
       "       [0.495697  ],\n",
       "       [0.49976003],\n",
       "       [0.49511123],\n",
       "       [0.49908313],\n",
       "       [0.49077362],\n",
       "       [0.48715407],\n",
       "       [0.5008857 ],\n",
       "       [0.49726346],\n",
       "       [0.49572858],\n",
       "       [0.4896993 ],\n",
       "       [0.4969094 ],\n",
       "       [0.49102408],\n",
       "       [0.49271622],\n",
       "       [0.4971344 ],\n",
       "       [0.49633387],\n",
       "       [0.49188524],\n",
       "       [0.49736655],\n",
       "       [0.49427372],\n",
       "       [0.4957871 ],\n",
       "       [0.5089639 ],\n",
       "       [0.49260175],\n",
       "       [0.49523526],\n",
       "       [0.5047599 ],\n",
       "       [0.49510387],\n",
       "       [0.4993282 ],\n",
       "       [0.5019079 ],\n",
       "       [0.49526533],\n",
       "       [0.49500814],\n",
       "       [0.49094522],\n",
       "       [0.49794272],\n",
       "       [0.4949565 ],\n",
       "       [0.4895137 ],\n",
       "       [0.494092  ],\n",
       "       [0.49108002],\n",
       "       [0.496803  ],\n",
       "       [0.4984597 ],\n",
       "       [0.4929868 ],\n",
       "       [0.49586606],\n",
       "       [0.4932927 ],\n",
       "       [0.4915978 ],\n",
       "       [0.49017397],\n",
       "       [0.48992744],\n",
       "       [0.49222717],\n",
       "       [0.49636817],\n",
       "       [0.4901104 ],\n",
       "       [0.49186897],\n",
       "       [0.5015958 ],\n",
       "       [0.49373412],\n",
       "       [0.500857  ],\n",
       "       [0.49740312],\n",
       "       [0.4899318 ],\n",
       "       [0.495321  ],\n",
       "       [0.48546442],\n",
       "       [0.4899881 ],\n",
       "       [0.49057472],\n",
       "       [0.49152297],\n",
       "       [0.49101418],\n",
       "       [0.49871892],\n",
       "       [0.515499  ],\n",
       "       [0.5153897 ],\n",
       "       [0.5059479 ],\n",
       "       [0.50186515],\n",
       "       [0.49548778],\n",
       "       [0.50502336],\n",
       "       [0.5026242 ],\n",
       "       [0.5231693 ],\n",
       "       [0.5268213 ],\n",
       "       [0.53378516],\n",
       "       [0.5264456 ],\n",
       "       [0.5279759 ],\n",
       "       [0.53321016],\n",
       "       [0.5337736 ],\n",
       "       [0.5317792 ],\n",
       "       [0.54086995],\n",
       "       [0.5378662 ],\n",
       "       [0.5363215 ],\n",
       "       [0.53381276],\n",
       "       [0.5379365 ],\n",
       "       [0.5289946 ],\n",
       "       [0.49359554],\n",
       "       [0.49882534],\n",
       "       [0.5105391 ],\n",
       "       [0.48929667],\n",
       "       [0.5245806 ],\n",
       "       [0.5078181 ],\n",
       "       [0.49750707],\n",
       "       [0.50382   ],\n",
       "       [0.5009478 ],\n",
       "       [0.50684214],\n",
       "       [0.49855793],\n",
       "       [0.49484193],\n",
       "       [0.500078  ],\n",
       "       [0.51869506],\n",
       "       [0.4965937 ],\n",
       "       [0.49778488],\n",
       "       [0.5036211 ],\n",
       "       [0.51115847],\n",
       "       [0.49648637],\n",
       "       [0.5046111 ],\n",
       "       [0.51752406],\n",
       "       [0.49599603],\n",
       "       [0.5096958 ],\n",
       "       [0.49120948],\n",
       "       [0.49955645],\n",
       "       [0.513953  ],\n",
       "       [0.50604004],\n",
       "       [0.50787157],\n",
       "       [0.49092108],\n",
       "       [0.485201  ],\n",
       "       [0.48213062],\n",
       "       [0.4947782 ],\n",
       "       [0.49750093],\n",
       "       [0.4957779 ],\n",
       "       [0.49828488],\n",
       "       [0.50452834],\n",
       "       [0.5082641 ],\n",
       "       [0.49548015],\n",
       "       [0.50531477],\n",
       "       [0.48853347],\n",
       "       [0.49055982],\n",
       "       [0.4882482 ],\n",
       "       [0.48607266],\n",
       "       [0.48681837],\n",
       "       [0.4907451 ],\n",
       "       [0.50419027],\n",
       "       [0.48710695],\n",
       "       [0.49312907],\n",
       "       [0.50703114],\n",
       "       [0.49543393],\n",
       "       [0.4932081 ],\n",
       "       [0.49505454],\n",
       "       [0.4955077 ],\n",
       "       [0.4915869 ],\n",
       "       [0.49339738],\n",
       "       [0.4963752 ],\n",
       "       [0.49118483],\n",
       "       [0.5001949 ],\n",
       "       [0.4988216 ],\n",
       "       [0.5104395 ],\n",
       "       [0.500122  ],\n",
       "       [0.48646104],\n",
       "       [0.48903129],\n",
       "       [0.49485508],\n",
       "       [0.49245462],\n",
       "       [0.5031462 ],\n",
       "       [0.4966254 ],\n",
       "       [0.49531236],\n",
       "       [0.49192014],\n",
       "       [0.4874146 ],\n",
       "       [0.49802148],\n",
       "       [0.49979302],\n",
       "       [0.50095445],\n",
       "       [0.49324015],\n",
       "       [0.49845138],\n",
       "       [0.4923474 ],\n",
       "       [0.50509685],\n",
       "       [0.50085515],\n",
       "       [0.49206144],\n",
       "       [0.49815214],\n",
       "       [0.51637435],\n",
       "       [0.5052366 ],\n",
       "       [0.4887445 ],\n",
       "       [0.48824906],\n",
       "       [0.49319106],\n",
       "       [0.5050801 ],\n",
       "       [0.49086684],\n",
       "       [0.4953849 ],\n",
       "       [0.4937822 ],\n",
       "       [0.49405667],\n",
       "       [0.49315622],\n",
       "       [0.4971555 ],\n",
       "       [0.50481176],\n",
       "       [0.5011775 ],\n",
       "       [0.50217617],\n",
       "       [0.49552277],\n",
       "       [0.49312496],\n",
       "       [0.5012606 ],\n",
       "       [0.5091711 ],\n",
       "       [0.5039828 ],\n",
       "       [0.50140035],\n",
       "       [0.50370175],\n",
       "       [0.49482274],\n",
       "       [0.4880533 ],\n",
       "       [0.49139202],\n",
       "       [0.49595028],\n",
       "       [0.50182414],\n",
       "       [0.49205172],\n",
       "       [0.49173322],\n",
       "       [0.49377993],\n",
       "       [0.49477574],\n",
       "       [0.50299126],\n",
       "       [0.5013302 ],\n",
       "       [0.49531564],\n",
       "       [0.4955162 ],\n",
       "       [0.49415573],\n",
       "       [0.49446538],\n",
       "       [0.51001173],\n",
       "       [0.49972382],\n",
       "       [0.49718165],\n",
       "       [0.5063726 ],\n",
       "       [0.50292253],\n",
       "       [0.49885845],\n",
       "       [0.5132866 ],\n",
       "       [0.5172761 ],\n",
       "       [0.5011957 ],\n",
       "       [0.50392234],\n",
       "       [0.5019107 ],\n",
       "       [0.5071025 ],\n",
       "       [0.5031774 ],\n",
       "       [0.5016367 ],\n",
       "       [0.49829152],\n",
       "       [0.4925793 ],\n",
       "       [0.49452698],\n",
       "       [0.4931335 ],\n",
       "       [0.49691883],\n",
       "       [0.4944673 ],\n",
       "       [0.5032946 ],\n",
       "       [0.49590376],\n",
       "       [0.49753258],\n",
       "       [0.49552712],\n",
       "       [0.50166106],\n",
       "       [0.5018081 ],\n",
       "       [0.49290708],\n",
       "       [0.5000838 ],\n",
       "       [0.4973031 ],\n",
       "       [0.49752808],\n",
       "       [0.49180853],\n",
       "       [0.49661228],\n",
       "       [0.49368945],\n",
       "       [0.49877906],\n",
       "       [0.488708  ],\n",
       "       [0.50573313],\n",
       "       [0.49645618],\n",
       "       [0.49606687],\n",
       "       [0.4894008 ],\n",
       "       [0.5017362 ],\n",
       "       [0.50398713],\n",
       "       [0.488631  ],\n",
       "       [0.49345362],\n",
       "       [0.49465063],\n",
       "       [0.4978315 ],\n",
       "       [0.49760446],\n",
       "       [0.49263653],\n",
       "       [0.49950233],\n",
       "       [0.49016526],\n",
       "       [0.48584452],\n",
       "       [0.5018302 ],\n",
       "       [0.50084645],\n",
       "       [0.5003698 ],\n",
       "       [0.48719594],\n",
       "       [0.5026241 ],\n",
       "       [0.4988918 ],\n",
       "       [0.50118196],\n",
       "       [0.504575  ],\n",
       "       [0.5017086 ],\n",
       "       [0.50282913],\n",
       "       [0.5045335 ],\n",
       "       [0.49784827],\n",
       "       [0.4986721 ],\n",
       "       [0.49433768],\n",
       "       [0.5106813 ],\n",
       "       [0.49027064],\n",
       "       [0.5131565 ],\n",
       "       [0.5005181 ],\n",
       "       [0.49332345],\n",
       "       [0.48670962],\n",
       "       [0.5004902 ],\n",
       "       [0.5021604 ],\n",
       "       [0.50319916],\n",
       "       [0.5059912 ],\n",
       "       [0.5040069 ],\n",
       "       [0.50507164],\n",
       "       [0.5058235 ],\n",
       "       [0.5025852 ],\n",
       "       [0.49519837],\n",
       "       [0.49609515],\n",
       "       [0.5099014 ],\n",
       "       [0.5066721 ],\n",
       "       [0.5047728 ],\n",
       "       [0.4987563 ],\n",
       "       [0.4970141 ],\n",
       "       [0.5064697 ],\n",
       "       [0.5121036 ],\n",
       "       [0.50249183],\n",
       "       [0.506542  ],\n",
       "       [0.5044787 ],\n",
       "       [0.50390774],\n",
       "       [0.5010358 ],\n",
       "       [0.5071766 ],\n",
       "       [0.5105853 ],\n",
       "       [0.5014584 ],\n",
       "       [0.5011444 ],\n",
       "       [0.4997636 ],\n",
       "       [0.4879433 ],\n",
       "       [0.48698214],\n",
       "       [0.511517  ],\n",
       "       [0.50527406],\n",
       "       [0.512248  ],\n",
       "       [0.4895603 ],\n",
       "       [0.48655087],\n",
       "       [0.48690814],\n",
       "       [0.48775083],\n",
       "       [0.48572406],\n",
       "       [0.48920035],\n",
       "       [0.48591122],\n",
       "       [0.4985104 ],\n",
       "       [0.48762903],\n",
       "       [0.49214306],\n",
       "       [0.49526766],\n",
       "       [0.4896935 ],\n",
       "       [0.4888267 ],\n",
       "       [0.4939915 ],\n",
       "       [0.49243966],\n",
       "       [0.4929474 ],\n",
       "       [0.49182314],\n",
       "       [0.49657995],\n",
       "       [0.49219942],\n",
       "       [0.49716946],\n",
       "       [0.49255884],\n",
       "       [0.49713835],\n",
       "       [0.49218765],\n",
       "       [0.4922073 ],\n",
       "       [0.49415812],\n",
       "       [0.4929946 ],\n",
       "       [0.4947649 ],\n",
       "       [0.49333203],\n",
       "       [0.49419603],\n",
       "       [0.4925615 ],\n",
       "       [0.48985443],\n",
       "       [0.49293417],\n",
       "       [0.5015649 ],\n",
       "       [0.49450228],\n",
       "       [0.50366044],\n",
       "       [0.49197555],\n",
       "       [0.488989  ],\n",
       "       [0.50353706],\n",
       "       [0.49697393],\n",
       "       [0.48701316],\n",
       "       [0.49036688],\n",
       "       [0.49136576],\n",
       "       [0.4919287 ],\n",
       "       [0.49897525],\n",
       "       [0.4890805 ],\n",
       "       [0.49047914],\n",
       "       [0.48927853],\n",
       "       [0.49706292],\n",
       "       [0.49396557],\n",
       "       [0.4941441 ],\n",
       "       [0.4891376 ],\n",
       "       [0.49016774],\n",
       "       [0.49625087],\n",
       "       [0.48910555],\n",
       "       [0.49492568],\n",
       "       [0.4975046 ],\n",
       "       [0.49758688],\n",
       "       [0.49693215],\n",
       "       [0.5024595 ],\n",
       "       [0.49611336],\n",
       "       [0.50237817],\n",
       "       [0.4944751 ],\n",
       "       [0.49385306],\n",
       "       [0.50181705],\n",
       "       [0.48815143],\n",
       "       [0.49252483],\n",
       "       [0.4938876 ],\n",
       "       [0.49515378],\n",
       "       [0.48908192],\n",
       "       [0.49488947],\n",
       "       [0.49039772],\n",
       "       [0.48372668],\n",
       "       [0.4839457 ],\n",
       "       [0.48984   ],\n",
       "       [0.4918012 ],\n",
       "       [0.5121071 ],\n",
       "       [0.50348186],\n",
       "       [0.49457324],\n",
       "       [0.494159  ],\n",
       "       [0.5056539 ],\n",
       "       [0.5014757 ],\n",
       "       [0.4962042 ],\n",
       "       [0.49888882],\n",
       "       [0.49790773],\n",
       "       [0.5060952 ],\n",
       "       [0.4912375 ],\n",
       "       [0.4915798 ],\n",
       "       [0.49341235],\n",
       "       [0.49089012],\n",
       "       [0.49278626],\n",
       "       [0.4930648 ],\n",
       "       [0.49537915],\n",
       "       [0.4878421 ],\n",
       "       [0.49318647],\n",
       "       [0.5015018 ],\n",
       "       [0.4987277 ],\n",
       "       [0.49257445],\n",
       "       [0.49931115],\n",
       "       [0.49055028],\n",
       "       [0.49219966],\n",
       "       [0.4925069 ],\n",
       "       [0.49428368],\n",
       "       [0.50104   ],\n",
       "       [0.48792887],\n",
       "       [0.50120336],\n",
       "       [0.5000383 ],\n",
       "       [0.49355918],\n",
       "       [0.492549  ],\n",
       "       [0.49139902],\n",
       "       [0.4941741 ],\n",
       "       [0.48988807],\n",
       "       [0.49081066],\n",
       "       [0.49131402],\n",
       "       [0.49007535],\n",
       "       [0.4952776 ],\n",
       "       [0.49107558],\n",
       "       [0.49322307],\n",
       "       [0.50256157],\n",
       "       [0.49254605],\n",
       "       [0.50756794],\n",
       "       [0.49366987],\n",
       "       [0.49596962],\n",
       "       [0.48931745],\n",
       "       [0.50207275],\n",
       "       [0.48972493],\n",
       "       [0.49768853],\n",
       "       [0.5052774 ],\n",
       "       [0.49607897],\n",
       "       [0.4954083 ],\n",
       "       [0.49121442],\n",
       "       [0.50041956],\n",
       "       [0.5033226 ],\n",
       "       [0.50911313],\n",
       "       [0.49657395],\n",
       "       [0.49759585],\n",
       "       [0.4981976 ],\n",
       "       [0.4972438 ],\n",
       "       [0.4971896 ],\n",
       "       [0.497102  ],\n",
       "       [0.48950556],\n",
       "       [0.49785668],\n",
       "       [0.50156856],\n",
       "       [0.49492672],\n",
       "       [0.49482116],\n",
       "       [0.50036734],\n",
       "       [0.4975353 ],\n",
       "       [0.496707  ],\n",
       "       [0.5070475 ],\n",
       "       [0.505686  ],\n",
       "       [0.5055629 ],\n",
       "       [0.508208  ],\n",
       "       [0.49870315],\n",
       "       [0.4902425 ],\n",
       "       [0.49420786],\n",
       "       [0.49607322],\n",
       "       [0.48789153],\n",
       "       [0.49221987],\n",
       "       [0.49617332],\n",
       "       [0.48958677],\n",
       "       [0.48759264],\n",
       "       [0.5041479 ],\n",
       "       [0.50435394],\n",
       "       [0.49842888],\n",
       "       [0.4990776 ],\n",
       "       [0.48686805],\n",
       "       [0.49426877],\n",
       "       [0.49396485],\n",
       "       [0.49171397],\n",
       "       [0.4894995 ],\n",
       "       [0.49926686],\n",
       "       [0.49068654],\n",
       "       [0.4923419 ],\n",
       "       [0.48992977],\n",
       "       [0.49469692],\n",
       "       [0.49056268],\n",
       "       [0.49187952],\n",
       "       [0.5007786 ],\n",
       "       [0.5038216 ],\n",
       "       [0.50232464],\n",
       "       [0.49765536],\n",
       "       [0.4914497 ],\n",
       "       [0.52002496],\n",
       "       [0.49725983],\n",
       "       [0.5005119 ],\n",
       "       [0.4977613 ],\n",
       "       [0.49292457],\n",
       "       [0.49078023],\n",
       "       [0.5027185 ],\n",
       "       [0.5057331 ],\n",
       "       [0.49808818],\n",
       "       [0.49970347],\n",
       "       [0.5112342 ],\n",
       "       [0.4976136 ],\n",
       "       [0.50804055],\n",
       "       [0.51124215],\n",
       "       [0.51838684],\n",
       "       [0.5084367 ],\n",
       "       [0.5198994 ],\n",
       "       [0.50089616],\n",
       "       [0.48805028],\n",
       "       [0.5029595 ],\n",
       "       [0.50112593],\n",
       "       [0.49679565],\n",
       "       [0.4970345 ],\n",
       "       [0.49765912],\n",
       "       [0.50623155],\n",
       "       [0.49992847],\n",
       "       [0.49776238],\n",
       "       [0.50017697],\n",
       "       [0.5020783 ],\n",
       "       [0.49735686],\n",
       "       [0.49978778],\n",
       "       [0.4963342 ],\n",
       "       [0.49869758],\n",
       "       [0.4901073 ],\n",
       "       [0.5026214 ],\n",
       "       [0.49305087],\n",
       "       [0.49092132],\n",
       "       [0.4905816 ],\n",
       "       [0.48836777],\n",
       "       [0.4895025 ],\n",
       "       [0.49328086],\n",
       "       [0.48978692],\n",
       "       [0.49034193],\n",
       "       [0.49541017],\n",
       "       [0.50154394],\n",
       "       [0.49155417],\n",
       "       [0.49501872],\n",
       "       [0.49099493],\n",
       "       [0.48960346],\n",
       "       [0.4905372 ],\n",
       "       [0.49368158],\n",
       "       [0.48991826],\n",
       "       [0.49374878],\n",
       "       [0.48997322],\n",
       "       [0.4937636 ],\n",
       "       [0.493168  ],\n",
       "       [0.49473733],\n",
       "       [0.5069549 ],\n",
       "       [0.49571335],\n",
       "       [0.4892905 ],\n",
       "       [0.490439  ],\n",
       "       [0.4904179 ],\n",
       "       [0.4959763 ],\n",
       "       [0.50019217],\n",
       "       [0.49124777],\n",
       "       [0.49485344],\n",
       "       [0.49790844],\n",
       "       [0.50845456],\n",
       "       [0.49639437],\n",
       "       [0.50332487],\n",
       "       [0.5038805 ],\n",
       "       [0.4976126 ],\n",
       "       [0.49391106],\n",
       "       [0.508118  ],\n",
       "       [0.5011336 ],\n",
       "       [0.49929345],\n",
       "       [0.50221   ],\n",
       "       [0.5024591 ],\n",
       "       [0.5045308 ],\n",
       "       [0.49764046],\n",
       "       [0.50472724],\n",
       "       [0.5006587 ],\n",
       "       [0.50382817],\n",
       "       [0.50534934],\n",
       "       [0.50241846],\n",
       "       [0.5060708 ],\n",
       "       [0.5021803 ],\n",
       "       [0.4952891 ],\n",
       "       [0.50427336],\n",
       "       [0.49573478],\n",
       "       [0.49825877],\n",
       "       [0.5020705 ],\n",
       "       [0.49635065],\n",
       "       [0.4957247 ],\n",
       "       [0.49769202],\n",
       "       [0.50568736],\n",
       "       [0.49756053],\n",
       "       [0.5067852 ],\n",
       "       [0.4945642 ],\n",
       "       [0.49351266],\n",
       "       [0.4957682 ],\n",
       "       [0.4909482 ],\n",
       "       [0.5054369 ],\n",
       "       [0.50450116],\n",
       "       [0.509671  ],\n",
       "       [0.50623786],\n",
       "       [0.49960703],\n",
       "       [0.4950414 ],\n",
       "       [0.4955168 ],\n",
       "       [0.50743717],\n",
       "       [0.50391734],\n",
       "       [0.51363003],\n",
       "       [0.49937713],\n",
       "       [0.5303565 ],\n",
       "       [0.49373633],\n",
       "       [0.48897794],\n",
       "       [0.49528253],\n",
       "       [0.5121522 ],\n",
       "       [0.4977897 ],\n",
       "       [0.50580025],\n",
       "       [0.49357575],\n",
       "       [0.49538594],\n",
       "       [0.4950683 ],\n",
       "       [0.5284349 ],\n",
       "       [0.49523568],\n",
       "       [0.4970528 ],\n",
       "       [0.5025926 ],\n",
       "       [0.49651235],\n",
       "       [0.49060664],\n",
       "       [0.5030862 ],\n",
       "       [0.4948396 ],\n",
       "       [0.50508475],\n",
       "       [0.5018859 ],\n",
       "       [0.5016772 ],\n",
       "       [0.49970096],\n",
       "       [0.52443635],\n",
       "       [0.48576164],\n",
       "       [0.51194155],\n",
       "       [0.495752  ],\n",
       "       [0.49548087],\n",
       "       [0.4952504 ],\n",
       "       [0.4950697 ],\n",
       "       [0.5053892 ],\n",
       "       [0.4912609 ],\n",
       "       [0.50164974],\n",
       "       [0.48864126],\n",
       "       [0.50020784],\n",
       "       [0.5035091 ],\n",
       "       [0.48730564],\n",
       "       [0.49554303],\n",
       "       [0.5262582 ],\n",
       "       [0.5000888 ],\n",
       "       [0.4986455 ],\n",
       "       [0.4950979 ],\n",
       "       [0.50060964],\n",
       "       [0.50113744],\n",
       "       [0.5068716 ],\n",
       "       [0.506764  ],\n",
       "       [0.49938327],\n",
       "       [0.48872757],\n",
       "       [0.4956843 ],\n",
       "       [0.49674314],\n",
       "       [0.5054487 ],\n",
       "       [0.5055988 ],\n",
       "       [0.50757354],\n",
       "       [0.4989351 ],\n",
       "       [0.5036269 ],\n",
       "       [0.5090604 ],\n",
       "       [0.48899832],\n",
       "       [0.49205762],\n",
       "       [0.49035552],\n",
       "       [0.4997371 ],\n",
       "       [0.4969729 ],\n",
       "       [0.49075255],\n",
       "       [0.490989  ],\n",
       "       [0.49333075],\n",
       "       [0.4919811 ],\n",
       "       [0.49385598],\n",
       "       [0.5065159 ],\n",
       "       [0.49803963],\n",
       "       [0.48830256],\n",
       "       [0.4971634 ],\n",
       "       [0.4938619 ],\n",
       "       [0.49985114],\n",
       "       [0.5023162 ],\n",
       "       [0.501242  ],\n",
       "       [0.48713014],\n",
       "       [0.4923418 ],\n",
       "       [0.49532545],\n",
       "       [0.50405604],\n",
       "       [0.50094765],\n",
       "       [0.5011554 ],\n",
       "       [0.50201833],\n",
       "       [0.49716952],\n",
       "       [0.4996159 ],\n",
       "       [0.49773696],\n",
       "       [0.50246775],\n",
       "       [0.49560365],\n",
       "       [0.4951228 ],\n",
       "       [0.4957825 ],\n",
       "       [0.48792872],\n",
       "       [0.509046  ],\n",
       "       [0.4964685 ],\n",
       "       [0.5022597 ],\n",
       "       [0.5024032 ],\n",
       "       [0.4955831 ],\n",
       "       [0.49620363],\n",
       "       [0.5046207 ],\n",
       "       [0.49587393],\n",
       "       [0.49855497],\n",
       "       [0.5130563 ],\n",
       "       [0.5033213 ],\n",
       "       [0.50681597],\n",
       "       [0.5006241 ],\n",
       "       [0.49914613],\n",
       "       [0.49936482],\n",
       "       [0.48754355],\n",
       "       [0.48632628],\n",
       "       [0.48662588],\n",
       "       [0.4994496 ],\n",
       "       [0.49943382],\n",
       "       [0.48723817],\n",
       "       [0.50102264],\n",
       "       [0.501876  ],\n",
       "       [0.49642774],\n",
       "       [0.51456636],\n",
       "       [0.5054995 ],\n",
       "       [0.4982863 ],\n",
       "       [0.49322516],\n",
       "       [0.5130974 ],\n",
       "       [0.49209422],\n",
       "       [0.50502515],\n",
       "       [0.491273  ],\n",
       "       [0.5084021 ],\n",
       "       [0.4888718 ],\n",
       "       [0.49076438],\n",
       "       [0.48969188],\n",
       "       [0.5029632 ],\n",
       "       [0.5092541 ],\n",
       "       [0.5030025 ],\n",
       "       [0.5022931 ],\n",
       "       [0.5067573 ],\n",
       "       [0.4975406 ],\n",
       "       [0.50982785],\n",
       "       [0.50411403],\n",
       "       [0.49248174],\n",
       "       [0.49739274],\n",
       "       [0.49860877],\n",
       "       [0.48949495],\n",
       "       [0.48921353],\n",
       "       [0.4891016 ],\n",
       "       [0.4897764 ],\n",
       "       [0.48846826],\n",
       "       [0.50678164],\n",
       "       [0.4997648 ],\n",
       "       [0.51037234],\n",
       "       [0.5113311 ],\n",
       "       [0.505166  ],\n",
       "       [0.5086773 ],\n",
       "       [0.5105974 ],\n",
       "       [0.507221  ],\n",
       "       [0.5055337 ],\n",
       "       [0.51935565],\n",
       "       [0.5010526 ],\n",
       "       [0.5138776 ],\n",
       "       [0.5069565 ],\n",
       "       [0.50855565],\n",
       "       [0.50849557],\n",
       "       [0.4993386 ],\n",
       "       [0.504842  ],\n",
       "       [0.50675625],\n",
       "       [0.50474596],\n",
       "       [0.5014189 ],\n",
       "       [0.51350766],\n",
       "       [0.50791043],\n",
       "       [0.5063857 ],\n",
       "       [0.50602746]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
