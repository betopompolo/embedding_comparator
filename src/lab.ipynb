{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, TFAutoModel, logging as transformers_logging\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Literal, List, Iterator\n",
    "from keras import Model, Sequential, callbacks\n",
    "from keras.layers import Dense, Input, Concatenate, Dot\n",
    "from keras.losses import Loss\n",
    "from keras.utils import losses_utils\n",
    "from keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "from keras.optimizers import Adam\n",
    "from mongo_db_client import MongoDbClient\n",
    "import more_itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "def shuffle(list: List) -> List:\n",
    "  shuffled_list = list.copy()\n",
    "  random.shuffle(shuffled_list)\n",
    "  return shuffled_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "  def __init__(self, code_embedding_model=\"microsoft/codebert-base\", comment_embedding_model=\"bert-large-uncased\") -> None:\n",
    "    self.embedding_max_length = 256\n",
    "    self.comment_embedding_model = comment_embedding_model\n",
    "    self.code_embedding_model = code_embedding_model\n",
    "\n",
    "  def from_pairs(self, pairs: List[MongoDbPairDoc], batch_size=100) -> Iterator:\n",
    "    for batch_pairs in more_itertools.chunked(pairs, batch_size):\n",
    "      codes = [self.__pre_process_tokens(pair['code_tokens']) for pair in batch_pairs]\n",
    "      comments = [self.__pre_process_tokens(pair['comment_tokens']) for pair in batch_pairs]\n",
    "\n",
    "      codes_embeddings = self.from_sentences(\n",
    "        sentences=codes,\n",
    "        model=TFAutoModel.from_pretrained(self.code_embedding_model),\n",
    "        tokenizer=AutoTokenizer.from_pretrained(self.code_embedding_model)\n",
    "      )\n",
    "      comments_embeddings = self.from_sentences(\n",
    "        sentences=comments,\n",
    "        model=TFAutoModel.from_pretrained(self.comment_embedding_model),\n",
    "        tokenizer=AutoTokenizer.from_pretrained(self.comment_embedding_model)\n",
    "      )\n",
    "\n",
    "      yield (codes_embeddings, comments_embeddings)\n",
    "\n",
    "  def from_sentences(self, sentences: List[str], tokenizer, model):\n",
    "      encoded_input = tokenizer(\n",
    "          sentences, \n",
    "          padding='max_length', \n",
    "          max_length=self.embedding_max_length,\n",
    "          truncation=True, \n",
    "          return_tensors='tf',\n",
    "      )\n",
    "      model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "      embeddings = self.__mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "      embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
    "      return embeddings\n",
    "  \n",
    "  def __mean_pooling(self, model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = tf.cast(tf.tile(tf.expand_dims(attention_mask, -1), [1, 1, token_embeddings.shape[-1]]), tf.float32)\n",
    "    return tf.math.reduce_sum(token_embeddings * input_mask_expanded, 1) / tf.math.maximum(tf.math.reduce_sum(input_mask_expanded, 1), 1e-9)\n",
    "  \n",
    "  def __pre_process_tokens(self, tokens) -> str:\n",
    "    parsed = ' '.join(tokens).replace('\\n', ' ')\n",
    "    parsed = ' '.join(parsed.strip().split())\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset:\n",
    "  def __init__(self, dataset_dir='../datasets/embeddings/') -> None:\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.embedding_generator = EmbeddingGenerator()\n",
    "\n",
    "  def save(self, pairs: List[MongoDbPairDoc]):\n",
    "    stored_pairs_ids = { pair_id.replace('.npy', ''): \"\" for pair_id in os.listdir(self.dataset_dir) if pair_id.endswith('.npy') }\n",
    "    pairs_to_save = [pair for pair in pairs if str(pair['_id']) not in stored_pairs_ids]\n",
    "    pairs_to_save_count = len(pairs_to_save)\n",
    "    pair_index = 0\n",
    "\n",
    "    with tqdm(total=pairs_to_save_count, desc=f\"Saving {pairs_to_save_count} pairs into embedding dataset\") as progress_bar:\n",
    "      for code_embeddings, comment_embeddings in self.embedding_generator.from_pairs(pairs_to_save):\n",
    "        for code_embedding, comment_embedding in zip(code_embeddings, comment_embeddings):\n",
    "          pair = pairs_to_save[pair_index]\n",
    "          np.save(os.path.join(self.dataset_dir, f'{pair[\"_id\"]}.npy'), [code_embedding.numpy(), comment_embedding.numpy()])\n",
    "\n",
    "          progress_bar.update(1)\n",
    "          pair_index += 1\n",
    "\n",
    "  def get(self, pair_id: str):\n",
    "    return np.load(os.path.join(self.dataset_dir, f'{pair_id}.npy'), allow_pickle=True)\n",
    "\n",
    "  def validate(self, pairs: List[MongoDbPairDoc]):\n",
    "    pairs_len = len(pairs)\n",
    "    if pairs_len > 100:\n",
    "      raise ValueError(\"The pairs length should be <= 100\")\n",
    "\n",
    "    random_index = random.randint(0, pairs_len - 1)\n",
    "    code_embeddings, comment_embeddings = next(self.embedding_generator.from_pairs(pairs))\n",
    "    [store_code_emb, store_comment_emb] = self.get(str(pairs[random_index][\"_id\"]))\n",
    "\n",
    "    correct_indexes = []\n",
    "    for index, (code_emb, comment_emb) in enumerate(zip(code_embeddings, comment_embeddings)):\n",
    "      is_correct = np.array_equal(code_emb, store_code_emb) and np.array_equal(comment_emb, store_comment_emb)\n",
    "      if is_correct:\n",
    "        correct_indexes.append(index)\n",
    "    \n",
    "    return len(correct_indexes) == 1 and correct_indexes[0] == random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_count = 10000\n",
    "test_samples_count = 2000\n",
    "valid_samples_count = 2000\n",
    "db_client = MongoDbClient()\n",
    "embedding_dataset = EmbeddingDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(pairs_ids: List[str]) -> tf.data.Dataset:\n",
    "  def dataset_generator():\n",
    "    for pair_id in pairs_ids:\n",
    "      [code_embedding, comment_embedding] = embedding_dataset.get(pair_id)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": code_embedding,\n",
    "        \"comment_embedding\": comment_embedding,\n",
    "      }\n",
    "  \n",
    "  return tf.data.Dataset.from_generator(dataset_generator, output_types={\n",
    "    \"code_embedding\": tf.float32, \n",
    "    \"comment_embedding\": tf.float32,\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dataset.save(list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(train_samples_count)))\n",
    "embedding_dataset.save(list(db_client.get_pairs_collection().find({ \"partition\": \"test\", \"language\": \"python\" }).limit(test_samples_count)))\n",
    "embedding_dataset.save(list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(valid_samples_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_validate_embedding_dataset = False\n",
    "\n",
    "if should_validate_embedding_dataset:\n",
    "  is_train_correct = embedding_dataset.validate(list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(10)))\n",
    "  is_test_correct = embedding_dataset.validate(list(db_client.get_pairs_collection().find({ \"partition\": \"test\", \"language\": \"python\" }).limit(10)))\n",
    "  is_valid_correct = embedding_dataset.validate(list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(10)))\n",
    "  print(f'is train dataset correct? {is_train_correct}') \n",
    "  print(f'is test dataset correct? {is_test_correct}') \n",
    "  print(f'is valid dataset correct? {is_valid_correct}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumDenseLayers = Literal[2, 4, 8]\n",
    "input_shape = (1024) # TODO: Use variables\n",
    "hidden_layer_activation = 'tanh'\n",
    "output_activation = 'sigmoid'\n",
    "dense_layers: Dict[NumDenseLayers, List] = {\n",
    "  2: [\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ],\n",
    "  4: [\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "  8: [\n",
    "    Dense(800, activation=hidden_layer_activation),\n",
    "    Dense(600, activation=hidden_layer_activation),\n",
    "    Dense(500, activation=hidden_layer_activation),\n",
    "    Dense(400, activation=hidden_layer_activation),\n",
    "    Dense(300, activation=hidden_layer_activation),\n",
    "    Dense(200, activation=hidden_layer_activation),\n",
    "    Dense(100, activation=hidden_layer_activation),\n",
    "    Dense(50, activation=hidden_layer_activation),\n",
    "  ], \n",
    "}\n",
    "dropout_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveLoss(Loss):\n",
    "   def __init__(self, reduction=losses_utils.ReductionV2.AUTO, name=\"constrastive_loss\", margin=1):\n",
    "      self.margin = margin\n",
    "      super().__init__(reduction, name)\n",
    "\n",
    "   def call(self, y_true, y_pred):\n",
    "      square_pred = tf.math.square(y_pred)\n",
    "      margin_square = tf.math.square(tf.math.maximum(self.margin - (y_pred), 0))\n",
    "      return tf.math.reduce_mean(\n",
    "        (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "      )\n",
    "\n",
    "def build_model(num_hidden_layers: NumDenseLayers):\n",
    "  code_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "\n",
    "  concatenated_inputs = Concatenate()([code_input, comment_input])\n",
    "  hidden_layers = Sequential(dense_layers[num_hidden_layers], name=\"hidden_layers\")(concatenated_inputs)\n",
    "  output = Dense(1, activation=output_activation, name=\"output\")(hidden_layers)\n",
    "  model = Model(\n",
    "    inputs=[code_input, comment_input],\n",
    "    outputs=output,\n",
    "    name=\"embedding_comparator\"\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_comparator = build_model(num_hidden_layers=2)\n",
    "tensor_board_callback = callbacks.TensorBoard(log_dir=f\"../logs/scalars/{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "train_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(train_samples_count))]\n",
    "valid_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"valid\", \"language\": \"python\" }).limit(valid_samples_count))]\n",
    "\n",
    "# def map_to_train(sample, target):\n",
    "#     return (sample, target)\n",
    "\n",
    "# positive_pairs = create_tf_dataset(train_pairs).map(lambda sample: map_to_train(sample, 1))\n",
    "# negative_pairs = positive_pairs.shuffle(buffer_size=int(train_samples_count * 0.4))\n",
    "# pairs_dataset = tf.data.Dataset.choose_from_datasets([positive_pairs, negative_pairs], [0, 1])\n",
    "# valid_pairs = create_tf_dataset(valid_pairs).map(lambda sample: map_to_train(sample, 1)).batch(100)\n",
    "\n",
    "# results = embedding_comparator.fit(\n",
    "#     pairs_dataset,\n",
    "#     validation_data=valid_pairs,\n",
    "#     epochs=10,\n",
    "#     callbacks=[tensor_board_callback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sample_target(sample, target: int):\n",
    "  sample['target'] = target\n",
    "  return sample\n",
    "\n",
    "train_dataset = create_tf_dataset(train_pairs).map(lambda sample: set_sample_target(sample, 0))\n",
    "negative_pairs_ds = train_dataset.map(lambda sample: set_sample_target(sample, 1)).shuffle(buffer_size=int(train_samples_count * 0.2))\n",
    "\n",
    "is_equal_count = 0\n",
    "for positive, negative in zip(train_dataset, negative_pairs_ds):\n",
    "  is_equal = np.array_equal(positive['code_embedding'], negative['code_embedding']) and np.array_equal(positive['comment_embedding'], negative['comment_embedding'])\n",
    "  is_equal_count += 1 if is_equal else 0\n",
    "\n",
    "print(f'equal pairs: {is_equal_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_with_target = x.map(lambda sample: set_sample_target(sample, 0))\n",
    "neg_x = x.map(lambda sample: set_sample_target(sample, 1))\n",
    "for positive, negative in zip(x_with_target.take(10), neg_x.take(10)):\n",
    "\n",
    "    print(f\"positive label: {positive['target']} negative target: {negative['target']}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "choice_dataset = tf.data.Dataset.range(2).repeat(10).shuffle(5)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "negative_ds = dataset.shuffle(5).map(lambda i: -i)\n",
    "\n",
    "all_data = tf.data.Dataset.choose_from_datasets([dataset, negative_ds], choice_dataset)\n",
    "\n",
    "for i in all_data:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "  [x, y] = vects\n",
    "  sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=0)\n",
    "  distance = tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "  return distance\n",
    "\n",
    "def build_siamese_model():\n",
    "  code_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"code_embedding\",\n",
    "  )\n",
    "  comment_embedding_input = Input(\n",
    "    shape=input_shape,\n",
    "    name=\"comment_embedding\",\n",
    "  )\n",
    "  similarity_score = Dot(normalize=True, axes=1)([code_embedding_input, comment_embedding_input])\n",
    "\n",
    "  # normal_layer = BatchNormalization()(concatenated_inputs)\n",
    "  output_layer = Dense(1, activation=\"sigmoid\")(similarity_score)\n",
    "  model = Model(inputs=[code_embedding_input, comment_embedding_input], outputs=output_layer, name=\"siamese_model\")\n",
    "  model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=ConstrastiveLoss(),\n",
    "    metrics=[\n",
    "      BinaryAccuracy(),\n",
    "      Precision(name=\"precision\"),\n",
    "      Recall(name=\"recall\"),\n",
    "      # f1_score, # TODO: Reactivate\n",
    "    ],\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model = build_siamese_model()\n",
    "# siamese_model.fit(\n",
    "#     pairs_dataset,\n",
    "#     validation_data=valid_pairs,\n",
    "#     epochs=10,\n",
    "#     callbacks=[tensor_board_callback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pairs = [str(pair['_id']) for pair in list(db_client.get_pairs_collection().find({ \"partition\": \"train\", \"language\": \"python\" }).limit(test_samples_count))]\n",
    "# test_dataset = create_tf_dataset(test_pairs, for_training=False).batch(100)\n",
    "\n",
    "# predicts = siamese_model.predict(test_dataset)\n",
    "# predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embedding_sample(sample):\n",
    "  fig, axs = plt.subplots(ncols=2, nrows=1)\n",
    "  code_axs = axs[0]\n",
    "  comment_axs = axs[1]\n",
    "\n",
    "  code_axs.plot(sample['code_embedding'], label=\"code\", color=\"blue\")\n",
    "  comment_axs.plot(sample['comment_embedding'], label=\"comment\", color=\"orange\")\n",
    "  fig.legend()\n",
    "  \n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = MongoDbClient().get_pairs_collection().find_one({\"language\": \"python\", \"partition\": \"train\" })\n",
    "if pair is None:\n",
    "    raise ValueError(\"Not found\")\n",
    "\n",
    "[code, comment] = EmbeddingGenerator().from_pairs([pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embedding_sample({\n",
    "    \"code_embedding\": code.numpy()[0],\n",
    "    \"comment_embedding\": comment.numpy()[0],\n",
    "})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import orjson\n",
    "def create_tf_dataset_from_csnet(partition: str) -> Iterator:\n",
    "  dataset_dir = os.path.join('../datasets/temp_python/python', 'final', 'jsonl', partition)\n",
    "  # file_names = [os.path.join(dataset_dir, file_name) for file_name in os.listdir(dataset_dir) if file_name.endswith('.jsonl.gz')]\n",
    "  file_names = [os.path.join(dataset_dir, 'python_train_0.jsonl.gz')]\n",
    "  return tf.data.TextLineDataset(\n",
    "    filenames=file_names,\n",
    "    compression_type='GZIP',\n",
    "    num_parallel_reads=tf.data.AUTOTUNE,\n",
    "  )\n",
    "\n",
    "expected = {\"repo\": \"ageitgey/face_recognition\", \"path\": \"examples/face_recognition_knn.py\", \"func_name\": \"train\", \"original_string\": \"def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \\\"\\\"\\\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \\\"\\\"\\\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\\\"Image {} not suitable for training: {}\\\".format(img_path, \\\"Didn't find a face\\\" if len(face_bounding_boxes) < 1 else \\\"Found more than one face\\\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\\\"Chose n_neighbors automatically:\\\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, 'wb') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf\", \"language\": \"python\", \"code\": \"def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\\n    \\\"\\\"\\\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \\\"\\\"\\\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\\\"Image {} not suitable for training: {}\\\".format(img_path, \\\"Didn't find a face\\\" if len(face_bounding_boxes) < 1 else \\\"Found more than one face\\\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\\\"Chose n_neighbors automatically:\\\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, 'wb') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf\", \"code_tokens\": [\"def\", \"train\", \"(\", \"train_dir\", \",\", \"model_save_path\", \"=\", \"None\", \",\", \"n_neighbors\", \"=\", \"None\", \",\", \"knn_algo\", \"=\", \"'ball_tree'\", \",\", \"verbose\", \"=\", \"False\", \")\", \":\", \"X\", \"=\", \"[\", \"]\", \"y\", \"=\", \"[\", \"]\", \"# Loop through each person in the training set\", \"for\", \"class_dir\", \"in\", \"os\", \".\", \"listdir\", \"(\", \"train_dir\", \")\", \":\", \"if\", \"not\", \"os\", \".\", \"path\", \".\", \"isdir\", \"(\", \"os\", \".\", \"path\", \".\", \"join\", \"(\", \"train_dir\", \",\", \"class_dir\", \")\", \")\", \":\", \"continue\", \"# Loop through each training image for the current person\", \"for\", \"img_path\", \"in\", \"image_files_in_folder\", \"(\", \"os\", \".\", \"path\", \".\", \"join\", \"(\", \"train_dir\", \",\", \"class_dir\", \")\", \")\", \":\", \"image\", \"=\", \"face_recognition\", \".\", \"load_image_file\", \"(\", \"img_path\", \")\", \"face_bounding_boxes\", \"=\", \"face_recognition\", \".\", \"face_locations\", \"(\", \"image\", \")\", \"if\", \"len\", \"(\", \"face_bounding_boxes\", \")\", \"!=\", \"1\", \":\", \"# If there are no people (or too many people) in a training image, skip the image.\", \"if\", \"verbose\", \":\", \"print\", \"(\", \"\\\"Image {} not suitable for training: {}\\\"\", \".\", \"format\", \"(\", \"img_path\", \",\", \"\\\"Didn't find a face\\\"\", \"if\", \"len\", \"(\", \"face_bounding_boxes\", \")\", \"<\", \"1\", \"else\", \"\\\"Found more than one face\\\"\", \")\", \")\", \"else\", \":\", \"# Add face encoding for current image to the training set\", \"X\", \".\", \"append\", \"(\", \"face_recognition\", \".\", \"face_encodings\", \"(\", \"image\", \",\", \"known_face_locations\", \"=\", \"face_bounding_boxes\", \")\", \"[\", \"0\", \"]\", \")\", \"y\", \".\", \"append\", \"(\", \"class_dir\", \")\", \"# Determine how many neighbors to use for weighting in the KNN classifier\", \"if\", \"n_neighbors\", \"is\", \"None\", \":\", \"n_neighbors\", \"=\", \"int\", \"(\", \"round\", \"(\", \"math\", \".\", \"sqrt\", \"(\", \"len\", \"(\", \"X\", \")\", \")\", \")\", \")\", \"if\", \"verbose\", \":\", \"print\", \"(\", \"\\\"Chose n_neighbors automatically:\\\"\", \",\", \"n_neighbors\", \")\", \"# Create and train the KNN classifier\", \"knn_clf\", \"=\", \"neighbors\", \".\", \"KNeighborsClassifier\", \"(\", \"n_neighbors\", \"=\", \"n_neighbors\", \",\", \"algorithm\", \"=\", \"knn_algo\", \",\", \"weights\", \"=\", \"'distance'\", \")\", \"knn_clf\", \".\", \"fit\", \"(\", \"X\", \",\", \"y\", \")\", \"# Save the trained KNN classifier\", \"if\", \"model_save_path\", \"is\", \"not\", \"None\", \":\", \"with\", \"open\", \"(\", \"model_save_path\", \",\", \"'wb'\", \")\", \"as\", \"f\", \":\", \"pickle\", \".\", \"dump\", \"(\", \"knn_clf\", \",\", \"f\", \")\", \"return\", \"knn_clf\"], \"docstring\": \"Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        \\u251c\\u2500\\u2500 <person1>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 <somename2>.jpeg\\n        \\u2502   \\u251c\\u2500\\u2500 ...\\n        \\u251c\\u2500\\u2500 <person2>/\\n        \\u2502   \\u251c\\u2500\\u2500 <somename1>.jpeg\\n        \\u2502   \\u2514\\u2500\\u2500 <somename2>.jpeg\\n        \\u2514\\u2500\\u2500 ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\", \"docstring_tokens\": [\"Trains\", \"a\", \"k\", \"-\", \"nearest\", \"neighbors\", \"classifier\", \"for\", \"face\", \"recognition\", \".\"], \"sha\": \"c96b010c02f15e8eeb0f71308c641179ac1f19bb\", \"url\": \"https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108\", \"partition\": \"train\"}\n",
    "for i in create_tf_dataset_from_csnet('train'):\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/beto/Projects/embedding_comparator/src/datasets/temp_python/python/final/jsonl/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcs_net_parser\u001b[39;00m \u001b[39mimport\u001b[39;00m CSNetParser\n\u001b[1;32m      4\u001b[0m cs_net_parser \u001b[39m=\u001b[39m CSNetParser()\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m cs_net_parser\u001b[39m.\u001b[39mto_tf_dataset(partition\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, language\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Projects/embedding_comparator/src/cs_net_parser.py:42\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m orjson\u001b[39m.\u001b[39mloads(tensor\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     41\u001b[0m cs_net_parser \u001b[39m=\u001b[39m CSNetParser()\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m cs_net_parser\u001b[39m.\u001b[39;49mto_tf_dataset(partition\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, language\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m'\u001b[39;49m):\n\u001b[1;32m     43\u001b[0m   sample \u001b[39m=\u001b[39m cs_net_parser\u001b[39m.\u001b[39mtensor_to_sample(tensor)\n\u001b[1;32m     44\u001b[0m   \u001b[39mif\u001b[39;00m sample[\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://github.com/mjirik/imcut/blob/1b38e7cd18a7a38fe683c1cabe1222fe5fa03aa3/imcut/graph.py#L586-L636\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/embedding_comparator/src/cs_net_parser.py:29\u001b[0m, in \u001b[0;36mCSNetParser.to_tf_dataset\u001b[0;34m(self, partition, language)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_tf_dataset\u001b[39m(\u001b[39mself\u001b[39m, partition: CSNetPartition \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, language: CSNetCodeLanguage \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset:\n\u001b[1;32m     28\u001b[0m   dataset_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mcurdir), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdatasets/temp_\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, language, \u001b[39m'\u001b[39m\u001b[39mfinal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjsonl\u001b[39m\u001b[39m'\u001b[39m, partition)\n\u001b[0;32m---> 29\u001b[0m   file_names \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir, file_name) \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(dataset_dir) \u001b[39mif\u001b[39;00m file_name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.jsonl.gz\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     31\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTextLineDataset(\n\u001b[1;32m     32\u001b[0m     filenames\u001b[39m=\u001b[39mfile_names,\n\u001b[1;32m     33\u001b[0m     compression_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGZIP\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     num_parallel_reads\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE,\n\u001b[1;32m     35\u001b[0m   )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/beto/Projects/embedding_comparator/src/datasets/temp_python/python/final/jsonl/train'"
     ]
    }
   ],
   "source": [
    "from cs_net_parser import CSNetParser\n",
    "\n",
    "\n",
    "cs_net_parser = CSNetParser()\n",
    "for tensor in cs_net_parser.to_tf_dataset(partition='train', language='python'):\n",
    "  sample = cs_net_parser.tensor_to_sample(tensor)\n",
    "  if sample['url'] == 'https://github.com/mjirik/imcut/blob/1b38e7cd18a7a38fe683c1cabe1222fe5fa03aa3/imcut/graph.py#L586-L636':\n",
    "    print(sample)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
