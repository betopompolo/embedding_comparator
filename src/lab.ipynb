{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CodeSearchNetLanguage = Literal['python', 'go', 'java', 'javascript', 'php', 'ruby']\n",
    "CodeSearchNetSplit = Literal['train', 'test', 'validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "def load_from_cs_net(take: int) -> Dataset:\n",
    "  ds = load_dataset(dataset_name, 'python', split='train')\n",
    "  return Dataset.from_dict(ds[:take]) # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "comment_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "code_model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "embedding_shape = (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "random_generator = default_rng(seed=42)\n",
    "\n",
    "def generate_negative_samples(iterator: Iterator, negative_samples_per_sample: int):\n",
    "  for batched_sample in iterator:\n",
    "    codes_embeddings = batched_sample['code_embedding']\n",
    "    comments_embeddings = batched_sample['comment_embedding']\n",
    "    batch_indexes = range(len(codes_embeddings))\n",
    "\n",
    "    for index in batch_indexes:\n",
    "      indexes = [i for i in batch_indexes if i != index]\n",
    "      negative_indexes = random_generator.choice(indexes, negative_samples_per_sample, replace=False)\n",
    "\n",
    "      yield {\n",
    "        \"code_embedding\": codes_embeddings[index],\n",
    "        \"comment_embedding\": comments_embeddings[index],\n",
    "        \"target\": 1\n",
    "      }\n",
    "\n",
    "      for negative_index in negative_indexes:\n",
    "        yield {\n",
    "          \"code_embedding\": codes_embeddings[index],\n",
    "          \"comment_embedding\": comments_embeddings[negative_index],\n",
    "          \"target\": 0\n",
    "        }\n",
    "\n",
    "def with_neg_samples(dataset: Dataset, negative_samples_per_sample: int, batch_size = 100) -> Dataset:\n",
    "  if negative_samples_per_sample <= 1:\n",
    "    return dataset\n",
    "  \n",
    "  dataset_with_negative_samples: Dataset = Dataset.from_generator(lambda: generate_negative_samples(dataset.iter(batch_size=batch_size), negative_samples_per_sample)) # type: ignore\n",
    "  return dataset_with_negative_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_in_batch(batched_sample):\n",
    "  codes = batched_sample['func_code_string']\n",
    "  comments = batched_sample['func_documentation_string']\n",
    "\n",
    "  return {\n",
    "    \"code_embedding\": code_model.encode(codes),\n",
    "    \"comment_embedding\": comment_model.encode(comments),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_count = 10000\n",
    "train_dataset_path = f'../datasets/embeddings_python_train_{train_count}'\n",
    "cs_net_pairs = load_from_cs_net(train_count)\n",
    "is_embeddings_dataset_stored = os.path.isdir(train_dataset_path)\n",
    "\n",
    "embeddings_dataset: Dataset = load_from_disk(train_dataset_path) if is_embeddings_dataset_stored else cs_net_pairs.map(\n",
    "  generate_embeddings_in_batch, \n",
    "  batched=True, \n",
    "  batch_size=100,\n",
    "  remove_columns=list(cs_net_pairs[0].keys()),\n",
    "  desc=\"Generating embeddings\"\n",
    ") # type: ignore\n",
    "\n",
    "if is_embeddings_dataset_stored == False:\n",
    "  embeddings_dataset.save_to_disk(train_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add negative samples to train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 01:12:30.288570: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-12 01:12:30.288947: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "negative_samples_per_sample = 5\n",
    "shuffle_buffer = int(train_count * 0.4)\n",
    "tf_train_dataset = with_neg_samples(embeddings_dataset, negative_samples_per_sample).to_tf_dataset().shuffle(shuffle_buffer).map(lambda sample: ({\n",
    "  \"code_embedding\": sample[\"code_embedding\"],\n",
    "  \"comment_embedding\": sample[\"comment_embedding\"],\n",
    "}, sample[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_dense_model\n",
    "\n",
    "epoch = 100\n",
    "batch_size = 200\n",
    "model = build_dense_model(num_hidden_layers=4, input_shape=embedding_shape, model_name='dense_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 01:12:30.929095: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-10-12 01:12:30.932731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 96s 299ms/step - loss: 0.4307 - binary_accuracy: 0.8327 - precision: 0.4281 - recall: 0.0119\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 101s 316ms/step - loss: 0.3247 - binary_accuracy: 0.8504 - precision: 0.6170 - recall: 0.2697\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.2743 - binary_accuracy: 0.8707 - precision: 0.6463 - recall: 0.4954\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 101s 316ms/step - loss: 0.2532 - binary_accuracy: 0.8812 - precision: 0.6731 - recall: 0.5587\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 101s 315ms/step - loss: 0.2407 - binary_accuracy: 0.8873 - precision: 0.6874 - recall: 0.5941\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 99s 309ms/step - loss: 0.2312 - binary_accuracy: 0.8919 - precision: 0.7023 - recall: 0.6097\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 99s 310ms/step - loss: 0.2200 - binary_accuracy: 0.8964 - precision: 0.7098 - recall: 0.6397\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 100s 312ms/step - loss: 0.2093 - binary_accuracy: 0.9028 - precision: 0.7253 - recall: 0.6708\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.1969 - binary_accuracy: 0.9093 - precision: 0.7420 - recall: 0.6985\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.1827 - binary_accuracy: 0.9169 - precision: 0.7578 - recall: 0.7372\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 96s 301ms/step - loss: 0.1717 - binary_accuracy: 0.9221 - precision: 0.7714 - recall: 0.7570\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.1566 - binary_accuracy: 0.9309 - precision: 0.7943 - recall: 0.7896\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.1427 - binary_accuracy: 0.9384 - precision: 0.8134 - recall: 0.8184\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.1304 - binary_accuracy: 0.9439 - precision: 0.8288 - recall: 0.8362\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.1175 - binary_accuracy: 0.9510 - precision: 0.8495 - recall: 0.8583\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.1067 - binary_accuracy: 0.9564 - precision: 0.8652 - recall: 0.8751\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.0960 - binary_accuracy: 0.9607 - precision: 0.8767 - recall: 0.8890\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0852 - binary_accuracy: 0.9653 - precision: 0.8910 - recall: 0.9022\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0741 - binary_accuracy: 0.9712 - precision: 0.9092 - recall: 0.9187\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0660 - binary_accuracy: 0.9747 - precision: 0.9185 - recall: 0.9308\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0602 - binary_accuracy: 0.9766 - precision: 0.9258 - recall: 0.9346\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0529 - binary_accuracy: 0.9800 - precision: 0.9349 - recall: 0.9459\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0489 - binary_accuracy: 0.9814 - precision: 0.9403 - recall: 0.9487\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0468 - binary_accuracy: 0.9821 - precision: 0.9426 - recall: 0.9507\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0389 - binary_accuracy: 0.9858 - precision: 0.9542 - recall: 0.9608\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0337 - binary_accuracy: 0.9876 - precision: 0.9596 - recall: 0.9663\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0306 - binary_accuracy: 0.9890 - precision: 0.9635 - recall: 0.9707\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0320 - binary_accuracy: 0.9884 - precision: 0.9622 - recall: 0.9687\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0309 - binary_accuracy: 0.9884 - precision: 0.9620 - recall: 0.9687\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0272 - binary_accuracy: 0.9905 - precision: 0.9680 - recall: 0.9752\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0290 - binary_accuracy: 0.9892 - precision: 0.9658 - recall: 0.9695\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0264 - binary_accuracy: 0.9897 - precision: 0.9674 - recall: 0.9710\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0272 - binary_accuracy: 0.9903 - precision: 0.9685 - recall: 0.9735\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0209 - binary_accuracy: 0.9917 - precision: 0.9725 - recall: 0.9781\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0211 - binary_accuracy: 0.9927 - precision: 0.9757 - recall: 0.9804\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0228 - binary_accuracy: 0.9917 - precision: 0.9717 - recall: 0.9786\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0254 - binary_accuracy: 0.9906 - precision: 0.9683 - recall: 0.9757\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0213 - binary_accuracy: 0.9920 - precision: 0.9732 - recall: 0.9787\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0192 - binary_accuracy: 0.9930 - precision: 0.9762 - recall: 0.9821\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 98s 305ms/step - loss: 0.0177 - binary_accuracy: 0.9936 - precision: 0.9785 - recall: 0.9834\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 102s 317ms/step - loss: 0.0180 - binary_accuracy: 0.9930 - precision: 0.9764 - recall: 0.9816\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.0225 - binary_accuracy: 0.9917 - precision: 0.9709 - recall: 0.9794\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.0218 - binary_accuracy: 0.9918 - precision: 0.9732 - recall: 0.9777\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.0220 - binary_accuracy: 0.9917 - precision: 0.9732 - recall: 0.9772\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.0195 - binary_accuracy: 0.9923 - precision: 0.9742 - recall: 0.9796\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 101s 314ms/step - loss: 0.0153 - binary_accuracy: 0.9943 - precision: 0.9811 - recall: 0.9847\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 99s 310ms/step - loss: 0.0168 - binary_accuracy: 0.9936 - precision: 0.9790 - recall: 0.9825\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0163 - binary_accuracy: 0.9935 - precision: 0.9774 - recall: 0.9837\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0163 - binary_accuracy: 0.9938 - precision: 0.9790 - recall: 0.9839\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0180 - binary_accuracy: 0.9932 - precision: 0.9772 - recall: 0.9822\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0190 - binary_accuracy: 0.9926 - precision: 0.9745 - recall: 0.9810\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0151 - binary_accuracy: 0.9942 - precision: 0.9797 - recall: 0.9854\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0166 - binary_accuracy: 0.9932 - precision: 0.9773 - recall: 0.9822\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0158 - binary_accuracy: 0.9937 - precision: 0.9792 - recall: 0.9828\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0176 - binary_accuracy: 0.9930 - precision: 0.9755 - recall: 0.9827\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0175 - binary_accuracy: 0.9928 - precision: 0.9762 - recall: 0.9806\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0180 - binary_accuracy: 0.9929 - precision: 0.9757 - recall: 0.9818\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0135 - binary_accuracy: 0.9944 - precision: 0.9807 - recall: 0.9858\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 98s 304ms/step - loss: 0.0131 - binary_accuracy: 0.9948 - precision: 0.9818 - recall: 0.9874\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0140 - binary_accuracy: 0.9945 - precision: 0.9814 - recall: 0.9857\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0135 - binary_accuracy: 0.9945 - precision: 0.9818 - recall: 0.9856\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0179 - binary_accuracy: 0.9931 - precision: 0.9771 - recall: 0.9815\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0187 - binary_accuracy: 0.9929 - precision: 0.9765 - recall: 0.9811\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0124 - binary_accuracy: 0.9950 - precision: 0.9827 - recall: 0.9876\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0114 - binary_accuracy: 0.9951 - precision: 0.9825 - recall: 0.9884\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0136 - binary_accuracy: 0.9943 - precision: 0.9798 - recall: 0.9863\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0118 - binary_accuracy: 0.9953 - precision: 0.9832 - recall: 0.9886\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0178 - binary_accuracy: 0.9930 - precision: 0.9769 - recall: 0.9814\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0164 - binary_accuracy: 0.9934 - precision: 0.9774 - recall: 0.9834\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0159 - binary_accuracy: 0.9936 - precision: 0.9786 - recall: 0.9832\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0121 - binary_accuracy: 0.9948 - precision: 0.9809 - recall: 0.9881\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0120 - binary_accuracy: 0.9952 - precision: 0.9835 - recall: 0.9875\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0132 - binary_accuracy: 0.9949 - precision: 0.9827 - recall: 0.9866\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0143 - binary_accuracy: 0.9943 - precision: 0.9810 - recall: 0.9851\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0172 - binary_accuracy: 0.9934 - precision: 0.9783 - recall: 0.9823\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0140 - binary_accuracy: 0.9943 - precision: 0.9795 - recall: 0.9863\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0121 - binary_accuracy: 0.9951 - precision: 0.9823 - recall: 0.9883\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0103 - binary_accuracy: 0.9957 - precision: 0.9846 - recall: 0.9895\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 98s 304ms/step - loss: 0.0089 - binary_accuracy: 0.9965 - precision: 0.9875 - recall: 0.9914\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0102 - binary_accuracy: 0.9959 - precision: 0.9844 - recall: 0.9911\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0135 - binary_accuracy: 0.9948 - precision: 0.9821 - recall: 0.9871\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0202 - binary_accuracy: 0.9923 - precision: 0.9736 - recall: 0.9802\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0151 - binary_accuracy: 0.9938 - precision: 0.9791 - recall: 0.9839\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.0110 - binary_accuracy: 0.9953 - precision: 0.9837 - recall: 0.9884\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0115 - binary_accuracy: 0.9953 - precision: 0.9835 - recall: 0.9883\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0123 - binary_accuracy: 0.9949 - precision: 0.9820 - recall: 0.9878\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0118 - binary_accuracy: 0.9952 - precision: 0.9842 - recall: 0.9871\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0126 - binary_accuracy: 0.9949 - precision: 0.9814 - recall: 0.9879\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0139 - binary_accuracy: 0.9945 - precision: 0.9816 - recall: 0.9857\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0135 - binary_accuracy: 0.9945 - precision: 0.9809 - recall: 0.9861\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0125 - binary_accuracy: 0.9952 - precision: 0.9834 - recall: 0.9876\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0108 - binary_accuracy: 0.9956 - precision: 0.9839 - recall: 0.9899\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0103 - binary_accuracy: 0.9954 - precision: 0.9837 - recall: 0.9890\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0099 - binary_accuracy: 0.9958 - precision: 0.9842 - recall: 0.9904\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 97s 302ms/step - loss: 0.0107 - binary_accuracy: 0.9956 - precision: 0.9840 - recall: 0.9895\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 97s 304ms/step - loss: 0.0144 - binary_accuracy: 0.9943 - precision: 0.9812 - recall: 0.9845\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0164 - binary_accuracy: 0.9936 - precision: 0.9778 - recall: 0.9837\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0134 - binary_accuracy: 0.9944 - precision: 0.9811 - recall: 0.9856\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0109 - binary_accuracy: 0.9956 - precision: 0.9839 - recall: 0.9896\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 97s 303ms/step - loss: 0.0104 - binary_accuracy: 0.9955 - precision: 0.9838 - recall: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30b47b2b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras import callbacks\n",
    "\n",
    "tensor_board_callback = callbacks.TensorBoard(log_dir=f'../logs/{model.name}-{datetime.now()}')\n",
    "model.fit(\n",
    "  tf_train_dataset.batch(batch_size),\n",
    "  batch_size=batch_size,\n",
    "  epochs=epoch,\n",
    "  callbacks=[tensor_board_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dense_4-new/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f'../models/{model.name}-new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
