{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beto/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from typing import TypedDict, Literal, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_samples_count = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CodeSearchNetLanguage = Literal['python', 'go', 'java', 'javascript', 'php', 'ruby']\n",
    "CodeSearchNetSplit = Literal['train', 'test', 'validation']\n",
    "\n",
    "class CodeSearchNetSample(TypedDict):\n",
    "  repository_name: str\n",
    "  func_path_in_repository: str\n",
    "  func_name: str\n",
    "  whole_func_string: str\n",
    "  language: CodeSearchNetLanguage\n",
    "  func_code_string: str\n",
    "  func_code_tokens: List[str]\n",
    "  func_documentation_string: str\n",
    "  func_documentation_string_tokens: List[str]\n",
    "  split_name: CodeSearchNetSplit\n",
    "  func_code_url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "def load(language: CodeSearchNetLanguage, split: CodeSearchNetSplit, take: int) -> Dataset:\n",
    "  ds = cast(Dataset, load_dataset(dataset_name, language, split=split))\n",
    "  return Dataset.from_dict(ds[:take])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "comment_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "code_model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "embedding_shape = (768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "random_generator = default_rng(seed=42)\n",
    "\n",
    "skip_generating_ds = True\n",
    "\n",
    "def generate_negative_samples(iterator: Iterator, negative_samples_per_sample: int):\n",
    "  for batched_sample in iterator:\n",
    "    processed_codes = [' '.join(code_tokens) for code_tokens in batched_sample['func_code_tokens']]\n",
    "    processed_comments = [' '.join(comment_tokens) for comment_tokens in batched_sample['func_documentation_tokens']]\n",
    "    batch_indexes = range(len(processed_codes))\n",
    "\n",
    "    for index, code, comment in zip(batch_indexes, processed_codes, processed_comments):\n",
    "      indexes = [i for i in batch_indexes if i != index]\n",
    "      negative_indexes = random_generator.choice(indexes, negative_samples_per_sample, replace=False)\n",
    "      negative_comments = np.array(processed_comments)[negative_indexes]\n",
    "      for negative_comment in negative_comments:\n",
    "        yield {\n",
    "          \"code\": code,\n",
    "          \"comment_positive\": comment,\n",
    "          \"comment_negative\": negative_comment,\n",
    "        }\n",
    "\n",
    "def pre_process_sample(sample):\n",
    "  return {\n",
    "    \"code\": ' '.join(sample['func_code_tokens']),\n",
    "    \"comment\": ' '.join(sample['func_documentation_tokens'])\n",
    "  }\n",
    "\n",
    "if skip_generating_ds == False:\n",
    "  pre_processed_ds: Dataset = load('python', 'train', take=train_samples_count).map(pre_process_sample, desc=\"Loading and pre-processing\")\n",
    "  full_ds: Dataset = Dataset.from_generator(lambda: generate_negative_samples(pre_processed_ds.iter(batch_size=batch_size), 3)) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(batched_sample):\n",
    "  return {\n",
    "    \"code_embedding\": code_model.encode(batched_sample[\"code\"]),\n",
    "    \"comment_positive_embedding\": comment_model.encode(batched_sample[\"comment_positive\"]),\n",
    "    \"comment_negative_embedding\": comment_model.encode(batched_sample[\"comment_negative\"]),\n",
    "  }\n",
    "\n",
    "train_ds = full_ds.map(add_embeddings, remove_columns=list(full_ds.features.keys()), batch_size=batch_size, batched=True, desc=\"Generating embeddings\") if skip_generating_ds == False else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_ds is None:\n",
    "  train_ds = load_from_disk('../datasets/train_with_negative_samples')\n",
    "else:\n",
    "  train_ds.save_to_disk('../datasets/train_with_negative_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 17:22:02.707217: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-07 17:22:02.707314: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from models import embedding_comparator_model\n",
    "\n",
    "\n",
    "model = embedding_comparator_model(input_shape=embedding_shape, margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_indexes = range(0, 30000, 3)\n",
    "new_train_ds = train_ds.select(test_train_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 17:22:02.845433: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-10-07 17:22:02.894713: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1074\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1074\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1074\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x31532ce80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras import callbacks\n",
    "\n",
    "print(f\"training with {len(test_train_indexes)} samples\")\n",
    "\n",
    "train_tf_dataset = new_train_ds.to_tf_dataset(batch_size=batch_size)\n",
    "\n",
    "tensor_board_callback = callbacks.TensorBoard(log_dir=f'../logs/embedding_comparator_{datetime.now()}')\n",
    "model.fit(train_tf_dataset, epochs=50, batch_size=batch_size, callbacks=[tensor_board_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name='code_embedding'), name='code_embedding', description=\"created by layer 'code_embedding'\"), but it was called on an input with incompatible shape (768,).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name='comment_positive_embedding'), name='comment_positive_embedding', description=\"created by layer 'comment_positive_embedding'\"), but it was called on an input with incompatible shape (768,).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name='comment_negative_embedding'), name='comment_negative_embedding', description=\"created by layer 'comment_negative_embedding'\"), but it was called on an input with incompatible shape (768,).\n",
      "  39/1000 [>.............................] - ETA: 3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 17:22:31.729830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "tests = new_train_ds.to_tf_dataset().take(1000)\n",
    "predicts = model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second = predicts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
